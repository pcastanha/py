{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import logging\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from optparse import OptionParser\n",
    "import sys\n",
    "from time import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neighbors import NearestCentroid\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.utils.extmath import density\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "# Display progress logs on stdout\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s %(levelname)s %(message)s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define default labels\n",
    "labels = ['Fatos', 'Normas', 'Argumentos', 'Pedidos', 'Irrelevante']\n",
    "\n",
    "# Define stopwords list\n",
    "stopwords = []\n",
    "\n",
    "raw_data = pd.read_csv('C:\\Users\\pedro.castanha\\Downloads\\ML_Gabinete_Digital.csv', error_bad_lines=False, sep='\\t', encoding='utf_8')\n",
    "words = pd.read_table('C:\\Users\\pedro.castanha\\Downloads\\stoplists\\stopwords_pt_br.txt', encoding='mbcs')\n",
    "\n",
    "stopwords = words.values.T.tolist()[0]\n",
    "\n",
    "x_vectorized = TfidfVectorizer(sublinear_tf=True, use_idf=True, max_df=0.5, stop_words=stopwords)\n",
    "x_vectorized.fit(raw_data.Text)\n",
    "x_train = x_vectorized.transform(raw_data.Text)\n",
    "y_train = raw_data.Class\n",
    "\n",
    "names = np.asarray(x_vectorized.get_feature_names())\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_train, y_train, test_size=0.4, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load some categories from the training set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 20 newsgroups dataset for categories:\n",
      "['alt.atheism', 'talk.religion.misc', 'comp.graphics', 'sci.space']\n",
      "data loaded\n",
      "2034 documents - 3.980MB (training set)\n",
      "1353 documents - 2.867MB (test set)\n",
      "4 categories\n",
      "\n",
      "Extracting features from the training data using a sparse vectorizer\n",
      "done in 0.778000s at 5.115MB/s\n",
      "n_samples: 2034, n_features: 33809\n",
      "\n",
      "Extracting features from the test data using the same vectorizer\n",
      "done in 0.395000s at 7.259MB/s\n",
      "n_samples: 1353, n_features: 33809\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#if opts.all_categories:\n",
    "#    categories = None\n",
    "\n",
    "categories = [\n",
    "        'alt.atheism',\n",
    "        'talk.religion.misc',\n",
    "        'comp.graphics',\n",
    "        'sci.space',\n",
    "]\n",
    "\n",
    "#if opts.filtered:\n",
    "#    remove = ('headers', 'footers', 'quotes')\n",
    "#else:\n",
    "remove = ()\n",
    "\n",
    "print(\"Loading 20 newsgroups dataset for categories:\")\n",
    "print(categories if categories else \"all\")\n",
    "\n",
    "data_train = fetch_20newsgroups(subset='train', categories=categories,\n",
    "                                shuffle=True, random_state=42,\n",
    "                                remove=remove)\n",
    "\n",
    "data_test = fetch_20newsgroups(subset='test', categories=categories,\n",
    "                               shuffle=True, random_state=42,\n",
    "                               remove=remove)\n",
    "print('data loaded')\n",
    "\n",
    "# order of labels in `target_names` can be different from `categories`\n",
    "target_names = data_train.target_names\n",
    "\n",
    "\n",
    "def size_mb(docs):\n",
    "    return sum(len(s.encode('utf-8')) for s in docs) / 1e6\n",
    "\n",
    "data_train_size_mb = size_mb(data_train.data)\n",
    "data_test_size_mb = size_mb(data_test.data)\n",
    "\n",
    "print(\"%d documents - %0.3fMB (training set)\" % (\n",
    "    len(data_train.data), data_train_size_mb))\n",
    "print(\"%d documents - %0.3fMB (test set)\" % (\n",
    "    len(data_test.data), data_test_size_mb))\n",
    "print(\"%d categories\" % len(categories))\n",
    "print()\n",
    "\n",
    "# split a training set and a test set\n",
    "y_train, y_test = data_train.target, data_test.target\n",
    "\n",
    "print(\"Extracting features from the training data using a sparse vectorizer\")\n",
    "t0 = time()\n",
    "#if opts.use_hashing:\n",
    "#    vectorizer = HashingVectorizer(stop_words='english', non_negative=True,\n",
    "#                                   n_features=opts.n_features)\n",
    "#    X_train = vectorizer.transform(data_train.data)\n",
    "#else:\n",
    "vectorizer = TfidfVectorizer(sublinear_tf=True, use_idf=True, max_df=0.5, stop_words='english')\n",
    "X_train = vectorizer.fit_transform(data_train.data)\n",
    "duration = time() - t0\n",
    "print(\"done in %fs at %0.3fMB/s\" % (duration, data_train_size_mb / duration))\n",
    "print(\"n_samples: %d, n_features: %d\" % X_train.shape)\n",
    "print()\n",
    "\n",
    "print(\"Extracting features from the test data using the same vectorizer\")\n",
    "t0 = time()\n",
    "X_test = vectorizer.transform(data_test.data)\n",
    "duration = time() - t0\n",
    "print(\"done in %fs at %0.3fMB/s\" % (duration, data_test_size_mb / duration))\n",
    "print(\"n_samples: %d, n_features: %d\" % X_test.shape)\n",
    "print()\n",
    "\n",
    "# mapping from integer feature name to original token string\n",
    "#if opts.use_hashing:\n",
    "#    feature_names = None\n",
    "#else:\n",
    "feature_names = vectorizer.get_feature_names()\n",
    "\n",
    "#if opts.select_chi2:\n",
    "#    print(\"Extracting %d best features by a chi-squared test\" %\n",
    "#          opts.select_chi2)\n",
    "#    t0 = time()\n",
    "#    ch2 = SelectKBest(chi2, k=opts.select_chi2)\n",
    "#    X_train = ch2.fit_transform(X_train, y_train)\n",
    "#    X_test = ch2.transform(X_test)\n",
    "#    if feature_names:\n",
    "        # keep selected feature names\n",
    "#        feature_names = [feature_names[i] for i\n",
    "#                         in ch2.get_support(indices=True)]\n",
    "#    print(\"done in %fs\" % (time() - t0))\n",
    "#    print()\n",
    "\n",
    "if feature_names:\n",
    "    feature_names = np.asarray(feature_names)\n",
    "\n",
    "\n",
    "def trim(s):\n",
    "    \"\"\"Trim string to fit on terminal (assuming 80-column display)\"\"\"\n",
    "    return s if len(s) <= 80 else s[:77] + \"...\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Projecting the input data...\n",
      "Done in: 6.028s\n"
     ]
    }
   ],
   "source": [
    "# Init - PCA Dim. reduction\n",
    "print(\"Projecting the input data...\")\n",
    "t0 = time()\n",
    "\n",
    "svd = TruncatedSVD(n_components=2000, algorithm='randomized',).fit(X_train.toarray())\n",
    "X_train = svd.transform(X_train)\n",
    "X_test = svd.transform(X_test)\n",
    "\n",
    "X_train = normalize(X_train)\n",
    "X_test = normalize(X_test)\n",
    "\n",
    "print(\"Done in: %0.3fs\" % (time() - t0))\n",
    "# End - PCA Dim. reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Ridge Classifier\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,\n",
      "        max_iter=None, normalize=False, random_state=None, solver='lsqr',\n",
      "        tol=0.01)\n",
      "train time: 0.000s\n",
      "test time:  0.016s\n",
      "accuracy:   0.897\n",
      "dimensionality: 300\n",
      "density: 1.000000\n",
      "top 10 keywords per class:\n",
      "alt.atheism: 000062david42 01a 000usd 0029 001555 000005102000 00 0001 000100...\n",
      "comp.graphics: 0192 0022 000062david42 0000vec 013034 02115 011634edt 0049 00...\n",
      "sci.space: 0004422 001718 000005102000 012536 000406 0033 00196 0004136 01854...\n",
      "talk.religion.misc: 001757 003719 002 0010580b 00090711 000 013034 0100 0000 ...\n",
      "\n",
      "classification report:\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "       alt.atheism       0.84      0.83      0.84       319\n",
      "     comp.graphics       0.94      0.97      0.95       389\n",
      "         sci.space       0.95      0.96      0.95       394\n",
      "talk.religion.misc       0.81      0.77      0.79       251\n",
      "\n",
      "       avg / total       0.90      0.90      0.90      1353\n",
      "\n",
      "confusion matrix:\n",
      "[[266   4  10  39]\n",
      " [  3 377   3   6]\n",
      " [  1  16 377   0]\n",
      " [ 45   4   8 194]]\n",
      "\n",
      "================================================================================\n",
      "Perceptron\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "Perceptron(alpha=0.0001, class_weight=None, eta0=1.0, fit_intercept=True,\n",
      "      n_iter=50, n_jobs=1, penalty=None, random_state=0, shuffle=True,\n",
      "      verbose=0, warm_start=False)\n",
      "train time: 0.166s\n",
      "test time:  0.000s\n",
      "accuracy:   0.897\n",
      "dimensionality: 300\n",
      "density: 1.000000\n",
      "top 10 keywords per class:\n",
      "alt.atheism: 034 06111 000100255pixel 041929 023b 0001 000062david42 0029 000...\n",
      "comp.graphics: 02115 0192 0988 0184 0049 001428 000100255pixel 01852 00048475...\n",
      "sci.space: 0971 000406 080719 020021 00196 0600 01854 0033 0004136 00000\n",
      "talk.religion.misc: 044958 024423 02142 00090711 070 0100 000 001757 0000 000...\n",
      "\n",
      "classification report:\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "       alt.atheism       0.83      0.87      0.85       319\n",
      "     comp.graphics       0.93      0.96      0.94       389\n",
      "         sci.space       0.94      0.95      0.95       394\n",
      "talk.religion.misc       0.86      0.75      0.80       251\n",
      "\n",
      "       avg / total       0.90      0.90      0.90      1353\n",
      "\n",
      "confusion matrix:\n",
      "[[278   5  11  25]\n",
      " [  5 373   6   5]\n",
      " [  2  17 374   1]\n",
      " [ 50   7   6 188]]\n",
      "\n",
      "================================================================================\n",
      "Passive-Aggressive\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "PassiveAggressiveClassifier(C=1.0, class_weight=None, fit_intercept=True,\n",
      "              loss='hinge', n_iter=50, n_jobs=1, random_state=None,\n",
      "              shuffle=True, verbose=0, warm_start=False)\n",
      "train time: 0.308s\n",
      "test time:  0.000s\n",
      "accuracy:   0.899\n",
      "dimensionality: 300\n",
      "density: 1.000000\n",
      "top 10 keywords per class:\n",
      "alt.atheism: 02139 0273 000100255pixel 023b 000062david42 041929 0001 0029 00...\n",
      "comp.graphics: 0034 0000vec 042918 000100255pixel 0x3d4 01852 0049 0184 00048...\n",
      "sci.space: 01463 01821 0600 000406 012536 00196 01854 0004136 0033 00000\n",
      "talk.religion.misc: 02142 044958 070 10012 00090711 0100 000 001757 0004246 0000\n",
      "\n",
      "classification report:\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "       alt.atheism       0.83      0.87      0.85       319\n",
      "     comp.graphics       0.94      0.96      0.95       389\n",
      "         sci.space       0.93      0.97      0.95       394\n",
      "talk.religion.misc       0.87      0.74      0.80       251\n",
      "\n",
      "       avg / total       0.90      0.90      0.90      1353\n",
      "\n",
      "confusion matrix:\n",
      "[[276   5  15  23]\n",
      " [  4 374   6   5]\n",
      " [  1  11 382   0]\n",
      " [ 52   6   8 185]]\n",
      "\n",
      "================================================================================\n",
      "kNN\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=10, p=2,\n",
      "           weights='uniform')\n",
      "train time: 0.016s\n",
      "test time:  1.678s\n",
      "accuracy:   0.857\n",
      "classification report:\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "       alt.atheism       0.77      0.90      0.83       319\n",
      "     comp.graphics       0.91      0.89      0.90       389\n",
      "         sci.space       0.90      0.92      0.91       394\n",
      "talk.religion.misc       0.84      0.66      0.74       251\n",
      "\n",
      "       avg / total       0.86      0.86      0.85      1353\n",
      "\n",
      "confusion matrix:\n",
      "[[286   2  13  18]\n",
      " [ 12 346  19  12]\n",
      " [  8  24 361   1]\n",
      " [ 66   9  10 166]]\n",
      "\n",
      "================================================================================\n",
      "Random forest\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=100, n_jobs=1, oob_score=False, random_state=None,\n",
      "            verbose=0, warm_start=False)\n",
      "train time: 1.990s\n",
      "test time:  0.063s\n",
      "accuracy:   0.874\n",
      "classification report:\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "       alt.atheism       0.79      0.87      0.83       319\n",
      "     comp.graphics       0.92      0.95      0.93       389\n",
      "         sci.space       0.90      0.93      0.92       394\n",
      "talk.religion.misc       0.87      0.67      0.76       251\n",
      "\n",
      "       avg / total       0.88      0.87      0.87      1353\n",
      "\n",
      "confusion matrix:\n",
      "[[279   8   9  23]\n",
      " [  2 368  17   2]\n",
      " [  8  18 368   0]\n",
      " [ 62   8  13 168]]\n",
      "\n",
      "================================================================================\n",
      "L2 penalty\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "LinearSVC(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='l2', max_iter=1000, multi_class='ovr',\n",
      "     penalty='l2', random_state=None, tol=0.001, verbose=0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pedro.castanha\\AppData\\Local\\Continuum\\Anaconda2\\lib\\site-packages\\sklearn\\svm\\classes.py:199: DeprecationWarning: loss='l2' has been deprecated in favor of loss='squared_hinge' as of 0.16. Backward compatibility for the loss='l2' will be removed in 1.0\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train time: 0.183s\n",
      "test time:  0.001s\n",
      "accuracy:   0.899\n",
      "dimensionality: 300\n",
      "density: 1.000000\n",
      "top 10 keywords per class:\n",
      "alt.atheism: 074 01a 001555 000062david42 000usd 0029 000100255pixel 0001 000...\n",
      "comp.graphics: 000062david42 011634edt 000100255pixel 0000vec 0039 01852 0184...\n",
      "sci.space: 001718 020021 0971 000005102000 000406 0033 00196 01854 0004136 00000\n",
      "talk.religion.misc: 013034 003719 024423 001757 0010580b 00090711 0100 000 00...\n",
      "\n",
      "classification report:\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "       alt.atheism       0.84      0.85      0.84       319\n",
      "     comp.graphics       0.95      0.96      0.96       389\n",
      "         sci.space       0.94      0.96      0.95       394\n",
      "talk.religion.misc       0.83      0.76      0.79       251\n",
      "\n",
      "       avg / total       0.90      0.90      0.90      1353\n",
      "\n",
      "confusion matrix:\n",
      "[[271   4  10  34]\n",
      " [  3 375   6   5]\n",
      " [  2  12 380   0]\n",
      " [ 47   5   9 190]]\n",
      "\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', n_iter=50, n_jobs=1,\n",
      "       penalty='l2', power_t=0.5, random_state=None, shuffle=True,\n",
      "       verbose=0, warm_start=False)\n",
      "train time: 0.165s\n",
      "test time:  0.000s\n",
      "accuracy:   0.902\n",
      "dimensionality: 300\n",
      "density: 1.000000\n",
      "top 10 keywords per class:\n",
      "alt.atheism: 06111 074 0029 000usd 000062david42 001555 000100255pixel 0001 0...\n",
      "comp.graphics: 0x3d4 000100255pixel 0022 0988 0049 0039 01852 0184 0004847546...\n",
      "sci.space: 012536 0600 001718 000005102000 000406 00196 0004136 01854 0033 00000\n",
      "talk.religion.misc: 013034 020751 001757 024423 00090711 0010580b 000 0100 00...\n",
      "\n",
      "classification report:\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "       alt.atheism       0.83      0.87      0.85       319\n",
      "     comp.graphics       0.95      0.95      0.95       389\n",
      "         sci.space       0.93      0.97      0.95       394\n",
      "talk.religion.misc       0.87      0.77      0.81       251\n",
      "\n",
      "       avg / total       0.90      0.90      0.90      1353\n",
      "\n",
      "confusion matrix:\n",
      "[[276   4  13  26]\n",
      " [  7 368  10   4]\n",
      " [  2   9 383   0]\n",
      " [ 46   5   7 193]]\n",
      "\n",
      "================================================================================\n",
      "L1 penalty\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "LinearSVC(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='l2', max_iter=1000, multi_class='ovr',\n",
      "     penalty='l1', random_state=None, tol=0.001, verbose=0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pedro.castanha\\AppData\\Local\\Continuum\\Anaconda2\\lib\\site-packages\\sklearn\\svm\\classes.py:199: DeprecationWarning: loss='l2' has been deprecated in favor of loss='squared_hinge' as of 0.16. Backward compatibility for the loss='l2' will be removed in 1.0\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train time: 0.496s\n",
      "test time:  0.000s\n",
      "accuracy:   0.894\n",
      "dimensionality: 300\n",
      "density: 0.474167\n",
      "top 10 keywords per class:\n",
      "alt.atheism: 0001 0029 034 0511 000usd 001555 000100255pixel 000005102000 000...\n",
      "comp.graphics: 020259 0005 011634edt 0018 01852 0184 0049 0000vec 0004847546 ...\n",
      "sci.space: 020021 0971 090 01821 000406 0004136 00196 0033 01854 00000\n",
      "talk.religion.misc: 020751 003719 070 02142 053250 001757 000 0100 0004246 0000\n",
      "\n",
      "classification report:\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "       alt.atheism       0.85      0.84      0.84       319\n",
      "     comp.graphics       0.94      0.95      0.95       389\n",
      "         sci.space       0.92      0.97      0.95       394\n",
      "talk.religion.misc       0.82      0.76      0.79       251\n",
      "\n",
      "       avg / total       0.89      0.89      0.89      1353\n",
      "\n",
      "confusion matrix:\n",
      "[[267   4  11  37]\n",
      " [  3 370  11   5]\n",
      " [  0  12 382   0]\n",
      " [ 45   6   9 191]]\n",
      "\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', n_iter=50, n_jobs=1,\n",
      "       penalty='l1', power_t=0.5, random_state=None, shuffle=True,\n",
      "       verbose=0, warm_start=False)\n",
      "train time: 0.435s\n",
      "test time:  0.000s\n",
      "accuracy:   0.897\n",
      "dimensionality: 300\n",
      "density: 0.520000\n",
      "top 10 keywords per class:\n",
      "alt.atheism: 023b 06111 034 0511 0001 0029 000100255pixel 000062david42 00000...\n",
      "comp.graphics: 0018 000100255pixel 0005 0184 02115 0049 0988 0034 0004847546 ...\n",
      "sci.space: 0004422 0028 080719 000406 001718 00196 01854 0004136 0033 00000\n",
      "talk.religion.misc: 044958 05 02142 00090711 020751 0100 000 001757 0000 0004246\n",
      "\n",
      "classification report:\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "       alt.atheism       0.83      0.85      0.84       319\n",
      "     comp.graphics       0.95      0.95      0.95       389\n",
      "         sci.space       0.93      0.97      0.95       394\n",
      "talk.religion.misc       0.83      0.75      0.79       251\n",
      "\n",
      "       avg / total       0.90      0.90      0.90      1353\n",
      "\n",
      "confusion matrix:\n",
      "[[272   4   9  34]\n",
      " [  3 370  12   4]\n",
      " [  1  10 383   0]\n",
      " [ 50   5   8 188]]\n",
      "\n",
      "================================================================================\n",
      "Elastic-Net penalty\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', n_iter=50, n_jobs=1,\n",
      "       penalty='elasticnet', power_t=0.5, random_state=None, shuffle=True,\n",
      "       verbose=0, warm_start=False)\n",
      "train time: 0.480s\n",
      "test time:  0.000s\n",
      "accuracy:   0.901\n",
      "dimensionality: 300\n",
      "density: 0.894167\n",
      "top 10 keywords per class:\n",
      "alt.atheism: 074 06111 000062david42 0029 000usd 001555 000100255pixel 0001 0...\n",
      "comp.graphics: 0179 0034 0988 0x3d4 0039 0049 01852 0184 0004847546 000000\n",
      "sci.space: 020021 0971 0600 012536 000406 00196 0004136 01854 0033 00000\n",
      "talk.religion.misc: 020751 013034 00090711 001757 024423 0010580b 000 0100 00...\n",
      "\n",
      "classification report:\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "       alt.atheism       0.84      0.85      0.85       319\n",
      "     comp.graphics       0.95      0.96      0.95       389\n",
      "         sci.space       0.94      0.97      0.95       394\n",
      "talk.religion.misc       0.84      0.77      0.80       251\n",
      "\n",
      "       avg / total       0.90      0.90      0.90      1353\n",
      "\n",
      "confusion matrix:\n",
      "[[271   4  12  32]\n",
      " [  3 374   7   5]\n",
      " [  2  11 381   0]\n",
      " [ 45   6   7 193]]\n",
      "\n",
      "================================================================================\n",
      "NearestCentroid (aka Rocchio classifier)\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "NearestCentroid(metric='euclidean', shrink_threshold=None)\n",
      "train time: 0.000s\n",
      "test time:  0.000s\n",
      "accuracy:   0.868\n",
      "classification report:\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "       alt.atheism       0.83      0.75      0.79       319\n",
      "     comp.graphics       0.93      0.95      0.94       389\n",
      "         sci.space       0.94      0.94      0.94       394\n",
      "talk.religion.misc       0.72      0.78      0.75       251\n",
      "\n",
      "       avg / total       0.87      0.87      0.87      1353\n",
      "\n",
      "confusion matrix:\n",
      "[[238   6   6  69]\n",
      " [  4 368  11   6]\n",
      " [  2  17 372   3]\n",
      " [ 42   5   7 197]]\n",
      "\n",
      "================================================================================\n",
      "Naive Bayes\n",
      "================================================================================\n",
      "LinearSVC with L1-based feature selection\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "Pipeline(steps=[('feature_selection', LinearSVC(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l1', random_state=None, tol=0.001,\n",
      "     verbose=0)), ('classification', LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
      "     verbose=0))])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pedro.castanha\\AppData\\Local\\Continuum\\Anaconda2\\lib\\site-packages\\sklearn\\utils\\deprecation.py:70: DeprecationWarning: Function transform is deprecated; Support to use estimators as feature selectors will be removed in version 0.19. Use SelectFromModel instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "C:\\Users\\pedro.castanha\\AppData\\Local\\Continuum\\Anaconda2\\lib\\site-packages\\sklearn\\utils\\deprecation.py:70: DeprecationWarning: Function transform is deprecated; Support to use estimators as feature selectors will be removed in version 0.19. Use SelectFromModel instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train time: 0.606s\n",
      "test time:  0.000s\n",
      "accuracy:   0.899\n",
      "classification report:\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "       alt.atheism       0.84      0.85      0.84       319\n",
      "     comp.graphics       0.95      0.96      0.96       389\n",
      "         sci.space       0.94      0.96      0.95       394\n",
      "talk.religion.misc       0.83      0.76      0.79       251\n",
      "\n",
      "       avg / total       0.90      0.90      0.90      1353\n",
      "\n",
      "confusion matrix:\n",
      "[[271   4  10  34]\n",
      " [  3 375   6   5]\n",
      " [  2  12 380   0]\n",
      " [ 48   4   9 190]]\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAuMAAAI1CAYAAAB8GvSWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nMC5JkiT1xDAuSZIk9eT/A/vwE1eq1PObAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x114cdb38>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def benchmark(clf):\n",
    "    print('_' * 80)\n",
    "    print(\"Training: \")\n",
    "    print(clf)\n",
    "    t0 = time()\n",
    "    clf.fit(X_train, y_train)\n",
    "    #clf.fit(x_train, y_train)\n",
    "    train_time = time() - t0\n",
    "    print(\"train time: %0.3fs\" % train_time)\n",
    "\n",
    "    t0 = time()\n",
    "    pred = clf.predict(X_test)\n",
    "    #pred = clf.predict(x_test)\n",
    "    test_time = time() - t0\n",
    "    print(\"test time:  %0.3fs\" % test_time)\n",
    "\n",
    "    score = metrics.accuracy_score(y_test, pred)\n",
    "    print(\"accuracy:   %0.3f\" % score)\n",
    "\n",
    "    if hasattr(clf, 'coef_'):\n",
    "        print(\"dimensionality: %d\" % clf.coef_.shape[1])\n",
    "        print(\"density: %f\" % density(clf.coef_))\n",
    "\n",
    "        if True and feature_names is not None:\n",
    "        #if True and names is not None:\n",
    "            print(\"top 10 keywords per class:\")\n",
    "            for i, label in enumerate(target_names):\n",
    "            #for i, label in enumerate(labels):\n",
    "                top10 = np.argsort(clf.coef_[i])[-10:]\n",
    "                print(trim(\"%s: %s\" % (label, \" \".join(feature_names[top10]))))\n",
    "                #print(trim(\"%s: %s\" % (label, \" \".join(names[top10]))))\n",
    "        print()\n",
    "\n",
    "    if True:\n",
    "        print(\"classification report:\")\n",
    "        print(metrics.classification_report(y_test, pred,\n",
    "                                            target_names=target_names))\n",
    "\n",
    "    if True:\n",
    "        print(\"confusion matrix:\")\n",
    "        print(metrics.confusion_matrix(y_test, pred))\n",
    "\n",
    "    print()\n",
    "    clf_descr = str(clf).split('(')[0]\n",
    "    return clf_descr, score, train_time, test_time\n",
    "\n",
    "\n",
    "results = []\n",
    "for clf, name in (\n",
    "        (RidgeClassifier(tol=1e-2, solver=\"lsqr\"), \"Ridge Classifier\"),\n",
    "        (Perceptron(n_iter=50), \"Perceptron\"),\n",
    "        (PassiveAggressiveClassifier(n_iter=50), \"Passive-Aggressive\"),\n",
    "        (KNeighborsClassifier(n_neighbors=10), \"kNN\"),\n",
    "        (RandomForestClassifier(n_estimators=100), \"Random forest\")):\n",
    "    print('=' * 80)\n",
    "    print(name)\n",
    "    results.append(benchmark(clf))\n",
    "\n",
    "for penalty in [\"l2\", \"l1\"]:\n",
    "    print('=' * 80)\n",
    "    print(\"%s penalty\" % penalty.upper())\n",
    "    # Train Liblinear model\n",
    "    results.append(benchmark(LinearSVC(loss='l2', penalty=penalty,\n",
    "                                            dual=False, tol=1e-3)))\n",
    "\n",
    "    # Train SGD model\n",
    "    results.append(benchmark(SGDClassifier(alpha=.0001, n_iter=50,\n",
    "                                           penalty=penalty)))\n",
    "\n",
    "# Train SGD with Elastic Net penalty\n",
    "print('=' * 80)\n",
    "print(\"Elastic-Net penalty\")\n",
    "#results.append(benchmark(SGDClassifier(alpha=.0001, n_iter=50,\n",
    "#                                       penalty=\"elasticnet\")))\n",
    "\n",
    "# 'alpha': 0.000868511373751352, 'l1_ratio': 0.0035564803062231283\n",
    "results.append(benchmark(SGDClassifier(alpha=0.000868511373751352, n_iter=50,\n",
    "                                       l1_ratio=0.0035564803062231283, penalty=\"elasticnet\")))\n",
    "\n",
    "# Train NearestCentroid without threshold\n",
    "print('=' * 80)\n",
    "print(\"NearestCentroid (aka Rocchio classifier)\")\n",
    "results.append(benchmark(NearestCentroid()))\n",
    "\n",
    "# Train sparse Naive Bayes classifiers\n",
    "print('=' * 80)\n",
    "print(\"Naive Bayes\")\n",
    "#results.append(benchmark(MultinomialNB(alpha=.01)))\n",
    "#results.append(benchmark(BernoulliNB(alpha=.01)))\n",
    "\n",
    "print('=' * 80)\n",
    "print(\"LinearSVC with L1-based feature selection\")\n",
    "# The smaller C, the stronger the regularization.\n",
    "# The more regularization, the more sparsity.\n",
    "results.append(benchmark(Pipeline([\n",
    "  ('feature_selection', LinearSVC(penalty=\"l1\", dual=False, tol=1e-3)),\n",
    "  ('classification', LinearSVC())\n",
    "])))\n",
    "\n",
    "# make some plots\n",
    "\n",
    "indices = np.arange(len(results))\n",
    "\n",
    "results = [[x[i] for x in results] for i in range(4)]\n",
    "\n",
    "clf_names, score, training_time, test_time = results\n",
    "training_time = np.array(training_time) / np.max(training_time)\n",
    "test_time = np.array(test_time) / np.max(test_time)\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.title(\"Score\")\n",
    "plt.barh(indices, score, .2, label=\"score\", color='navy')\n",
    "plt.barh(indices + .3, training_time, .2, label=\"training time\",\n",
    "         color='c')\n",
    "plt.barh(indices + .6, test_time, .2, label=\"test time\", color='darkorange')\n",
    "plt.yticks(())\n",
    "plt.legend(loc='best')\n",
    "plt.subplots_adjust(left=.25)\n",
    "plt.subplots_adjust(top=.95)\n",
    "plt.subplots_adjust(bottom=.05)\n",
    "\n",
    "for i, c in zip(indices, clf_names):\n",
    "    plt.text(-.3, i, c)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "      Fatos       0.73      0.68      0.70        47\n",
      "     Normas       0.70      0.72      0.71        43\n",
      " Argumentos       0.43      0.52      0.47        44\n",
      "    Pedidos       0.55      0.71      0.62        34\n",
      "Irrelevante       0.76      0.60      0.67        85\n",
      "\n",
      "avg / total       0.66      0.64      0.64       253\n",
      "\n",
      "Fatos: n ru reclamante anexo qualquer 00 data imvel conforme requerente\n",
      "Normas: ser qualquer atos ato processual processo iii lei ii art\n",
      "Argumentos: protesto ru r razo requerente requerida imvel assim autor ser\n",
      "Pedidos: advocatcios custas bem 20 honorrios juros processuais pagamento co...\n",
      "Irrelevante: tutela direito contrato moral mais posse exposto dano ao pedido\n"
     ]
    }
   ],
   "source": [
    "raw_data = pd.read_csv('C:\\Users\\pedro.castanha\\Downloads\\ML_Gabinete_Digital.csv', error_bad_lines=False, sep='\\t', encoding='utf_8')\n",
    "words = pd.read_table('C:\\Users\\pedro.castanha\\Downloads\\stoplists\\stopwords_pt_br.txt', encoding='mbcs')\n",
    "\n",
    "stopwords = words.values.T.tolist()[0]\n",
    "\n",
    "x_vectorized = TfidfVectorizer(sublinear_tf=True, max_df=0.5, stop_words=stopwords)\n",
    "x_vectorized.fit(raw_data.Text)\n",
    "x_train = x_vectorized.transform(raw_data.Text)\n",
    "y_train = raw_data.Class\n",
    "\n",
    "names = np.asarray(x_vectorized.get_feature_names())\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_train, y_train, test_size=0.4, random_state=42)\n",
    "\n",
    "clf = MultinomialNB(alpha=.01)\n",
    "clf.fit(x_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(x_test)\n",
    "\n",
    "print(metrics.classification_report(y_test, y_pred, target_names=labels))\n",
    "\n",
    "for i, label in enumerate(labels):\n",
    "    top10 = np.argsort(clf.coef_[i])[-10:]\n",
    "    print(trim(\"%s: %s\" % (label, \" \".join(names[top10]))))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
