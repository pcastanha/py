{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from __future__ import print_function\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn.model_selection import validation_curve\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.model_selection import ShuffleSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('C:\\Pedro\\workspace\\Acc-challenge\\data.csv')\n",
    "train = train.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "timezone_mapping = dict(zip(sorted(train['Timezone'].unique()), range(0, len(sorted(train['Timezone'].unique())) + 1)))\n",
    "fixture_mapping = dict(zip(sorted(train['FixtureDate'].unique()), range(0, len(sorted(train['FixtureDate'].unique())) + 1)))\n",
    "hteam_mapping = dict(zip(sorted(train['HomeTeam'].unique()), range(0, len(sorted(train['HomeTeam'].unique())) + 1)))\n",
    "ateam_mapping = dict(zip(sorted(train['AwayTeam'].unique()), range(0, len(sorted(train['AwayTeam'].unique())) + 1)))\n",
    "team_mapping = dict(zip(sorted(train['Team'].unique()), range(0, len(sorted(train['Team'].unique())) + 1)))\n",
    "atype_mapping = dict(zip(sorted(train['ActionTypeDesc'].unique()), range(0, len(sorted(train['ActionTypeDesc'].unique())) + 1)))\n",
    "res_mapping = dict(zip(sorted(train['ActionResultDesc'].unique()), range(0, len(sorted(train['ActionResultDesc'].unique())) + 1)))\n",
    "start_mapping = dict(zip(sorted(train['StartingPositionDesc'].unique()), range(0, len(sorted(train['StartingPositionDesc'].unique())) + 1)))\n",
    "end_mapping = dict(zip(sorted(train['EndPositionDesc'].unique()), range(0, len(sorted(train['EndPositionDesc'].unique())) + 1)))\n",
    "\n",
    "train['Timezone_Val'] = train['Timezone'].map(timezone_mapping).astype(int)\n",
    "train['Fixture_Val'] = train['FixtureDate'].map(fixture_mapping).astype(int)\n",
    "train['Hteam_Val'] = train['HomeTeam'].map(hteam_mapping).astype(int)\n",
    "train['Ateam_Val'] = train['AwayTeam'].map(ateam_mapping).astype(int)\n",
    "train['Team_Val'] = train['Team'].map(team_mapping).astype(int)\n",
    "train['Atype_Val'] = train['ActionTypeDesc'].map(atype_mapping).astype(int)\n",
    "train['Start_Val'] = train['StartingPositionDesc'].map(start_mapping).astype(int)\n",
    "train['End_Val'] = train['EndPositionDesc'].map(end_mapping).astype(int)\n",
    "train['Res_Val'] = train['ActionResultDesc'].map(res_mapping).astype(int)\n",
    "\n",
    "train_test = train.drop(['LineOutAttackers','FixtureDate','StadiumName','KickOffTime_GMT','Timezone','KickOffTime_Local','HomeTeam',\n",
    "                        'AwayTeam','Team','ActionTypeDesc','ActionResultDesc','StartingPositionDesc',\n",
    "                        'EndPositionDesc','PlayDirection','City','Icon','Summary','ZoneDescription','CloudCover','Pressure'],\n",
    "                        axis=1)\n",
    "\n",
    "#train_features = train_test.values[:, 1:48]\n",
    "#train_features = train_test.iloc[:,[10,11,17,12,35,34,6,8,5,9]].values\n",
    "train_features = train_test.iloc[:,[10,11,15,34,6]].values\n",
    "train_target = train_test['Res_Val'].values[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(train_features, train_target, test_size=0.5, random_state=0)\n",
    "\n",
    "# Set the parameters by cross-validation\n",
    "tuned_parameters = [{'kernel': ['rbf'], 'gamma': [1e-3, 1e-4], 'C': [1, 10, 100, 1000]}, \n",
    "                        {'kernel': ['linear'], 'C': [1, 10, 100, 1000]}]\n",
    "\n",
    "scores = ['precision', 'recall']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for precision\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files (x86)\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "\n",
      "{'kernel': 'linear', 'C': 1}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.383 (+/-0.004) for {'kernel': 'rbf', 'C': 1, 'gamma': 0.001}\n",
      "0.535 (+/-0.403) for {'kernel': 'rbf', 'C': 1, 'gamma': 0.0001}\n",
      "0.383 (+/-0.004) for {'kernel': 'rbf', 'C': 10, 'gamma': 0.001}\n",
      "0.467 (+/-0.159) for {'kernel': 'rbf', 'C': 10, 'gamma': 0.0001}\n",
      "0.383 (+/-0.004) for {'kernel': 'rbf', 'C': 100, 'gamma': 0.001}\n",
      "0.467 (+/-0.159) for {'kernel': 'rbf', 'C': 100, 'gamma': 0.0001}\n",
      "0.383 (+/-0.004) for {'kernel': 'rbf', 'C': 1000, 'gamma': 0.001}\n",
      "0.467 (+/-0.159) for {'kernel': 'rbf', 'C': 1000, 'gamma': 0.0001}\n",
      "1.000 (+/-0.000) for {'kernel': 'linear', 'C': 1}\n",
      "1.000 (+/-0.000) for {'kernel': 'linear', 'C': 10}\n",
      "1.000 (+/-0.000) for {'kernel': 'linear', 'C': 100}\n",
      "1.000 (+/-0.000) for {'kernel': 'linear', 'C': 1000}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00       290\n",
      "          1       1.00      1.00      1.00       107\n",
      "\n",
      "avg / total       1.00      1.00      1.00       397\n",
      "\n",
      "\n",
      "# Tuning hyper-parameters for recall\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'kernel': 'linear', 'C': 1}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.500 (+/-0.000) for {'kernel': 'rbf', 'C': 1, 'gamma': 0.001}\n",
      "0.507 (+/-0.026) for {'kernel': 'rbf', 'C': 1, 'gamma': 0.0001}\n",
      "0.500 (+/-0.000) for {'kernel': 'rbf', 'C': 10, 'gamma': 0.001}\n",
      "0.487 (+/-0.048) for {'kernel': 'rbf', 'C': 10, 'gamma': 0.0001}\n",
      "0.500 (+/-0.000) for {'kernel': 'rbf', 'C': 100, 'gamma': 0.001}\n",
      "0.487 (+/-0.048) for {'kernel': 'rbf', 'C': 100, 'gamma': 0.0001}\n",
      "0.500 (+/-0.000) for {'kernel': 'rbf', 'C': 1000, 'gamma': 0.001}\n",
      "0.487 (+/-0.048) for {'kernel': 'rbf', 'C': 1000, 'gamma': 0.0001}\n",
      "1.000 (+/-0.000) for {'kernel': 'linear', 'C': 1}\n",
      "1.000 (+/-0.000) for {'kernel': 'linear', 'C': 10}\n",
      "1.000 (+/-0.000) for {'kernel': 'linear', 'C': 100}\n",
      "1.000 (+/-0.000) for {'kernel': 'linear', 'C': 1000}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00       290\n",
      "          1       1.00      1.00      1.00       107\n",
      "\n",
      "avg / total       1.00      1.00      1.00       397\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for score in scores:\n",
    "    print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "    print()\n",
    "\n",
    "    clf = GridSearchCV(SVC(C=1), tuned_parameters, cv=5, scoring='%s_macro' % score)\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    print(\"Best parameters set found on development set:\")\n",
    "    print()\n",
    "    print(clf.best_params_)\n",
    "    print()\n",
    "    print(\"Grid scores on development set:\")\n",
    "    print()\n",
    "    means = clf.cv_results_['mean_test_score']\n",
    "    stds = clf.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\" % (mean, std * 2, params))\n",
    "    print()\n",
    "\n",
    "    print(\"Detailed classification report:\")\n",
    "    print()\n",
    "    print(\"The model is trained on the full development set.\")\n",
    "    print(\"The scores are computed on the full evaluation set.\")\n",
    "    print()\n",
    "    y_true, y_pred = y_test, clf.predict(X_test)\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "X, y = train_features, train_target\n",
    "indices = np.arange(y.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "X, y = X[indices], y[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train scores \n",
      "\n",
      " [[ 0.74789916  0.74789916  0.74789916  0.75490196  0.74825175  0.74825175\n",
      "   0.74825175  0.74825175  0.74825175  0.74825175]\n",
      " [ 0.75210084  0.74789916  0.74929972  0.75490196  0.74825175  0.74825175\n",
      "   0.74825175  0.75244755  0.74825175  0.75384615]\n",
      " [ 0.76610644  0.76890756  0.76470588  0.76330532  0.74965035  0.75664336\n",
      "   0.75944056  0.76083916  0.75664336  0.76363636]\n",
      " [ 0.78291317  0.77731092  0.78291317  0.78851541  0.77762238  0.78321678\n",
      "   0.78321678  0.77902098  0.77762238  0.78181818]\n",
      " [ 0.81092437  0.83333333  0.80952381  0.82773109  0.81258741  0.81818182\n",
      "   0.81538462  0.82377622  0.81118881  0.81118881]\n",
      " [ 0.8767507   0.88795518  0.87955182  0.89355742  0.88811189  0.88111888\n",
      "   0.88811189  0.8951049   0.88111888  0.88391608]\n",
      " [ 0.96078431  0.95518207  0.95238095  0.95938375  0.95524476  0.95664336\n",
      "   0.95664336  0.96223776  0.96083916  0.95664336]\n",
      " [ 0.99019608  0.9929972   0.99159664  0.9929972   0.99020979  0.99020979\n",
      "   0.99020979  0.99300699  0.98881119  0.99160839]\n",
      " [ 0.99859944  0.99859944  1.          1.          0.9986014   0.9986014\n",
      "   0.9986014   0.9986014   0.9986014   0.9986014 ]\n",
      " [ 1.          1.          1.          1.          1.          1.          1.\n",
      "   1.          1.          1.        ]\n",
      " [ 1.          1.          1.          1.          1.          1.          1.\n",
      "   1.          1.          1.        ]\n",
      " [ 1.          1.          1.          1.          1.          1.          1.\n",
      "   1.          1.          1.        ]\n",
      " [ 1.          1.          1.          1.          1.          1.          1.\n",
      "   1.          1.          1.        ]\n",
      " [ 1.          1.          1.          1.          1.          1.          1.\n",
      "   1.          1.          1.        ]\n",
      " [ 1.          1.          1.          1.          1.          1.          1.\n",
      "   1.          1.          1.        ]] \n",
      "\n",
      "Valid scores \n",
      "\n",
      " [[ 0.75        0.75        0.75        0.725       0.74683544  0.74683544\n",
      "   0.74683544  0.74683544  0.74683544  0.74683544]\n",
      " [ 0.75        0.75        0.75        0.725       0.74683544  0.74683544\n",
      "   0.74683544  0.73417722  0.74683544  0.74683544]\n",
      " [ 0.7125      0.7         0.7125      0.7375      0.75949367  0.74683544\n",
      "   0.74683544  0.72151899  0.74683544  0.74683544]\n",
      " [ 0.6875      0.6875      0.7125      0.7375      0.75949367  0.74683544\n",
      "   0.72151899  0.72151899  0.74683544  0.74683544]\n",
      " [ 0.7125      0.725       0.725       0.6875      0.73417722  0.73417722\n",
      "   0.74683544  0.72151899  0.73417722  0.73417722]\n",
      " [ 0.7375      0.725       0.7375      0.7125      0.73417722  0.73417722\n",
      "   0.74683544  0.72151899  0.73417722  0.69620253]\n",
      " [ 0.725       0.75        0.75        0.725       0.74683544  0.74683544\n",
      "   0.74683544  0.72151899  0.74683544  0.72151899]\n",
      " [ 0.75        0.75        0.75        0.725       0.74683544  0.74683544\n",
      "   0.74683544  0.74683544  0.74683544  0.74683544]\n",
      " [ 0.75        0.75        0.75        0.75        0.74683544  0.74683544\n",
      "   0.74683544  0.74683544  0.74683544  0.74683544]\n",
      " [ 0.75        0.75        0.75        0.75        0.74683544  0.74683544\n",
      "   0.74683544  0.74683544  0.74683544  0.74683544]\n",
      " [ 0.75        0.75        0.75        0.75        0.74683544  0.74683544\n",
      "   0.74683544  0.74683544  0.74683544  0.74683544]\n",
      " [ 0.75        0.75        0.75        0.75        0.74683544  0.74683544\n",
      "   0.74683544  0.74683544  0.74683544  0.74683544]\n",
      " [ 0.75        0.75        0.75        0.75        0.74683544  0.74683544\n",
      "   0.74683544  0.74683544  0.74683544  0.74683544]\n",
      " [ 0.75        0.75        0.75        0.75        0.74683544  0.74683544\n",
      "   0.74683544  0.74683544  0.74683544  0.74683544]\n",
      " [ 0.75        0.75        0.75        0.75        0.74683544  0.74683544\n",
      "   0.74683544  0.74683544  0.74683544  0.74683544]]\n"
     ]
    }
   ],
   "source": [
    "param_range = np.logspace(-6, -1, 15)\n",
    "train_scores, test_scores = validation_curve(SVC(), X, y, param_name=\"gamma\", param_range=param_range,\n",
    "                                             cv=10, scoring=\"accuracy\", n_jobs=1)\n",
    "train_scores_mean = np.mean(train_scores, axis=1)\n",
    "train_scores_std = np.std(train_scores, axis=1)\n",
    "test_scores_mean = np.mean(test_scores, axis=1)\n",
    "test_scores_std = np.std(test_scores, axis=1)\n",
    "\n",
    "print(\"Train scores \\n\\n %s \\n\" % train_scores)\n",
    "print(\"Valid scores \\n\\n %s\" % test_scores)\n",
    "\n",
    "plt.title(\"Validation Curve with SVM\")\n",
    "plt.xlabel(\"$\\gamma$\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.ylim(0.0, 1.1)\n",
    "lw = 2\n",
    "plt.semilogx(param_range, train_scores_mean, label=\"Training score\",\n",
    "             color=\"darkorange\", lw=lw)\n",
    "plt.fill_between(param_range, train_scores_mean - train_scores_std,\n",
    "                 train_scores_mean + train_scores_std, alpha=0.2,\n",
    "                 color=\"darkorange\", lw=lw)\n",
    "plt.semilogx(param_range, test_scores_mean, label=\"Cross-validation score\",\n",
    "             color=\"navy\", lw=lw)\n",
    "plt.fill_between(param_range, test_scores_mean - test_scores_std,\n",
    "                 test_scores_mean + test_scores_std, alpha=0.2,\n",
    "                 color=\"navy\", lw=lw)\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train scores \n",
      "\n",
      " [[ 0.74789916  0.74789916  0.74789916  0.74789916  0.74825175  0.74825175\n",
      "   0.74825175  0.74825175  0.74825175  0.74825175]\n",
      " [ 0.74789916  0.74789916  0.74789916  0.74789916  0.74825175  0.74825175\n",
      "   0.74825175  0.74825175  0.74825175  0.74825175]\n",
      " [ 0.74789916  0.74789916  0.74789916  0.74789916  0.74825175  0.74825175\n",
      "   0.74825175  0.74825175  0.74825175  0.74825175]\n",
      " [ 0.74789916  0.74789916  0.74789916  0.74789916  0.74825175  0.74825175\n",
      "   0.74825175  0.74825175  0.74825175  0.74825175]\n",
      " [ 0.74789916  0.74789916  0.74789916  0.74789916  0.74825175  0.74825175\n",
      "   0.74825175  0.74825175  0.74825175  0.74825175]\n",
      " [ 0.74789916  0.74789916  0.74789916  0.74789916  0.74825175  0.74825175\n",
      "   0.74825175  0.74825175  0.74825175  0.74825175]\n",
      " [ 0.74789916  0.74789916  0.74789916  0.74789916  0.74825175  0.74825175\n",
      "   0.74825175  0.74825175  0.74825175  0.74825175]\n",
      " [ 0.74789916  0.74789916  0.74789916  0.74789916  0.74825175  0.74825175\n",
      "   0.74825175  0.74825175  0.74825175  0.74825175]\n",
      " [ 0.98459384  0.95238095  0.96498599  0.97478992  0.95944056  0.97482517\n",
      "   0.97202797  0.94965035  0.97902098  0.96083916]\n",
      " [ 1.          1.          1.          1.          1.          1.          1.\n",
      "   1.          1.          1.        ]\n",
      " [ 1.          1.          1.          1.          1.          1.          1.\n",
      "   1.          1.          1.        ]\n",
      " [ 1.          1.          1.          1.          1.          1.          1.\n",
      "   1.          1.          1.        ]\n",
      " [ 1.          1.          1.          1.          1.          1.          1.\n",
      "   1.          1.          1.        ]\n",
      " [ 0.99859944  0.99859944  1.          1.          1.          1.          1.\n",
      "   1.          1.          1.        ]\n",
      " [ 1.          1.          1.          1.          1.          1.          1.\n",
      "   0.9986014   1.          1.        ]] \n",
      "\n",
      "Valid scores \n",
      "\n",
      " [[ 0.75        0.75        0.75        0.75        0.74683544  0.74683544\n",
      "   0.74683544  0.74683544  0.74683544  0.74683544]\n",
      " [ 0.75        0.75        0.75        0.75        0.74683544  0.74683544\n",
      "   0.74683544  0.74683544  0.74683544  0.74683544]\n",
      " [ 0.75        0.75        0.75        0.75        0.74683544  0.74683544\n",
      "   0.74683544  0.74683544  0.74683544  0.74683544]\n",
      " [ 0.75        0.75        0.75        0.75        0.74683544  0.74683544\n",
      "   0.74683544  0.74683544  0.74683544  0.74683544]\n",
      " [ 0.75        0.75        0.75        0.75        0.74683544  0.74683544\n",
      "   0.74683544  0.74683544  0.74683544  0.74683544]\n",
      " [ 0.75        0.75        0.75        0.75        0.74683544  0.74683544\n",
      "   0.74683544  0.74683544  0.74683544  0.74683544]\n",
      " [ 0.75        0.75        0.75        0.75        0.74683544  0.74683544\n",
      "   0.74683544  0.74683544  0.74683544  0.74683544]\n",
      " [ 0.75        0.75        0.75        0.75        0.74683544  0.74683544\n",
      "   0.74683544  0.74683544  0.74683544  0.74683544]\n",
      " [ 0.95        0.9375      0.9625      1.          0.96202532  0.97468354\n",
      "   0.96202532  0.96202532  0.98734177  0.93670886]\n",
      " [ 1.          1.          1.          1.          1.          1.          1.\n",
      "   1.          1.          1.        ]\n",
      " [ 1.          1.          1.          1.          1.          1.          1.\n",
      "   1.          1.          1.        ]\n",
      " [ 1.          1.          1.          1.          1.          1.          1.\n",
      "   1.          1.          0.98734177]\n",
      " [ 0.9875      1.          0.9875      0.9875      1.          1.\n",
      "   0.97468354  0.98734177  1.          0.98734177]\n",
      " [ 0.925       0.9875      0.9875      0.9875      0.98734177  1.\n",
      "   0.92405063  0.98734177  0.97468354  0.97468354]\n",
      " [ 0.8         0.8875      0.875       0.8875      0.87341772  0.89873418\n",
      "   0.84810127  0.84810127  0.92405063  0.87341772]]\n"
     ]
    }
   ],
   "source": [
    "#Testing cv set with normalized data\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X)\n",
    "X_normalized = scaler.transform(X)\n",
    "#X_test = scaler.transform(X)  # apply same transformation to test data\n",
    "\n",
    "param_range = np.logspace(-6, -1, 15)\n",
    "train_scores, test_scores = validation_curve(SVC(C=1), X_normalized, y, param_name=\"gamma\", param_range=param_range,\n",
    "                                             cv=10, scoring=\"accuracy\", n_jobs=1)\n",
    "train_scores_mean = np.mean(train_scores, axis=1)\n",
    "train_scores_std = np.std(train_scores, axis=1)\n",
    "test_scores_mean = np.mean(test_scores, axis=1)\n",
    "test_scores_std = np.std(test_scores, axis=1)\n",
    "\n",
    "print(\"Train scores \\n\\n %s \\n\" % train_scores)\n",
    "print(\"Valid scores \\n\\n %s\" % test_scores)\n",
    "\n",
    "plt.title(\"Validation Curve with SVM\")\n",
    "plt.xlabel(\"$\\gamma$\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.ylim(0.0, 1.1)\n",
    "lw = 2\n",
    "plt.semilogx(param_range, train_scores_mean, label=\"Training score\",\n",
    "             color=\"darkorange\", lw=lw)\n",
    "plt.fill_between(param_range, train_scores_mean - train_scores_std,\n",
    "                 train_scores_mean + train_scores_std, alpha=0.2,\n",
    "                 color=\"darkorange\", lw=lw)\n",
    "plt.semilogx(param_range, test_scores_mean, label=\"Cross-validation score\",\n",
    "             color=\"navy\", lw=lw)\n",
    "plt.fill_between(param_range, test_scores_mean - test_scores_std,\n",
    "                 test_scores_mean + test_scores_std, alpha=0.2,\n",
    "                 color=\"navy\", lw=lw)\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_learning_curve(estimator, title, X, y, ylim=None, cv=None,\n",
    "                        n_jobs=1, train_sizes=np.linspace(.1, 1.0, 5)):\n",
    "    \"\"\"\n",
    "    Generate a simple plot of the test and training learning curve.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    estimator : object type that implements the \"fit\" and \"predict\" methods\n",
    "        An object of that type which is cloned for each validation.\n",
    "\n",
    "    title : string\n",
    "        Title for the chart.\n",
    "\n",
    "    X : array-like, shape (n_samples, n_features)\n",
    "        Training vector, where n_samples is the number of samples and\n",
    "        n_features is the number of features.\n",
    "\n",
    "    y : array-like, shape (n_samples) or (n_samples, n_features), optional\n",
    "        Target relative to X for classification or regression;\n",
    "        None for unsupervised learning.\n",
    "\n",
    "    ylim : tuple, shape (ymin, ymax), optional\n",
    "        Defines minimum and maximum yvalues plotted.\n",
    "\n",
    "    cv : int, cross-validation generator or an iterable, optional\n",
    "        Determines the cross-validation splitting strategy.\n",
    "        Possible inputs for cv are:\n",
    "          - None, to use the default 3-fold cross-validation,\n",
    "          - integer, to specify the number of folds.\n",
    "          - An object to be used as a cross-validation generator.\n",
    "          - An iterable yielding train/test splits.\n",
    "\n",
    "        For integer/None inputs, if ``y`` is binary or multiclass,\n",
    "        :class:`StratifiedKFold` used. If the estimator is not a classifier\n",
    "        or if ``y`` is neither binary nor multiclass, :class:`KFold` is used.\n",
    "\n",
    "        Refer :ref:`User Guide <cross_validation>` for the various\n",
    "        cross-validators that can be used here.\n",
    "\n",
    "    n_jobs : integer, optional\n",
    "        Number of jobs to run in parallel (default 1).\n",
    "    \"\"\"\n",
    "    plt.figure()\n",
    "    plt.title(title)\n",
    "    if ylim is not None:\n",
    "        plt.ylim(*ylim)\n",
    "    plt.xlabel(\"Training examples\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    train_sizes, train_scores, test_scores = learning_curve(\n",
    "        estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes)\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    plt.grid()\n",
    "\n",
    "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                     train_scores_mean + train_scores_std, alpha=0.1,\n",
    "                     color=\"r\")\n",
    "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                     test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
    "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n",
    "             label=\"Training score\")\n",
    "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
    "             label=\"Cross-validation score\")\n",
    "\n",
    "    plt.legend(loc=\"best\")\n",
    "    return plt\n",
    "\n",
    "\n",
    "title = \"Learning Curves (Naive Bayes)\"\n",
    "# Cross validation with 100 iterations to get smoother mean test and train\n",
    "# score curves, each time with 20% data randomly selected as a validation set.\n",
    "cv = ShuffleSplit(n_splits=100, test_size=0.2, random_state=0)\n",
    "\n",
    "estimator = SVC(C=1, kernel='linear')\n",
    "plot_learning_curve(estimator, title, X_normalized, y, ylim=(0.7, 1.01), cv=cv, n_jobs=4)\n",
    "\n",
    "title = \"Learning Curves (SVC, Linear kernel, $\\gamma=0.0041$)\"\n",
    "# SVC is more expensive so we do a lower number of CV iterations:\n",
    "cv = ShuffleSplit(n_splits=10, test_size=0.2, random_state=0)\n",
    "estimator = SVC(C=1, kernel='linear')\n",
    "plot_learning_curve(estimator, title, X, y, (0.7, 1.01), cv=cv, n_jobs=4)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test = pd.read_csv('C:\\Pedro\\workspace\\Acc-challenge\\\\test_data.csv')\n",
    "test = test.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "t_timezone_mapping = dict(zip(sorted(test['Timezone'].unique()), range(0, len(sorted(test['Timezone'].unique())) + 1)))\n",
    "t_fixture_mapping = dict(zip(sorted(test['FixtureDate'].unique()), range(0, len(sorted(test['FixtureDate'].unique())) + 1)))\n",
    "t_hteam_mapping = dict(zip(sorted(test['HomeTeam'].unique()), range(0, len(sorted(test['HomeTeam'].unique())) + 1)))\n",
    "t_ateam_mapping = dict(zip(sorted(test['AwayTeam'].unique()), range(0, len(sorted(test['AwayTeam'].unique())) + 1)))\n",
    "t_team_mapping = dict(zip(sorted(test['Team'].unique()), range(0, len(sorted(test['Team'].unique())) + 1)))\n",
    "t_atype_mapping = dict(zip(sorted(test['ActionTypeDesc'].unique()), range(0, len(sorted(test['ActionTypeDesc'].unique())) + 1)))\n",
    "t_res_mapping = dict(zip(sorted(test['ActionResultDesc'].unique()), range(0, len(sorted(test['ActionResultDesc'].unique())) + 1)))\n",
    "t_start_mapping = dict(zip(sorted(test['StartingPositionDesc'].unique()), range(0, len(sorted(test['StartingPositionDesc'].unique())) + 1)))\n",
    "t_end_mapping = dict(zip(sorted(test['EndPositionDesc'].unique()), range(0, len(sorted(test['EndPositionDesc'].unique())) + 1)))\n",
    "\n",
    "test['Timezone_Val'] = test['Timezone'].map(t_timezone_mapping).astype(int)\n",
    "test['Fixture_Val'] = test['FixtureDate'].map(t_fixture_mapping).astype(int)\n",
    "test['Hteam_Val'] = test['HomeTeam'].map(t_hteam_mapping).astype(int)\n",
    "test['Ateam_Val'] = test['AwayTeam'].map(t_ateam_mapping).astype(int)\n",
    "test['Team_Val'] = test['Team'].map(t_team_mapping).astype(int)\n",
    "test['Atype_Val'] = test['ActionTypeDesc'].map(t_atype_mapping).astype(int)\n",
    "test['Start_Val'] = test['StartingPositionDesc'].map(t_start_mapping).astype(int)\n",
    "test['End_Val'] = test['EndPositionDesc'].map(t_end_mapping).astype(int)\n",
    "test['Res_Val'] = test['ActionResultDesc'].map(t_res_mapping).astype(int)\n",
    "\n",
    "test_set = test.drop(['FixtureDate','StadiumName','KickOffTime_GMT','Timezone','KickOffTime_Local','HomeTeam',\n",
    "                        'AwayTeam','Team','ActionTypeDesc','ActionResultDesc','StartingPositionDesc','EndPositionDesc',\n",
    "                        'PlayDirection','City','Icon','Summary','ZoneDescription','CloudCover','Pressure','Visibility'], axis=1)\n",
    "\n",
    "#test_features = test_set.iloc[:,[10,11,17,12,35,34,6,8,5,9]].values\n",
    "test_features = test_set.iloc[:,[10,11,15,34,6]].values\n",
    "#test_features = test_set.values[:,1:48]\n",
    "#X_test = scaler.transform(test_features)  # apply same transformation to test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features=2, max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=100, n_jobs=1, oob_score=False, random_state=None,\n",
       "            verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = RandomForestClassifier(max_features=2, n_estimators=100)\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_y = clf.predict(test_features)\n",
    "pred_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result = pd.DataFrame({'RecordID': test_set['RecordID']})\n",
    "result['ActionName'] = pred_y.T\n",
    "result\n",
    "result.to_excel('PedroCastanha.xlsx', index=False)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
