{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import explained_variance_score\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import Imputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>derived_0</th>\n",
       "      <th>derived_1</th>\n",
       "      <th>derived_2</th>\n",
       "      <th>derived_3</th>\n",
       "      <th>derived_4</th>\n",
       "      <th>fundamental_0</th>\n",
       "      <th>fundamental_1</th>\n",
       "      <th>fundamental_2</th>\n",
       "      <th>...</th>\n",
       "      <th>technical_36</th>\n",
       "      <th>technical_37</th>\n",
       "      <th>technical_38</th>\n",
       "      <th>technical_39</th>\n",
       "      <th>technical_40</th>\n",
       "      <th>technical_41</th>\n",
       "      <th>technical_42</th>\n",
       "      <th>technical_43</th>\n",
       "      <th>technical_44</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0.370326</td>\n",
       "      <td>-0.006316</td>\n",
       "      <td>0.222831</td>\n",
       "      <td>-0.213030</td>\n",
       "      <td>0.729277</td>\n",
       "      <td>-0.335633</td>\n",
       "      <td>0.113292</td>\n",
       "      <td>1.621238</td>\n",
       "      <td>...</td>\n",
       "      <td>0.775208</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.414776</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.011753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0.014765</td>\n",
       "      <td>-0.038064</td>\n",
       "      <td>-0.017425</td>\n",
       "      <td>0.320652</td>\n",
       "      <td>-0.034134</td>\n",
       "      <td>0.004413</td>\n",
       "      <td>0.114285</td>\n",
       "      <td>-0.210185</td>\n",
       "      <td>...</td>\n",
       "      <td>0.025590</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.273607</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.001240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.010622</td>\n",
       "      <td>-0.050577</td>\n",
       "      <td>3.379575</td>\n",
       "      <td>-0.157525</td>\n",
       "      <td>-0.068550</td>\n",
       "      <td>-0.155937</td>\n",
       "      <td>1.219439</td>\n",
       "      <td>-0.764516</td>\n",
       "      <td>...</td>\n",
       "      <td>0.151881</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.175710</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.020940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.178495</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.007262</td>\n",
       "      <td>...</td>\n",
       "      <td>1.035936</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.211506</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.015959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0.176693</td>\n",
       "      <td>-0.025284</td>\n",
       "      <td>-0.057680</td>\n",
       "      <td>0.015100</td>\n",
       "      <td>0.180894</td>\n",
       "      <td>0.139445</td>\n",
       "      <td>-0.125687</td>\n",
       "      <td>-0.018707</td>\n",
       "      <td>...</td>\n",
       "      <td>0.630232</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.001957</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.007338</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 111 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  timestamp  derived_0  derived_1  derived_2  derived_3  derived_4  \\\n",
       "0  10          0   0.370326  -0.006316   0.222831  -0.213030   0.729277   \n",
       "1  11          0   0.014765  -0.038064  -0.017425   0.320652  -0.034134   \n",
       "2  12          0  -0.010622  -0.050577   3.379575  -0.157525  -0.068550   \n",
       "3  25          0        NaN        NaN        NaN        NaN        NaN   \n",
       "4  26          0   0.176693  -0.025284  -0.057680   0.015100   0.180894   \n",
       "\n",
       "   fundamental_0  fundamental_1  fundamental_2    ...     technical_36  \\\n",
       "0      -0.335633       0.113292       1.621238    ...         0.775208   \n",
       "1       0.004413       0.114285      -0.210185    ...         0.025590   \n",
       "2      -0.155937       1.219439      -0.764516    ...         0.151881   \n",
       "3       0.178495            NaN      -0.007262    ...         1.035936   \n",
       "4       0.139445      -0.125687      -0.018707    ...         0.630232   \n",
       "\n",
       "   technical_37  technical_38  technical_39  technical_40  technical_41  \\\n",
       "0           NaN           NaN           NaN     -0.414776           NaN   \n",
       "1           NaN           NaN           NaN     -0.273607           NaN   \n",
       "2           NaN           NaN           NaN     -0.175710           NaN   \n",
       "3           NaN           NaN           NaN     -0.211506           NaN   \n",
       "4           NaN           NaN           NaN     -0.001957           NaN   \n",
       "\n",
       "   technical_42  technical_43  technical_44         y  \n",
       "0           NaN          -2.0           NaN -0.011753  \n",
       "1           NaN          -2.0           NaN -0.001240  \n",
       "2           NaN          -2.0           NaN -0.020940  \n",
       "3           NaN          -2.0           NaN -0.015959  \n",
       "4           NaN           0.0           NaN -0.007338  \n",
       "\n",
       "[5 rows x 111 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_hdf('C:\\Pedro\\Kaggle\\TwoSigma\\\\train.h5')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>derived_0</th>\n",
       "      <th>derived_1</th>\n",
       "      <th>derived_2</th>\n",
       "      <th>derived_3</th>\n",
       "      <th>derived_4</th>\n",
       "      <th>fundamental_0</th>\n",
       "      <th>fundamental_1</th>\n",
       "      <th>fundamental_2</th>\n",
       "      <th>...</th>\n",
       "      <th>technical_36</th>\n",
       "      <th>technical_37</th>\n",
       "      <th>technical_38</th>\n",
       "      <th>technical_39</th>\n",
       "      <th>technical_40</th>\n",
       "      <th>technical_41</th>\n",
       "      <th>technical_42</th>\n",
       "      <th>technical_43</th>\n",
       "      <th>technical_44</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.710756e+06</td>\n",
       "      <td>1.710756e+06</td>\n",
       "      <td>1.637797e+06</td>\n",
       "      <td>1.629727e+06</td>\n",
       "      <td>1.312105e+06</td>\n",
       "      <td>1.561285e+06</td>\n",
       "      <td>1.304298e+06</td>\n",
       "      <td>1.686809e+06</td>\n",
       "      <td>1.031686e+06</td>\n",
       "      <td>1.341916e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>1.708204e+06</td>\n",
       "      <td>1.691591e+06</td>\n",
       "      <td>1.691591e+06</td>\n",
       "      <td>1.690740e+06</td>\n",
       "      <td>1.708520e+06</td>\n",
       "      <td>1.666567e+06</td>\n",
       "      <td>1.690755e+06</td>\n",
       "      <td>1.706070e+06</td>\n",
       "      <td>1.473977e+06</td>\n",
       "      <td>1.710756e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.093858e+03</td>\n",
       "      <td>9.456257e+02</td>\n",
       "      <td>-4.536046e+00</td>\n",
       "      <td>7.729436e+11</td>\n",
       "      <td>-3.320328e-01</td>\n",
       "      <td>-5.046012e-01</td>\n",
       "      <td>1.801661e+01</td>\n",
       "      <td>-2.040938e-02</td>\n",
       "      <td>-5.703754e+08</td>\n",
       "      <td>-1.622954e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-8.584833e-02</td>\n",
       "      <td>-9.103397e-02</td>\n",
       "      <td>-8.156685e-02</td>\n",
       "      <td>-7.287001e-02</td>\n",
       "      <td>4.908321e-02</td>\n",
       "      <td>5.236218e-03</td>\n",
       "      <td>-1.699966e-02</td>\n",
       "      <td>-9.735299e-01</td>\n",
       "      <td>3.881475e-04</td>\n",
       "      <td>2.217509e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>6.308563e+02</td>\n",
       "      <td>5.195685e+02</td>\n",
       "      <td>2.497382e+02</td>\n",
       "      <td>7.620606e+13</td>\n",
       "      <td>6.519810e+01</td>\n",
       "      <td>1.020749e+02</td>\n",
       "      <td>9.258360e+02</td>\n",
       "      <td>2.494859e-01</td>\n",
       "      <td>7.502322e+10</td>\n",
       "      <td>3.668149e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>6.125852e-01</td>\n",
       "      <td>2.471038e-01</td>\n",
       "      <td>2.346534e-01</td>\n",
       "      <td>2.235729e-01</td>\n",
       "      <td>3.102316e-01</td>\n",
       "      <td>1.133733e-01</td>\n",
       "      <td>2.116284e-01</td>\n",
       "      <td>9.605551e-01</td>\n",
       "      <td>3.011983e-02</td>\n",
       "      <td>2.240643e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-2.017497e+04</td>\n",
       "      <td>-7.375435e-02</td>\n",
       "      <td>-9.848880e+03</td>\n",
       "      <td>-3.434176e+04</td>\n",
       "      <td>-8.551914e+03</td>\n",
       "      <td>-2.344957e+00</td>\n",
       "      <td>-1.043737e+13</td>\n",
       "      <td>-1.077101e+03</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.687572e+00</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>-5.250904e-01</td>\n",
       "      <td>-4.449529e-01</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>-2.000000e+00</td>\n",
       "      <td>-1.265686e-01</td>\n",
       "      <td>-8.609413e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>5.500000e+02</td>\n",
       "      <td>5.040000e+02</td>\n",
       "      <td>-1.449710e-01</td>\n",
       "      <td>-2.956479e-02</td>\n",
       "      <td>-5.967524e-02</td>\n",
       "      <td>-1.655826e-01</td>\n",
       "      <td>-1.057050e-01</td>\n",
       "      <td>-1.996543e-01</td>\n",
       "      <td>-1.960470e-01</td>\n",
       "      <td>-2.280967e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.050297e-01</td>\n",
       "      <td>-4.651562e-04</td>\n",
       "      <td>-1.992532e-04</td>\n",
       "      <td>-2.203252e-05</td>\n",
       "      <td>-1.521701e-01</td>\n",
       "      <td>-7.377038e-02</td>\n",
       "      <td>-3.887695e-15</td>\n",
       "      <td>-2.000000e+00</td>\n",
       "      <td>-1.998819e-02</td>\n",
       "      <td>-9.561389e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.098000e+03</td>\n",
       "      <td>9.560000e+02</td>\n",
       "      <td>-8.368272e-04</td>\n",
       "      <td>5.523058e-03</td>\n",
       "      <td>2.109505e-02</td>\n",
       "      <td>2.475614e-03</td>\n",
       "      <td>1.175234e-02</td>\n",
       "      <td>-4.064488e-02</td>\n",
       "      <td>-7.395084e-03</td>\n",
       "      <td>-3.029069e-02</td>\n",
       "      <td>...</td>\n",
       "      <td>-8.502064e-02</td>\n",
       "      <td>-3.951567e-12</td>\n",
       "      <td>-1.418487e-13</td>\n",
       "      <td>-1.591224e-16</td>\n",
       "      <td>-1.476793e-02</td>\n",
       "      <td>9.782702e-05</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-6.597540e-01</td>\n",
       "      <td>1.117279e-05</td>\n",
       "      <td>-1.570681e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.657000e+03</td>\n",
       "      <td>1.401000e+03</td>\n",
       "      <td>1.199108e-01</td>\n",
       "      <td>1.078554e-01</td>\n",
       "      <td>1.952209e-01</td>\n",
       "      <td>3.037236e-01</td>\n",
       "      <td>1.556464e-01</td>\n",
       "      <td>1.303819e-01</td>\n",
       "      <td>1.832071e-01</td>\n",
       "      <td>1.764751e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>1.909600e-01</td>\n",
       "      <td>-5.219879e-40</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.772415e-01</td>\n",
       "      <td>7.855728e-02</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-5.188884e-08</td>\n",
       "      <td>2.047074e-02</td>\n",
       "      <td>9.520990e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.158000e+03</td>\n",
       "      <td>1.812000e+03</td>\n",
       "      <td>3.252527e+03</td>\n",
       "      <td>1.068448e+16</td>\n",
       "      <td>3.823001e+03</td>\n",
       "      <td>1.239737e+03</td>\n",
       "      <td>6.785965e+04</td>\n",
       "      <td>1.378195e+00</td>\n",
       "      <td>5.203165e+02</td>\n",
       "      <td>7.677125e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>4.957758e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.569265e+00</td>\n",
       "      <td>6.844833e-01</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.435858e-01</td>\n",
       "      <td>9.349781e-02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 111 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id     timestamp     derived_0     derived_1     derived_2  \\\n",
       "count  1.710756e+06  1.710756e+06  1.637797e+06  1.629727e+06  1.312105e+06   \n",
       "mean   1.093858e+03  9.456257e+02 -4.536046e+00  7.729436e+11 -3.320328e-01   \n",
       "std    6.308563e+02  5.195685e+02  2.497382e+02  7.620606e+13  6.519810e+01   \n",
       "min    0.000000e+00  0.000000e+00 -2.017497e+04 -7.375435e-02 -9.848880e+03   \n",
       "25%    5.500000e+02  5.040000e+02 -1.449710e-01 -2.956479e-02 -5.967524e-02   \n",
       "50%    1.098000e+03  9.560000e+02 -8.368272e-04  5.523058e-03  2.109505e-02   \n",
       "75%    1.657000e+03  1.401000e+03  1.199108e-01  1.078554e-01  1.952209e-01   \n",
       "max    2.158000e+03  1.812000e+03  3.252527e+03  1.068448e+16  3.823001e+03   \n",
       "\n",
       "          derived_3     derived_4  fundamental_0  fundamental_1  \\\n",
       "count  1.561285e+06  1.304298e+06   1.686809e+06   1.031686e+06   \n",
       "mean  -5.046012e-01  1.801661e+01  -2.040938e-02  -5.703754e+08   \n",
       "std    1.020749e+02  9.258360e+02   2.494859e-01   7.502322e+10   \n",
       "min   -3.434176e+04 -8.551914e+03  -2.344957e+00  -1.043737e+13   \n",
       "25%   -1.655826e-01 -1.057050e-01  -1.996543e-01  -1.960470e-01   \n",
       "50%    2.475614e-03  1.175234e-02  -4.064488e-02  -7.395084e-03   \n",
       "75%    3.037236e-01  1.556464e-01   1.303819e-01   1.832071e-01   \n",
       "max    1.239737e+03  6.785965e+04   1.378195e+00   5.203165e+02   \n",
       "\n",
       "       fundamental_2      ...       technical_36  technical_37  technical_38  \\\n",
       "count   1.341916e+06      ...       1.708204e+06  1.691591e+06  1.691591e+06   \n",
       "mean   -1.622954e-01      ...      -8.584833e-02 -9.103397e-02 -8.156685e-02   \n",
       "std     3.668149e+00      ...       6.125852e-01  2.471038e-01  2.346534e-01   \n",
       "min    -1.077101e+03      ...      -1.687572e+00 -1.000000e+00 -1.000000e+00   \n",
       "25%    -2.280967e-01      ...      -4.050297e-01 -4.651562e-04 -1.992532e-04   \n",
       "50%    -3.029069e-02      ...      -8.502064e-02 -3.951567e-12 -1.418487e-13   \n",
       "75%     1.764751e-01      ...       1.909600e-01 -5.219879e-40  0.000000e+00   \n",
       "max     7.677125e+01      ...       4.957758e+01  0.000000e+00  0.000000e+00   \n",
       "\n",
       "       technical_39  technical_40  technical_41  technical_42  technical_43  \\\n",
       "count  1.690740e+06  1.708520e+06  1.666567e+06  1.690755e+06  1.706070e+06   \n",
       "mean  -7.287001e-02  4.908321e-02  5.236218e-03 -1.699966e-02 -9.735299e-01   \n",
       "std    2.235729e-01  3.102316e-01  1.133733e-01  2.116284e-01  9.605551e-01   \n",
       "min   -1.000000e+00 -5.250904e-01 -4.449529e-01 -1.000000e+00 -2.000000e+00   \n",
       "25%   -2.203252e-05 -1.521701e-01 -7.377038e-02 -3.887695e-15 -2.000000e+00   \n",
       "50%   -1.591224e-16 -1.476793e-02  9.782702e-05  0.000000e+00 -6.597540e-01   \n",
       "75%    0.000000e+00  1.772415e-01  7.855728e-02  0.000000e+00 -5.188884e-08   \n",
       "max    0.000000e+00  1.569265e+00  6.844833e-01  1.000000e+00  0.000000e+00   \n",
       "\n",
       "       technical_44             y  \n",
       "count  1.473977e+06  1.710756e+06  \n",
       "mean   3.881475e-04  2.217509e-04  \n",
       "std    3.011983e-02  2.240643e-02  \n",
       "min   -1.265686e-01 -8.609413e-02  \n",
       "25%   -1.998819e-02 -9.561389e-03  \n",
       "50%    1.117279e-05 -1.570681e-04  \n",
       "75%    2.047074e-02  9.520990e-03  \n",
       "max    1.435858e-01  9.349781e-02  \n",
       "\n",
       "[8 rows x 111 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDRegressor(alpha=0.0001, average=False, epsilon=0.1, eta0=0.01,\n",
       "       fit_intercept=True, l1_ratio=0.15, learning_rate='invscaling',\n",
       "       loss='squared_loss', n_iter=1, penalty='l2', power_t=0.25,\n",
       "       random_state=None, shuffle=True, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg = SGDRegressor(n_iter=1, penalty='l2', loss='squared_loss')\n",
    "reg\n",
    "\n",
    "#svr = SVR(cache_size=1000, C=0.1, degree=4)\n",
    "#svr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1710756.0\n",
      "1374902.0\n",
      "0.803680945734\n"
     ]
    }
   ],
   "source": [
    "#tot = float(len(df['derived_1']))\n",
    "#uni = float(len(df['derived_1'].unique()))\n",
    "#print(tot)\n",
    "#print(uni)\n",
    "\n",
    "#print(uni / tot)\n",
    "\n",
    "#df.apply(lambda x: len(x.unique())/len(x) if len(x.unique())/len(x) < 0.50 else None )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = df.fillna(0)\n",
    "\n",
    "y = df['y'].values\n",
    "X = df.drop(['id', 'y'], axis=1).values\n",
    "\n",
    "#imp = Imputer(missing_values='NaN', strategy='mean', axis=0) # Filling nan's with mean\n",
    "#imp.fit(X)\n",
    "#X = imp.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Splitting data into train and cv sets using 40%, 60%\n",
    "X_train, X_cv, y_train, y_cv = train_test_split(X, y, test_size=0.6, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_cv = scaler.transform(X_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Components: 4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SGDRegressor(alpha=0.0001, average=False, epsilon=0.1, eta0=0.01,\n",
       "       fit_intercept=True, l1_ratio=0.15, learning_rate='invscaling',\n",
       "       loss='squared_loss', n_iter=1, penalty='l2', power_t=0.25,\n",
       "       random_state=None, shuffle=True, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#pca = PCA(n_components='mle', svd_solver='full').fit(X_train)\n",
    "pca = PCA(n_components=4, svd_solver='randomized').fit(X_train)\n",
    "X_train_pca = pca.transform(X_train)\n",
    "X_cv_pca = pca.transform(X_cv)\n",
    "\n",
    "print(\"Number of Components: %d\" % pca.n_components_)\n",
    "\n",
    "reg.fit(X_train_pca,y_train) # Remove NaN's before fitting data\n",
    "#svr.fit(X_train_pca,y_train) # Remove NaN's before fitting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  1.65346226e+09   6.22860155e+08   2.40382974e+07   1.97944359e+09\n",
      "  -6.60968248e+07   3.33472741e+08   9.21029695e+08  -1.07382433e+08\n",
      "   1.18945500e+09  -1.55343005e+08   4.63782991e+08  -8.57723166e+08\n",
      "  -1.03560439e+09   1.86817660e+09  -9.58863253e+08  -8.19233376e+08\n",
      "   1.12421960e+09   4.25194342e+08   2.56757664e+09   4.85485703e+08]\n",
      "[-0.05937321 -0.0079669  -0.00313469 -0.01286841 -0.01544089 -0.00391624\n",
      " -0.02095961 -0.00787476 -0.00264549 -0.01243801  0.02336292  0.05032206\n",
      " -0.00117565 -0.03457598 -0.01040553  0.00349346 -0.02084679 -0.0292836\n",
      " -0.02136473  0.02028296]\n"
     ]
    }
   ],
   "source": [
    "print(reg.predict(X_cv_pca)[:20])\n",
    "#print(svr.predict(X_cv_pca)[:20])\n",
    "print(y_cv[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_learning_curve(estimator, title, X, y, ylim=None, cv=None,\n",
    "                        n_jobs=1, train_sizes=np.linspace(.1, 1.0, 5)):\n",
    "    \"\"\"\n",
    "    Generate a simple plot of the test and training learning curve.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    estimator : object type that implements the \"fit\" and \"predict\" methods\n",
    "        An object of that type which is cloned for each validation.\n",
    "\n",
    "    title : string\n",
    "        Title for the chart.\n",
    "\n",
    "    X : array-like, shape (n_samples, n_features)\n",
    "        Training vector, where n_samples is the number of samples and\n",
    "        n_features is the number of features.\n",
    "\n",
    "    y : array-like, shape (n_samples) or (n_samples, n_features), optional\n",
    "        Target relative to X for classification or regression;\n",
    "        None for unsupervised learning.\n",
    "\n",
    "    ylim : tuple, shape (ymin, ymax), optional\n",
    "        Defines minimum and maximum yvalues plotted.\n",
    "\n",
    "    cv : int, cross-validation generator or an iterable, optional\n",
    "        Determines the cross-validation splitting strategy.\n",
    "        Possible inputs for cv are:\n",
    "          - None, to use the default 3-fold cross-validation,\n",
    "          - integer, to specify the number of folds.\n",
    "          - An object to be used as a cross-validation generator.\n",
    "          - An iterable yielding train/test splits.\n",
    "\n",
    "        For integer/None inputs, if ``y`` is binary or multiclass,\n",
    "        :class:`StratifiedKFold` used. If the estimator is not a classifier\n",
    "        or if ``y`` is neither binary nor multiclass, :class:`KFold` is used.\n",
    "\n",
    "        Refer :ref:`User Guide <cross_validation>` for the various\n",
    "        cross-validators that can be used here.\n",
    "\n",
    "    n_jobs : integer, optional\n",
    "        Number of jobs to run in parallel (default 1).\n",
    "    \"\"\"\n",
    "    plt.figure()\n",
    "    plt.title(title)\n",
    "    if ylim is not None:\n",
    "        plt.ylim(*ylim)\n",
    "    plt.xlabel(\"Training examples\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    train_sizes, train_scores, test_scores = learning_curve(estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes)\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    plt.grid()\n",
    "\n",
    "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                     train_scores_mean + train_scores_std, alpha=0.1,\n",
    "                     color=\"r\")\n",
    "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                     test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
    "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n",
    "             label=\"Training score\")\n",
    "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
    "             label=\"Cross-validation score\")\n",
    "\n",
    "    plt.legend(loc=\"best\")\n",
    "    return plt\n",
    "\n",
    "\n",
    "title = \"Learning Curves - SGD\"\n",
    "# Cross validation with 100 iterations to get smoother mean test and train\n",
    "# score curves, each time with 20% data randomly selected as a validation set.\n",
    "cv = ShuffleSplit(n_splits=10, test_size=0.2, random_state=0)\n",
    "\n",
    "plot_learning_curve(reg, title, X_train_pca, y_train, cv=cv, n_jobs=4)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  1.00000000e-05   1.08263673e-05   1.17210230e-05   1.26896100e-05\n",
      "   1.37382380e-05   1.48735211e-05   1.61026203e-05   1.74332882e-05\n",
      "   1.88739182e-05   2.04335972e-05   2.21221629e-05   2.39502662e-05\n",
      "   2.59294380e-05   2.80721620e-05   3.03919538e-05   3.29034456e-05\n",
      "   3.56224789e-05   3.85662042e-05   4.17531894e-05   4.52035366e-05\n",
      "   4.89390092e-05   5.29831691e-05   5.73615251e-05   6.21016942e-05\n",
      "   6.72335754e-05   7.27895384e-05   7.88046282e-05   8.53167852e-05\n",
      "   9.23670857e-05   1.00000000e-04]\n",
      "# Tuning hyper-parameters for neg_mean_squared_error\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'alpha': 2.592943797404667e-05}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "-26104094438793408413696.000 (+/-43491304439182729936896.000) for {'alpha': 1.0000000000000001e-05}\n",
      "-9660334779485416062976.000 (+/-13567711688061693722624.000) for {'alpha': 1.0826367338740541e-05}\n",
      "-6163400598307641229312.000 (+/-21258789907642412171264.000) for {'alpha': 1.1721022975334793e-05}\n",
      "-54566884664916658094080.000 (+/-43024002572295461666816.000) for {'alpha': 1.2689610031679234e-05}\n",
      "-13138520262238139318272.000 (+/-20810704033597192404992.000) for {'alpha': 1.3738237958832637e-05}\n",
      "-9212197875313537974272.000 (+/-16580025677874961842176.000) for {'alpha': 1.4873521072935119e-05}\n",
      "-15030304801089608744960.000 (+/-19809288103006297915392.000) for {'alpha': 1.6102620275609392e-05}\n",
      "-5821975795515667775488.000 (+/-7639813541006604763136.000) for {'alpha': 1.7433288221999873e-05}\n",
      "-8803211850627595370496.000 (+/-12639800033302259171328.000) for {'alpha': 1.8873918221350958e-05}\n",
      "-15190424016191364268032.000 (+/-29113257453430060875776.000) for {'alpha': 2.0433597178569438e-05}\n",
      "-6080526549054417534976.000 (+/-7953617596821616459776.000) for {'alpha': 2.2122162910704501e-05}\n",
      "-12281065344278611361792.000 (+/-38566494557390724136960.000) for {'alpha': 2.395026619987486e-05}\n",
      "-5406505042684063776768.000 (+/-8068022354006035660800.000) for {'alpha': 2.592943797404667e-05}\n",
      "-29770016370291380322304.000 (+/-31419215625119357468672.000) for {'alpha': 2.8072162039411757e-05}\n",
      "-18575720872137453469696.000 (+/-35647063882402847784960.000) for {'alpha': 3.0391953823131949e-05}\n",
      "-7064184914758168739840.000 (+/-8360083149123260252160.000) for {'alpha': 3.290344562312671e-05}\n",
      "-15323990307608247402496.000 (+/-31428323636962759016448.000) for {'alpha': 3.5622478902624444e-05}\n",
      "-15736757242915597582336.000 (+/-5427320375166890934272.000) for {'alpha': 3.856620421163472e-05}\n",
      "-22444398394887429423104.000 (+/-43741079193250147860480.000) for {'alpha': 4.1753189365604006e-05}\n",
      "-36921911686395607384064.000 (+/-47431509443542431825920.000) for {'alpha': 4.5203536563602408e-05}\n",
      "-22932862822797379895296.000 (+/-29294506306473237151744.000) for {'alpha': 4.8939009184774991e-05}\n",
      "-31765926482549994946560.000 (+/-46643434382840240799744.000) for {'alpha': 5.2983169062837125e-05}\n",
      "-14260781830189801799680.000 (+/-15505757090290436407296.000) for {'alpha': 5.7361525104486811e-05}\n",
      "-16971385591527702003712.000 (+/-41065156785803676876800.000) for {'alpha': 6.2101694189156158e-05}\n",
      "-18050044555338708942848.000 (+/-20384529945286433308672.000) for {'alpha': 6.7233575364993346e-05}\n",
      "-17571126284311722983424.000 (+/-40461900540212003471360.000) for {'alpha': 7.2789538439831455e-05}\n",
      "-18076607406493877141504.000 (+/-58683870354507999215616.000) for {'alpha': 7.8804628156699046e-05}\n",
      "-28868089235927732322304.000 (+/-35704944550777704153088.000) for {'alpha': 8.5316785241728148e-05}\n",
      "-21041014417376453591040.000 (+/-24156325586565026807808.000) for {'alpha': 9.2367085718738658e-05}\n",
      "-13727790864834622390272.000 (+/-23955575684823785668608.000) for {'alpha': 0.0001}\n",
      "\n",
      "Detailed regression report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "7.69600230437e+22\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rate_param = np.logspace(-5,-4,num=5,base=10.0)\n",
    "#rate_param = 10.0**-np.arange(1,7)\n",
    "print(rate_param)\n",
    "\n",
    "#tuned_parameters = [{'alpha': rate_param, 'loss': ['huber','squared_loss'], 'penalty': ['l1','l2']}] \n",
    "#tuned_parameters = [{'epsilon': rate_param}]\n",
    "tuned_parameters = [{'alpha': rate_param}]\n",
    "#tuned_parameters = [{'degree': np.arange(4,15), 'C': np.logspace(-1,0,num=10,base=10.0)}]\n",
    "\n",
    "scores = ['neg_mean_squared_error']\n",
    "\n",
    "for score in scores:\n",
    "    print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "    print()   \n",
    "\n",
    "    gscv = GridSearchCV(reg, tuned_parameters, cv=5, scoring='%s' % score)\n",
    "    #gscv = GridSearchCV(svr, tuned_parameters, cv=5, scoring='%s' % score)\n",
    "    gscv.fit(X_train_pca, y_train)\n",
    "\n",
    "    print(\"Best parameters set found on development set:\")\n",
    "    print()\n",
    "    print(gscv.best_params_)\n",
    "    print()\n",
    "    print(\"Grid scores on development set:\")\n",
    "    print()\n",
    "    means = gscv.cv_results_['mean_test_score']\n",
    "    stds = gscv.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, gscv.cv_results_['params']):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\" % (mean, std * 2, params))\n",
    "    print()\n",
    "\n",
    "    print(\"Detailed regression report:\")\n",
    "    print()\n",
    "    print(\"The model is trained on the full development set.\")\n",
    "    print(\"The scores are computed on the full evaluation set.\")\n",
    "    print()\n",
    "    \n",
    "    y_true, y_pred = y_cv, gscv.predict(X_cv_pca)\n",
    "    \n",
    "    print(mean_squared_error(y_true,y_pred))\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
