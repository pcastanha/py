{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "========================================================\n",
    "Classification of text documents: using a MLComp dataset\n",
    "========================================================\n",
    "\n",
    "This is an example showing how the scikit-learn can be used to classify\n",
    "documents by topics using a bag-of-words approach. This example uses\n",
    "a scipy.sparse matrix to store the features instead of standard numpy arrays.\n",
    "\n",
    "The dataset used in this example is the 20 newsgroups dataset and should be\n",
    "downloaded from the http://mlcomp.org (free registration required):\n",
    "\n",
    "  http://mlcomp.org/datasets/379\n",
    "\n",
    "Once downloaded unzip the archive somewhere on your filesystem.\n",
    "For instance in::\n",
    "\n",
    "  % mkdir -p ~/data/mlcomp\n",
    "  % cd  ~/data/mlcomp\n",
    "  % unzip /path/to/dataset-379-20news-18828_XXXXX.zip\n",
    "\n",
    "You should get a folder ``~/data/mlcomp/379`` with a file named ``metadata``\n",
    "and subfolders ``raw``, ``train`` and ``test`` holding the text documents\n",
    "organized by newsgroups.\n",
    "\n",
    "Then set the ``MLCOMP_DATASETS_HOME`` environment variable pointing to\n",
    "the root folder holding the uncompressed archive::\n",
    "\n",
    "  % export MLCOMP_DATASETS_HOME=\"~/data/mlcomp\"\n",
    "\n",
    "Then you are ready to run this example using your favorite python shell::\n",
    "\n",
    "  % ipython examples/mlcomp_sparse_document_classification.py\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatically created module for IPython interactive environment\n",
      "MLCOMP_DATASETS_HOME not set; please follow the above instructions\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "To exit: use 'exit', 'quit', or Ctrl-D.\n"
     ]
    }
   ],
   "source": [
    "# Author: Olivier Grisel <olivier.grisel@ensta.org>\n",
    "# License: BSD 3 clause\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "from time import time\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.datasets import load_mlcomp\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "\n",
    "print(__doc__)\n",
    "\n",
    "if 'MLCOMP_DATASETS_HOME' not in os.environ:\n",
    "    print(\"MLCOMP_DATASETS_HOME not set; please follow the above instructions\")\n",
    "    sys.exit(0)\n",
    "\n",
    "# Load the training set\n",
    "print(\"Loading 20 newsgroups training set... \")\n",
    "news_train = load_mlcomp('20news-18828', 'train')\n",
    "print(news_train.DESCR)\n",
    "print(\"%d documents\" % len(news_train.filenames))\n",
    "print(\"%d categories\" % len(news_train.target_names))\n",
    "\n",
    "print(\"Extracting features from the dataset using a sparse vectorizer\")\n",
    "t0 = time()\n",
    "vectorizer = TfidfVectorizer(encoding='latin1')\n",
    "X_train = vectorizer.fit_transform((open(f).read()\n",
    "                                    for f in news_train.filenames))\n",
    "print(\"done in %fs\" % (time() - t0))\n",
    "print(\"n_samples: %d, n_features: %d\" % X_train.shape)\n",
    "assert sp.issparse(X_train)\n",
    "y_train = news_train.target\n",
    "\n",
    "print(\"Loading 20 newsgroups test set... \")\n",
    "news_test = load_mlcomp('20news-18828', 'test')\n",
    "t0 = time()\n",
    "print(\"done in %fs\" % (time() - t0))\n",
    "\n",
    "print(\"Predicting the labels of the test set...\")\n",
    "print(\"%d documents\" % len(news_test.filenames))\n",
    "print(\"%d categories\" % len(news_test.target_names))\n",
    "\n",
    "print(\"Extracting features from the dataset using the same vectorizer\")\n",
    "t0 = time()\n",
    "X_test = vectorizer.transform((open(f).read() for f in news_test.filenames))\n",
    "y_test = news_test.target\n",
    "print(\"done in %fs\" % (time() - t0))\n",
    "print(\"n_samples: %d, n_features: %d\" % X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Benchmark classifiers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def benchmark(clf_class, params, name):\n",
    "    print(\"parameters:\", params)\n",
    "    t0 = time()\n",
    "    clf = clf_class(**params).fit(X_train, y_train)\n",
    "    print(\"done in %fs\" % (time() - t0))\n",
    "\n",
    "    if hasattr(clf, 'coef_'):\n",
    "        print(\"Percentage of non zeros coef: %f\"\n",
    "              % (np.mean(clf.coef_ != 0) * 100))\n",
    "    print(\"Predicting the outcomes of the testing set\")\n",
    "    t0 = time()\n",
    "    pred = clf.predict(X_test)\n",
    "    print(\"done in %fs\" % (time() - t0))\n",
    "\n",
    "    print(\"Classification report on test set for classifier:\")\n",
    "    print(clf)\n",
    "    print()\n",
    "    print(classification_report(y_test, pred,\n",
    "                                target_names=news_test.target_names))\n",
    "\n",
    "    cm = confusion_matrix(y_test, pred)\n",
    "    print(\"Confusion matrix:\")\n",
    "    print(cm)\n",
    "\n",
    "    # Show confusion matrix\n",
    "    plt.matshow(cm)\n",
    "    plt.title('Confusion matrix of the %s classifier' % name)\n",
    "    plt.colorbar()\n",
    "\n",
    "\n",
    "print(\"Testbenching a linear classifier...\")\n",
    "parameters = {\n",
    "    'loss': 'hinge',\n",
    "    'penalty': 'l2',\n",
    "    'n_iter': 50,\n",
    "    'alpha': 0.00001,\n",
    "    'fit_intercept': True,\n",
    "}\n",
    "\n",
    "benchmark(SGDClassifier, parameters, 'SGD')\n",
    "\n",
    "print(\"Testbenching a MultinomialNB classifier...\")\n",
    "parameters = {'alpha': 0.01}\n",
    "\n",
    "benchmark(MultinomialNB, parameters, 'MultinomialNB')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
