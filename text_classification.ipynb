{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import logging\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from optparse import OptionParser\n",
    "import sys\n",
    "from time import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neighbors import NearestCentroid\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.utils.extmath import density\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "# Display progress logs on stdout\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s %(levelname)s %(message)s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define default labels\n",
    "labels = ['Fatos', 'Normas', 'Argumentos', 'Pedidos', 'Irrelevante']\n",
    "\n",
    "# Define stopwords list\n",
    "stopwords = []\n",
    "\n",
    "raw_data = pd.read_csv('C:\\Users\\pedro.castanha\\Downloads\\ML_Gabinete_Digital.csv', error_bad_lines=False, sep='\\t', encoding='utf_8')\n",
    "words = pd.read_table('C:\\Users\\pedro.castanha\\Downloads\\stoplists\\stopwords_pt_br.txt', encoding='mbcs')\n",
    "\n",
    "stopwords = words.values.T.tolist()[0]\n",
    "\n",
    "x_vectorized = TfidfVectorizer(sublinear_tf=True, use_idf=True, max_df=0.5, stop_words=stopwords)\n",
    "x_vectorized.fit(raw_data.Text)\n",
    "x_train = x_vectorized.transform(raw_data.Text)\n",
    "y_train = raw_data.Class\n",
    "\n",
    "names = np.asarray(x_vectorized.get_feature_names())\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_train, y_train, test_size=0.4, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load some categories from the training set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 20 newsgroups dataset for categories:\n",
      "['alt.atheism', 'talk.religion.misc', 'comp.graphics', 'sci.space']\n",
      "data loaded\n",
      "2034 documents - 3.980MB (training set)\n",
      "1353 documents - 2.867MB (test set)\n",
      "4 categories\n",
      "\n",
      "Extracting features from the training data using a sparse vectorizer\n",
      "done in 0.592000s at 6.722MB/s\n",
      "n_samples: 2034, n_features: 33809\n",
      "\n",
      "Extracting features from the test data using the same vectorizer\n",
      "done in 0.381000s at 7.526MB/s\n",
      "n_samples: 1353, n_features: 33809\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#if opts.all_categories:\n",
    "#    categories = None\n",
    "\n",
    "categories = [\n",
    "        'alt.atheism',\n",
    "        'talk.religion.misc',\n",
    "        'comp.graphics',\n",
    "        'sci.space',\n",
    "]\n",
    "\n",
    "#if opts.filtered:\n",
    "#    remove = ('headers', 'footers', 'quotes')\n",
    "#else:\n",
    "remove = ()\n",
    "\n",
    "print(\"Loading 20 newsgroups dataset for categories:\")\n",
    "print(categories if categories else \"all\")\n",
    "\n",
    "data_train = fetch_20newsgroups(subset='train', categories=categories,\n",
    "                                shuffle=True, random_state=42,\n",
    "                                remove=remove)\n",
    "\n",
    "data_test = fetch_20newsgroups(subset='test', categories=categories,\n",
    "                               shuffle=True, random_state=42,\n",
    "                               remove=remove)\n",
    "print('data loaded')\n",
    "\n",
    "# order of labels in `target_names` can be different from `categories`\n",
    "target_names = data_train.target_names\n",
    "\n",
    "\n",
    "def size_mb(docs):\n",
    "    return sum(len(s.encode('utf-8')) for s in docs) / 1e6\n",
    "\n",
    "data_train_size_mb = size_mb(data_train.data)\n",
    "data_test_size_mb = size_mb(data_test.data)\n",
    "\n",
    "print(\"%d documents - %0.3fMB (training set)\" % (\n",
    "    len(data_train.data), data_train_size_mb))\n",
    "print(\"%d documents - %0.3fMB (test set)\" % (\n",
    "    len(data_test.data), data_test_size_mb))\n",
    "print(\"%d categories\" % len(categories))\n",
    "print()\n",
    "\n",
    "# split a training set and a test set\n",
    "y_train, y_test = data_train.target, data_test.target\n",
    "\n",
    "print(\"Extracting features from the training data using a sparse vectorizer\")\n",
    "t0 = time()\n",
    "#if opts.use_hashing:\n",
    "#    vectorizer = HashingVectorizer(stop_words='english', non_negative=True,\n",
    "#                                   n_features=opts.n_features)\n",
    "#    X_train = vectorizer.transform(data_train.data)\n",
    "#else:\n",
    "vectorizer = TfidfVectorizer(sublinear_tf=True, use_idf=True, max_df=0.5, stop_words='english')\n",
    "X_train = vectorizer.fit_transform(data_train.data)\n",
    "duration = time() - t0\n",
    "print(\"done in %fs at %0.3fMB/s\" % (duration, data_train_size_mb / duration))\n",
    "print(\"n_samples: %d, n_features: %d\" % X_train.shape)\n",
    "print()\n",
    "\n",
    "print(\"Extracting features from the test data using the same vectorizer\")\n",
    "t0 = time()\n",
    "X_test = vectorizer.transform(data_test.data)\n",
    "duration = time() - t0\n",
    "print(\"done in %fs at %0.3fMB/s\" % (duration, data_test_size_mb / duration))\n",
    "print(\"n_samples: %d, n_features: %d\" % X_test.shape)\n",
    "print()\n",
    "\n",
    "# mapping from integer feature name to original token string\n",
    "#if opts.use_hashing:\n",
    "#    feature_names = None\n",
    "#else:\n",
    "feature_names = vectorizer.get_feature_names()\n",
    "\n",
    "#if opts.select_chi2:\n",
    "#    print(\"Extracting %d best features by a chi-squared test\" %\n",
    "#          opts.select_chi2)\n",
    "#    t0 = time()\n",
    "#    ch2 = SelectKBest(chi2, k=opts.select_chi2)\n",
    "#    X_train = ch2.fit_transform(X_train, y_train)\n",
    "#    X_test = ch2.transform(X_test)\n",
    "#    if feature_names:\n",
    "        # keep selected feature names\n",
    "#        feature_names = [feature_names[i] for i\n",
    "#                         in ch2.get_support(indices=True)]\n",
    "#    print(\"done in %fs\" % (time() - t0))\n",
    "#    print()\n",
    "\n",
    "if feature_names:\n",
    "    feature_names = np.asarray(feature_names)\n",
    "\n",
    "\n",
    "def trim(s):\n",
    "    \"\"\"Trim string to fit on terminal (assuming 80-column display)\"\"\"\n",
    "    return s if len(s) <= 80 else s[:77] + \"...\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cl = SGDClassifier(alpha=0.000868511373751352, n_iter=50, l1_ratio=0.0035564803062231283, penalty=\"elasticnet\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Projecting the input data...\n",
      "Done in: 54.041s\n"
     ]
    }
   ],
   "source": [
    "# Init - PCA Dim. reduction\n",
    "print(\"Projecting the input data...\")\n",
    "t0 = time()\n",
    "\n",
    "svd = TruncatedSVD(n_components=2000, algorithm='randomized',).fit(X_train.toarray())\n",
    "X_train = svd.transform(X_train)\n",
    "X_test = svd.transform(X_test)\n",
    "\n",
    "X_train = normalize(X_train)\n",
    "X_test = normalize(X_test)\n",
    "\n",
    "print(\"Done in: %0.3fs\" % (time() - t0))\n",
    "# End - PCA Dim. reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Ridge Classifier\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,\n",
      "        max_iter=None, normalize=False, random_state=None, solver='lsqr',\n",
      "        tol=0.01)\n",
      "train time: 0.120s\n",
      "test time:  0.006s\n",
      "accuracy:   0.902\n",
      "dimensionality: 2000\n",
      "density: 1.000000\n",
      "top 10 keywords per class:\n",
      "alt.atheism: 00041032 0029 01a 001555 000usd 000005102000 0001 000100255pixel...\n",
      "comp.graphics: 0039 011634edt 013034 0901 02115 000062david42 0000vec 0049 00...\n",
      "sci.space: 012536 083731 0033 034 000406 000005102000 00196 0004136 01854 00000\n",
      "talk.religion.misc: 003719 001757 0511 013034 0010580b 00090711 0100 000 0000...\n",
      "\n",
      "classification report:\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "       alt.atheism       0.84      0.87      0.85       319\n",
      "     comp.graphics       0.94      0.97      0.95       389\n",
      "         sci.space       0.95      0.95      0.95       394\n",
      "talk.religion.misc       0.84      0.77      0.80       251\n",
      "\n",
      "       avg / total       0.90      0.90      0.90      1353\n",
      "\n",
      "confusion matrix:\n",
      "[[276   4   8  31]\n",
      " [  3 376   6   4]\n",
      " [  3  15 375   1]\n",
      " [ 47   5   6 193]]\n",
      "\n",
      "================================================================================\n",
      "Perceptron\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "Perceptron(alpha=0.0001, class_weight=None, eta0=1.0, fit_intercept=True,\n",
      "      n_iter=50, n_jobs=1, penalty=None, random_state=0, shuffle=True,\n",
      "      verbose=0, warm_start=False)\n",
      "train time: 1.155s\n",
      "test time:  0.006s\n",
      "accuracy:   0.883\n",
      "dimensionality: 2000\n",
      "density: 1.000000\n",
      "top 10 keywords per class:\n",
      "alt.atheism: 053333 0029 01a 000005102000 001555 000usd 000100255pixel 00 000...\n",
      "comp.graphics: 000062david42 0184 024626 074 031905saundrsg 0049 001428 0192 ...\n",
      "sci.space: 083731 001718 0004422 000005102000 000406 0033 0004136 00196 01854...\n",
      "talk.religion.misc: 0511 001757 0820 013034 071814 00090711 02138 0100 0000 0...\n",
      "\n",
      "classification report:\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "       alt.atheism       0.87      0.78      0.82       319\n",
      "     comp.graphics       0.94      0.92      0.93       389\n",
      "         sci.space       0.91      0.98      0.94       394\n",
      "talk.religion.misc       0.76      0.81      0.78       251\n",
      "\n",
      "       avg / total       0.88      0.88      0.88      1353\n",
      "\n",
      "confusion matrix:\n",
      "[[248   7  13  51]\n",
      " [  2 359  17  11]\n",
      " [  0   7 385   2]\n",
      " [ 34   7   7 203]]\n",
      "\n",
      "================================================================================\n",
      "Passive-Aggressive\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "PassiveAggressiveClassifier(C=1.0, class_weight=None, fit_intercept=True,\n",
      "              loss='hinge', n_iter=50, n_jobs=1, random_state=None,\n",
      "              shuffle=True, verbose=0, warm_start=False)\n",
      "train time: 2.088s\n",
      "test time:  0.006s\n",
      "accuracy:   0.902\n",
      "dimensionality: 2000\n",
      "density: 1.000000\n",
      "top 10 keywords per class:\n",
      "alt.atheism: 001555 01a 0029 000062david42 00 000usd 000005102000 0001 000100...\n",
      "comp.graphics: 000100255pixel 0022 011634edt 000062david42 02115 0000vec 0901...\n",
      "sci.space: 020021 012536 034 001718 000406 00196 0033 01854 0004136 00000\n",
      "talk.religion.misc: 010116 003719 013034 0511 001757 0100 00090711 000 0000 0...\n",
      "\n",
      "classification report:\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "       alt.atheism       0.83      0.87      0.85       319\n",
      "     comp.graphics       0.95      0.96      0.95       389\n",
      "         sci.space       0.96      0.95      0.96       394\n",
      "talk.religion.misc       0.83      0.77      0.80       251\n",
      "\n",
      "       avg / total       0.90      0.90      0.90      1353\n",
      "\n",
      "confusion matrix:\n",
      "[[276   3   6  34]\n",
      " [  5 374   5   5]\n",
      " [  4  13 376   1]\n",
      " [ 47   5   5 194]]\n",
      "\n",
      "================================================================================\n",
      "kNN\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=10, p=2,\n",
      "           weights='uniform')\n",
      "train time: 0.126s\n",
      "test time:  13.456s\n",
      "accuracy:   0.857\n",
      "classification report:\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "       alt.atheism       0.78      0.90      0.84       319\n",
      "     comp.graphics       0.89      0.89      0.89       389\n",
      "         sci.space       0.90      0.91      0.90       394\n",
      "talk.religion.misc       0.85      0.67      0.75       251\n",
      "\n",
      "       avg / total       0.86      0.86      0.85      1353\n",
      "\n",
      "confusion matrix:\n",
      "[[286   3  11  19]\n",
      " [ 14 348  19   8]\n",
      " [  7  27 358   2]\n",
      " [ 59  13  12 167]]\n",
      "\n",
      "================================================================================\n",
      "Random forest\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=100, n_jobs=1, oob_score=False, random_state=None,\n",
      "            verbose=0, warm_start=False)\n",
      "train time: 5.725s\n",
      "test time:  0.100s\n",
      "accuracy:   0.833\n",
      "classification report:\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "       alt.atheism       0.75      0.89      0.81       319\n",
      "     comp.graphics       0.97      0.86      0.92       389\n",
      "         sci.space       0.80      0.98      0.88       394\n",
      "talk.religion.misc       0.84      0.49      0.61       251\n",
      "\n",
      "       avg / total       0.84      0.83      0.82      1353\n",
      "\n",
      "confusion matrix:\n",
      "[[284   2  14  19]\n",
      " [  1 336  48   4]\n",
      " [  4   4 385   1]\n",
      " [ 92   3  34 122]]\n",
      "\n",
      "================================================================================\n",
      "L2 penalty\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "LinearSVC(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='l2', max_iter=1000, multi_class='ovr',\n",
      "     penalty='l2', random_state=None, tol=0.001, verbose=0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pedro.castanha\\AppData\\Local\\Continuum\\Anaconda2\\lib\\site-packages\\sklearn\\svm\\classes.py:199: DeprecationWarning: loss='l2' has been deprecated in favor of loss='squared_hinge' as of 0.16. Backward compatibility for the loss='l2' will be removed in 1.0\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train time: 1.563s\n",
      "test time:  0.005s\n",
      "accuracy:   0.903\n",
      "dimensionality: 2000\n",
      "density: 1.000000\n",
      "top 10 keywords per class:\n",
      "alt.atheism: 000062david42 0029 001555 01a 000usd 0001 00 000005102000 000100...\n",
      "comp.graphics: 0184 013034 02115 011634edt 0049 0901 0000vec 000062david42 00...\n",
      "sci.space: 083731 012536 000005102000 034 0033 000406 00196 0004136 01854 00000\n",
      "talk.religion.misc: 003719 013034 001757 0010580b 0511 00090711 0100 000 0000...\n",
      "\n",
      "classification report:\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "       alt.atheism       0.85      0.86      0.85       319\n",
      "     comp.graphics       0.94      0.96      0.95       389\n",
      "         sci.space       0.94      0.95      0.95       394\n",
      "talk.religion.misc       0.84      0.78      0.81       251\n",
      "\n",
      "       avg / total       0.90      0.90      0.90      1353\n",
      "\n",
      "confusion matrix:\n",
      "[[275   2   9  33]\n",
      " [  3 375   7   4]\n",
      " [  3  15 376   0]\n",
      " [ 44   5   6 196]]\n",
      "\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', n_iter=50, n_jobs=1,\n",
      "       penalty='l2', power_t=0.5, random_state=None, shuffle=True,\n",
      "       verbose=0, warm_start=False)\n",
      "train time: 1.184s\n",
      "test time:  0.000s\n",
      "accuracy:   0.902\n",
      "dimensionality: 2000\n",
      "density: 1.000000\n",
      "top 10 keywords per class:\n",
      "alt.atheism: 000062david42 0029 01a 001555 000usd 00 000100255pixel 000005102...\n",
      "comp.graphics: 013034 02115 011634edt 0184 0000vec 0049 000062david42 0901 00...\n",
      "sci.space: 012536 083731 000005102000 034 000406 0033 00196 0004136 01854 00000\n",
      "talk.religion.misc: 024423 013034 001757 0010580b 00090711 0511 000 0100 0000...\n",
      "\n",
      "classification report:\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "       alt.atheism       0.85      0.85      0.85       319\n",
      "     comp.graphics       0.94      0.96      0.95       389\n",
      "         sci.space       0.94      0.96      0.95       394\n",
      "talk.religion.misc       0.84      0.78      0.81       251\n",
      "\n",
      "       avg / total       0.90      0.90      0.90      1353\n",
      "\n",
      "confusion matrix:\n",
      "[[271   4  10  34]\n",
      " [  3 375   7   4]\n",
      " [  3  13 378   0]\n",
      " [ 43   6   5 197]]\n",
      "\n",
      "================================================================================\n",
      "L1 penalty\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "LinearSVC(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='l2', max_iter=1000, multi_class='ovr',\n",
      "     penalty='l1', random_state=None, tol=0.001, verbose=0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pedro.castanha\\AppData\\Local\\Continuum\\Anaconda2\\lib\\site-packages\\sklearn\\svm\\classes.py:199: DeprecationWarning: loss='l2' has been deprecated in favor of loss='squared_hinge' as of 0.16. Backward compatibility for the loss='l2' will be removed in 1.0\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train time: 1.983s\n",
      "test time:  0.000s\n",
      "accuracy:   0.901\n",
      "dimensionality: 2000\n",
      "density: 0.082125\n",
      "top 10 keywords per class:\n",
      "alt.atheism: 01a 0029 001555 0001 095220 000062david42 000usd 000100255pixel ...\n",
      "comp.graphics: 013034 0018 02115 011634edt 0901 0000vec 0049 0184 0004847546 ...\n",
      "sci.space: 012536 141137 041929 01821 000406 00196 0004136 0033 01854 00000\n",
      "talk.religion.misc: 003719 02138 013034 071814 0511 001757 0100 000 0004246 0000\n",
      "\n",
      "classification report:\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "       alt.atheism       0.84      0.87      0.86       319\n",
      "     comp.graphics       0.95      0.95      0.95       389\n",
      "         sci.space       0.91      0.98      0.94       394\n",
      "talk.religion.misc       0.87      0.75      0.80       251\n",
      "\n",
      "       avg / total       0.90      0.90      0.90      1353\n",
      "\n",
      "confusion matrix:\n",
      "[[277   4  13  25]\n",
      " [  4 370  13   2]\n",
      " [  0   9 385   0]\n",
      " [ 47   5  12 187]]\n",
      "\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', n_iter=50, n_jobs=1,\n",
      "       penalty='l1', power_t=0.5, random_state=None, shuffle=True,\n",
      "       verbose=0, warm_start=False)\n",
      "train time: 2.753s\n",
      "test time:  0.007s\n",
      "accuracy:   0.894\n",
      "dimensionality: 2000\n",
      "density: 0.145875\n",
      "top 10 keywords per class:\n",
      "alt.atheism: 10kw 0004422 001555 0001 02139 10km 000062david42 000100255pixel...\n",
      "comp.graphics: 10th 0005 0049 0184 0022 01852 011634edt 013034 0004847546 000000\n",
      "sci.space: 041929 0004422 083731 001718 149 0033 01854 00196 0004136 00000\n",
      "talk.religion.misc: 024423 013034 003719 00090711 0100 0511 000 001757 0000 0...\n",
      "\n",
      "classification report:\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "       alt.atheism       0.83      0.86      0.85       319\n",
      "     comp.graphics       0.95      0.94      0.94       389\n",
      "         sci.space       0.92      0.97      0.94       394\n",
      "talk.religion.misc       0.84      0.74      0.79       251\n",
      "\n",
      "       avg / total       0.89      0.89      0.89      1353\n",
      "\n",
      "confusion matrix:\n",
      "[[273   4  10  32]\n",
      " [  4 367  15   3]\n",
      " [  0  11 383   0]\n",
      " [ 50   6   9 186]]\n",
      "\n",
      "================================================================================\n",
      "Elastic-Net penalty\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "SGDClassifier(alpha=0.000868511373751, average=False, class_weight=None,\n",
      "       epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
      "       l1_ratio=0.00355648030622, learning_rate='optimal', loss='hinge',\n",
      "       n_iter=50, n_jobs=1, penalty='elasticnet', power_t=0.5,\n",
      "       random_state=None, shuffle=True, verbose=0, warm_start=False)\n",
      "train time: 5.077s\n",
      "test time:  0.005s\n",
      "accuracy:   0.905\n",
      "dimensionality: 2000\n",
      "density: 0.955000\n",
      "top 10 keywords per class:\n",
      "alt.atheism: 000062david42 0029 01a 001555 000005102000 000usd 0001 00 000100...\n",
      "comp.graphics: 011634edt 02115 0039 0184 0901 0000vec 0049 000062david42 0004...\n",
      "sci.space: 020021 083731 034 000005102000 0033 000406 00196 0004136 01854 00000\n",
      "talk.religion.misc: 001200201pixel 003719 001757 013034 000 0010580b 00090711...\n",
      "\n",
      "classification report:\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "       alt.atheism       0.84      0.87      0.85       319\n",
      "     comp.graphics       0.94      0.97      0.96       389\n",
      "         sci.space       0.94      0.96      0.95       394\n",
      "talk.religion.misc       0.85      0.77      0.81       251\n",
      "\n",
      "       avg / total       0.90      0.90      0.90      1353\n",
      "\n",
      "confusion matrix:\n",
      "[[276   3   9  31]\n",
      " [  3 376   7   3]\n",
      " [  2  14 378   0]\n",
      " [ 46   5   6 194]]\n",
      "\n",
      "================================================================================\n",
      "NearestCentroid (aka Rocchio classifier)\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "NearestCentroid(metric='euclidean', shrink_threshold=None)\n",
      "train time: 0.020s\n",
      "test time:  0.010s\n",
      "accuracy:   0.866\n",
      "classification report:\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "       alt.atheism       0.82      0.75      0.78       319\n",
      "     comp.graphics       0.92      0.95      0.93       389\n",
      "         sci.space       0.94      0.95      0.95       394\n",
      "talk.religion.misc       0.73      0.76      0.75       251\n",
      "\n",
      "       avg / total       0.87      0.87      0.87      1353\n",
      "\n",
      "confusion matrix:\n",
      "[[238   9   6  66]\n",
      " [  5 369  11   4]\n",
      " [  3  16 373   2]\n",
      " [ 46   8   5 192]]\n",
      "\n",
      "================================================================================\n",
      "Naive Bayes\n",
      "================================================================================\n",
      "LinearSVC with L1-based feature selection\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "Pipeline(steps=[('feature_selection', LinearSVC(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l1', random_state=None, tol=0.001,\n",
      "     verbose=0)), ('classification', LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
      "     verbose=0))])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pedro.castanha\\AppData\\Local\\Continuum\\Anaconda2\\lib\\site-packages\\sklearn\\utils\\deprecation.py:70: DeprecationWarning: Function transform is deprecated; Support to use estimators as feature selectors will be removed in version 0.19. Use SelectFromModel instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "C:\\Users\\pedro.castanha\\AppData\\Local\\Continuum\\Anaconda2\\lib\\site-packages\\sklearn\\utils\\deprecation.py:70: DeprecationWarning: Function transform is deprecated; Support to use estimators as feature selectors will be removed in version 0.19. Use SelectFromModel instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train time: 1.772s\n",
      "test time:  0.000s\n",
      "accuracy:   0.908\n",
      "classification report:\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "       alt.atheism       0.84      0.87      0.85       319\n",
      "     comp.graphics       0.95      0.97      0.96       389\n",
      "         sci.space       0.95      0.97      0.96       394\n",
      "talk.religion.misc       0.85      0.78      0.81       251\n",
      "\n",
      "       avg / total       0.91      0.91      0.91      1353\n",
      "\n",
      "confusion matrix:\n",
      "[[276   4   8  31]\n",
      " [  4 376   5   4]\n",
      " [  1  12 381   0]\n",
      " [ 46   4   6 195]]\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAuMAAAI1CAYAAAB8GvSWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzs3Xm8XVV9///XOwNDSABlkogSRGYCISFRRDAMIiLihFO1\nihZkEtQCBSs1YJXiFxwYRFoVGQSLiLWoqAElRRAkuSEyCDIURKA/EEoggYQS8vn9cXbiIQRyb7jJ\nzvB6Ph73kbPXXnuttQ9/8L6fu84+qSokSZIkLX0D2l6AJEmStLIyjEuSJEktMYxLkiRJLTGMS5Ik\nSS0xjEuSJEktMYxLkiRJLTGMS5IkSS0xjEuSlltJ3pjkt0keT/K/Sa5NMrbtdUlSbw1qewGSJC2O\nJGsCPwUOBX4ArALsAjzdj3MMrKpn+2s8SVqQlXFJ0vJqc4Cq+n5VPVtVs6pqYlXdBJDkoCS3JZmR\n5A9JRjftWyWZlGR6kluT7DdvwCTnJvlmksuTPAnslmTVJKcmuS/JQ0nOTrJ6K3csaYVjGJckLa/u\nAJ5Ncl6StyZ52bwTSd4LnAB8BFgT2A94NMlg4CfARGB94AjgwiRbdI37N8CXgGHANcDJdIL/KOC1\nwCuBzy/ZW5O0skhVtb0GSZIWS5KtgGOBPYFXAJcDBwHnA5dX1WkL9N8FuAQYXlVzm7bvA3+sqhOS\nnAsMqKqPNOcCzAS2q6q7m7adgIuqapOlcIuSVnDuGZckLbeq6jbgAIAkWwLfA74OvAq4eyGXDAf+\nPC+IN/5Ep9o9z5+7Xq8HDAF6OrkcgAAD+2H5kuQ2FUnSiqGqbgfOBbalE6g3XUi3B4FXJen+/9+r\ngQe6h+p6/QgwC9imqtZuftaqqqH9unhJKy3DuCRpuZRkyyRHJdmoOX4V8EHgeuDbwNFJxqTjtUk2\nBn4HPAX8Q5LBScYDbwf+fWFzNBX0bwFfS7J+M88rk7xlSd+fpJWDYVyStLyaAbwO+F3z5JPrgVuA\no6rqEjofwryo6fdj4OVV9X90wvdb6VS9zwI+0lTVX8ixwF3A9UmeAK4EtniR/pLUa36AU5IkSWqJ\nlXFJkiSpJYZxSZIkqSWGcUmSJKklhnFJkiSpJX7pj5Zp6667bo0YMaLtZUiSJPVJT0/PI1W13qL6\nGca1TBsxYgRTpkxpexmSJEl9kuRPvennNhVJkiSpJYZxSZIkqSWGcUmSJKkl7hmXJElazjzzzDPc\nf//9zJ49u+2lrPRWW201NtpoIwYPHrxY1xvGJUmSljP3338/w4YNY8SIESRpezkrrari0Ucf5f77\n72eTTTZZrDHcpiJJkrScmT17Nuuss45BvGVJWGeddV7SXygM45IkScshg/iy4aX+dzCMS5IkSS1x\nz7gkSdJyLjmxX8ermtCv4+mFWRmXJElSa+bMmdP2ElplGJckSVKfPPnkk7ztbW9j++23Z9ttt+Xi\niy9m8uTJvOENb2D77bdn3LhxzJgxg9mzZ/Oxj32MkSNHssMOO3DVVVcBcO6557Lffvux++67s8ce\newBwyimnMHbsWLbbbjsmTFh5KvNuU5EkSVKf/OIXv2D48OH87Gc/A+Dxxx9nhx124OKLL2bs2LE8\n8cQTrL766px22mkk4eabb+b2229nr7324o477gBg6tSp3HTTTbz85S9n4sSJ3Hnnndxwww1UFfvt\ntx9XX301u+66a5u3uVRYGZckSVKfjBw5kiuuuIJjjz2W3/zmN9x3331suOGGjB07FoA111yTQYMG\ncc011/DhD38YgC233JKNN954fhh/85vfzMtf/nIAJk6cyMSJE9lhhx0YPXo0t99+O3feeWc7N7eU\nWRmXJElSn2y++eZMnTqVyy+/nOOPP57dd9+9z2OsscYa819XFZ/97Gc5+OCD+3OZywUr45IkSeqT\nBx98kCFDhvDhD3+YY445ht/97nf8z//8D5MnTwZgxowZzJkzh1122YULL7wQgDvuuIP77ruPLbbY\n4nnjveUtb+Gcc85h5syZADzwwAM8/PDDS++GWmRlXJIkaTm3tB9FePPNN3PMMccwYMAABg8ezDe/\n+U2qiiOOOIJZs2ax+uqrc+WVV3LYYYdx6KGHMnLkSAYNGsS5557Lqquu+rzx9tprL2677TZ22mkn\nAIYOHcr3vvc91l9//aV6X21IVbW9BukF7bjjjjVlypS2lyFJ0jLltttuY6uttmp7GWos7L9Hkp6q\n2nFR17pNRZIkSWqJYVySJElqiWFckiRJaolhXJIkSWqJYVySJElqiWFckiRJaonPGZckSVrOZdKk\nfh2vxo9/0fPTp0/noosu4rDDDuvz2Pvssw8XXXQRa6+99gv2+fznP8+uu+7Knnvu2efxF3TSSSfx\nj//4j/OP3/CGN/Db3/72JY/bX3zOuJZpPmdckqTnW/C51ks7jN97773su+++3HLLLc87N2fOHAYN\nWnbqvUOHDp3/zZ5Lis8ZlyRJ0lJz3HHHcffddzNq1CiOOeYYJk2axC677MJ+++3H1ltvDcA73/lO\nxowZwzbbbMO//du/zb92xIgRPPLII9x7771stdVWHHTQQWyzzTbstddezJo1C4ADDjiAH/7wh/P7\nT5gwgdGjRzNy5Ehuv/12AP7yl7/w5je/mW222YYDDzyQjTfemEceeeR565w1axajRo3iQx/6ENAJ\n5wCTJk3iTW96E+94xzt4zWtew3HHHceFF17IuHHjGDlyJHfffff8ed7znvcwduxYxo4dy7XXXtuv\n76VhXJIkSX1y8skns+mmmzJt2jROOeUUAKZOncppp53GHXfcAcA555xDT08PU6ZM4fTTT+fRRx99\n3jh33nknhx9+OLfeeitrr702l1566ULnW3fddZk6dSqHHnoop556KgAnnngiu+++O7feeiv7778/\n991330LXufrqqzNt2jQuvPDC553//e9/z9lnn81tt93GBRdcwB133MENN9zAgQceyBlnnAHApz71\nKT7zmc8wefJkLr30Ug488MDFe9NewLLzNwRJkiQtt8aNG8cmm2wy//j000/nP/7jPwD485//zJ13\n3sk666zznGs22WQTRo0aBcCYMWO49957Fzr2u9/97vl9fvSjHwFwzTXXzB9/77335mUve1mf1zx2\n7Fg23HBDADbddFP22msvAEaOHMlVV10FwJVXXskf/vCH+dc88cQTzJw5c36F/aUyjEuSJOklW2ON\nNea/njRpEldeeSXXXXcdQ4YMYfz48cyePft516y66qrzXw8cOHD+NpUX6jdw4EDmzJnTb2vunn/A\ngAHzjwcMGDB/nrlz53L99dez2mqr9du83dymIkmSpD4ZNmwYM2bMeMHzjz/+OC972csYMmQIt99+\nO9dff32/r2HnnXfmBz/4AQATJ07kscceW2i/wYMH88wzzyz2PHvttdf8LSsA06ZNW+yxFsbKuCRJ\n0nJuUU8/6W/rrLMOO++8M9tuuy1vfetbedvb3vac83vvvTdnn302W221FVtssQWvf/3r+30NEyZM\n4IMf/CAXXHABO+20E694xSsYNmzY8/p94hOfYLvttmP06NEL3Te+KKeffjqHH3442223HXPmzGHX\nXXfl7LPP7o9bAHy0oZZxPtpQkqTnW9ij9FY2Tz/9NAMHDmTQoEFcd911HHroof1ete6tl/JoQyvj\nkiRJWu7cd999vO9972Pu3LmsssoqfOtb32p7SYvFMC5JkqTlzmabbcaNN97Y9jJeMsO4lmk9M2b0\n+7eKSS/F0t6XKUlasfk0FUmSJKklhnFJkiSpJYZxSZIkqSXuGZckSVrefSX9O95RL/7o6+nTp3PR\nRRdx2GGHLdbwX//61/nEJz7BkCFDFnlun3324aKLLmLttdderLmWdVbGJUmS1CfTp0/nrLPOWuzr\nv/71r/PUU0/16tzll1++wgZxMIxLkiSpj4477jjuvvtuRo0axTHHHAPAKaecwtixY9luu+2YMGEC\nAE8++SRve9vb2H777dl22225+OKLOf3003nwwQfZbbfd2G233Z4z7sLOjRgxgkceeYR7772XLbfc\nkgMOOIDNN9+cD33oQ1x55ZXsvPPObLbZZtxwww3z5/z4xz/OuHHj2GGHHfjP//zPpfjO9J3bVCRJ\nktQnJ598Mrfccsv8b7ycOHEid955JzfccANVxX777cfVV1/NX/7yF4YPH87PfvYzAB5//HHWWmst\nvvrVr3LVVVex7rrrPmfcI4888gXPAdx1111ccsklnHPOOYwdO5aLLrqIa665hssuu4yTTjqJH//4\nx3zpS19i991355xzzmH69OmMGzeOPffckzXWWGPJvzGLwTCuZdqYYcOY4nOdJUlapk2cOJGJEyey\nww47ADBz5kzuvPNOdtllF4466iiOPfZY9t13X3bZZZeXNM8mm2zCyJEjAdhmm23YY489SMLIkSO5\n995756/lsssu49RTTwVg9uzZ3Hfffc/7uvplxSLDeJJngZubvrcBH62qp5L8tqresDiTJpkEHF1V\nU5JcDvxNVU1fnLEkSZLUrqris5/9LAcffPDzzk2dOpXLL7+c448/nj322IPPf/7ziz3PqquuOv/1\ngAED5h8PGDCAOXPmzF/LpZdeyhZbbLHY8yxNvdkzPquqRlXVtsD/AYcALG4QX1BV7WMQlyRJWn4M\nGzaMGTNmzD9+y1vewjnnnMPMmTMBeOCBB3j44Yd58MEHGTJkCB/+8Ic55phjmDp16kKvf7Gx++ot\nb3kLZ5xxBlWdJ8LceOONiz3W0tDXbSq/AbYDSDKzqoYmGQ98AZgBvBa4CjisquYm2Qs4EVgVuBv4\nWFXN7B4wyb3AjsBQ4OfANcAbgAeAd1TVrCSbAt8A1gOeAg6qqtv7fruSJEkroEU8irC/rbPOOuy8\n885su+22vPWtb+WUU07htttuY6eddgJg6NChfO973+Ouu+7imGOOYcCAAQwePJhvfvObAHziE59g\n7733Zvjw4Vx11VXPGfvFzvXGP/3TP/HpT3+a7bbbjrlz57LJJpvw05/+9KXf9BKSeb81vGCHv4bu\nQcClwC+q6psLhPFfAFsDf2pe/yswCfgR8NaqejLJscCqVfWFBbap3Mtfw/hdwI5VNS3JD4DLqup7\nSX4FHFJVdyZ5HfAvVbV7f78ZWvYkwwue/ycvSZJWZj//+V6su+7GS3XOHXccvlTnW57cdtttz9uT\nnqSnqnZc1LW9qYyvnmRa8/o3wHcW0ueGqvrvZuLvA28EZtMJ6NcmAVgFuG4Rc91TVfPm6gFGJBlK\np1J+STMOdCrtkiRJ0nKtN2F8VlWNWkSfBcvrBQS4oqo+2If1PN31+llgdTr72qf3Yg2SJEnScqW/\nvvRnXJJNkgwA3k9n3/f1wM5JXguQZI0km/d14Kp6ArgnyXubcZJk+35atyRJ0nJn7lx4fi1UbVjU\nlu9F6a8wPhk4k86jD+8B/qOq/gIcAHw/yU10tqhsuZjjfwj4uyS/B24F3vGSVyxJkrScuuuuJ5gz\n50kM5O2qKh599FFWW221xR5jkR/gXOQAnQ9wHl1V+76kgaSF8AOckiQ938tetgonnDCa1752TQb0\nV2l1ETbeeO2lM9FyZrXVVmOjjTZi8ODBz2nvzw9wSpIkaRny2GP/x6c+df1SnbNqwlKdb2XxksN4\nVU2i8xhDSZIkSX1gZVzLtDFjhjNlir+JS5KkFdNS2mUkSZIkaUGGcUmSJKklhnFJkiSpJYZxSZIk\nqSWGcUmSJKklhnFJkiSpJYZxSZIkqSWGcUmSJKklhnFJkiSpJYZxSZIkqSWGcUmSJKklhnFJkiSp\nJYZxSZIkqSWGcUmSJKklhnFJkiSpJYZxSZIkqSWGcUmSJKklhnFJkiSpJYZxSZIkqSWGcS3TembM\nIJMmtb0MSZKkJcIwLkmSJLXEMC5JkiS1xDAuSZIktcQwLkmSJLXEMC5JkiS1xDAuSZIktcQwLkmS\nJLXEMK5l2phhw6jx49tehiRJ0hKxyDCepJJ8pev46CQnLNFVvfBaPp1kSNfx0CT/muTuJD1JJiV5\n3WKO/c4kWy/GdYck+chC2kckuWVx1iJJkqSVQ28q408D706ybn9OnGTQYlz2aWBI1/G3gf8FNquq\nMcDHgMVd5zuBhYbxF1trVZ1dVecv5pySJElaifUmjM8B/g34zIInkqyX5NIkk5ufnZv2cUmuS3Jj\nkt8m2aJpPyDJZUl+DfyqaTumufamJCc2bWsk+VmS3ye5Jcn7kxwJDAeuSnJVkk2B1wHHV9VcgKq6\np6p+1ozx4SQ3JJnWVM8HNu0zk3ypGfv6JBskeQOwH3BK03/Tpsr+9SRTgE81le5fN+v8VZJXN+Od\nkOTo5vWYZtzfA4cv3n8SSZIkrSx6W53+BnBTkv+3QPtpwNeq6pomnP4S2Aq4HdilquYk2RM4CXhP\nc81oYLuq+t8kewGbAeOAAJcl2RVYD3iwqt4GkGStqno8yd8Du1XVI0n2A6ZV1bMLLjbJVsD7gZ2r\n6pkkZwEfAs4H1gCur6rPNfdzUFV9McllwE+r6ofNGACrVNWOzfFPgPOq6rwkHwdOp1NN7/Zd4JNV\ndXWSU3r53upF9PQ8SPM7miRJ6oWqCW0vQX3QqzBeVU8kOR84EpjVdWpPYOsmuAKsmWQosBZwXpLN\ngAIGd11zRVX9b/N6r+bnxuZ4KJ1w/hvgK0m+TCcg/6aP97UHMAaY3KxtdeDh5tz/AT9tXvcAb36R\ncS7uer0T8O7m9QXAc34xSbI2sHZVXd3V5619XLckSZJWIn3Zt/11YCqd6u88A4DXV9Xs7o5JzgSu\nqqp3JRkBTOo6/WR3V+BfqupfF5wsyWhgH+CLSX5VVV9YoMutwPZJBi6kOh46VezPLuQ+nqmqal4/\ny4u/B0++yDlJkiTpJen1ow2bavYPgL/rap4IHDHvIMmo5uVawAPN6wNeZNhfAh9vqukkeWWS9ZMM\nB56qqu8Bp9DZ2gIwAxjWrOduYApwYpryd7Ov+2109qPvn2T9pv3lSTZexC3OH/sF/Bb4QPP6Q3Sq\n9/NV1XRgepI3dvWRJEmSXlBfnzP+FZ77tJIjgR2bDzX+ATikaf9/wL8kuZEXqTxX1UTgIuC6JDcD\nP6QTiEcCNySZBkwAvthc8m/AL5Jc1RwfCGwA3NU8RvBc4OGq+gNwPDAxyU3AFcCGi7i3fweOaT50\nuulCzh8BfKwZ72+BTy2kz8eAbzTrzkLOS5IkSfPlrzs2pGVPMrzg4LaXIUnScsMPcC4bkvTMexDI\ni/EbOCVJkqSWGMYlSZKklizOt2BKS82YMcOZMsU/t0mSpBWTlXFJkiSpJYZxSZIkqSWGcUmSJKkl\nhnFJkiSpJYZxSZIkqSWGcUmSJKklhnFJkiSpJYZxSZIkqSWGcUmSJKklhnFJkiSpJYZxSZIkqSWG\ncUmSJKklhnFJkiSpJYZxSZIkqSWGcUmSJKklhnFJkiSpJYZxSZIkqSWGcUmSJKklhnFJkiSpJYPa\nXoD0YnpmzCCTJrW9DEmSVkg1fnzbS1jpWRmXJEmSWmIYlyRJklpiGJckSZJaYhiXJEmSWmIYlyRJ\nklpiGJckSZJaYhiXJEmSWuJzxrVMGzNsGFN8BqokSVpB9aoynuRzSW5NclOSaUlel2RQkpOS3Nm0\nTUvyua5rnm3abk3y+yRHJRnQdX5ckquT/DHJjUm+nWRIkgOSnNlfN5jk8iRrN6+PTHJbkguT7Jfk\nuP6aR5IkSeqrRVbGk+wE7AuMrqqnk6wLrAJ8EXgFMLKqZicZBhzVdemsqhrVjLE+cBGwJjAhyQbA\nJcAHquq6ps/+wLD+u7WOqtqn6/AwYM+qur85vqy34yQZVFVz+nVxkiRJWqn1pjK+IfBIVT0NUFWP\nANOBg4Ajqmp20z6jqk5Y2ABV9TDwCeCTSQIcDpw3L4g3fX5YVQ91X5fk7Ul+11TOr2xCPEne1FWN\nvzHJsCQbNpX2aUluSbJL0/feJOsmORt4DfDzJJ/prsAnWS/JpUkmNz87N+0nJLkgybXABb18TyVJ\nkqRe6c2e8YnA55PcAVwJXAw8BtxXVTN6O1FV/XeSgcD6wLbAeb247Brg9VVVSQ4E/oFO9f1o4PCq\nujbJUGA2nbD/y6r6UjPPkAXmPyTJ3sBuVfVIkgO6Tp8GfK2qrknyauCXwFbNua2BN1bVrN7eq/pP\nT8+DJCe2vQxJklZqVRPaXsIKa5FhvKpmJhkD7ALsRieMn9TdJ8nHgE8B6wBvqKo/99P6NgIuTrIh\nna0x9zTt1wJfTXIh8KOquj/JZOCcJIOBH1fVtD7MsyewdadoD8CaTcgHuMwgLkmSpCWhVx/grKpn\nq2pSdX4t+iTwduDVzT5xquq7zf7wx4GBCxsjyWuAZ4GHgVuBMb2Y+gzgzKoaCRwMrNbMdzJwILA6\ncG2SLavqamBX4AHg3CQf6c29NQbQqcCPan5eWVUzm3NP9mEcSZIkqdcWGcaTbJFks66mUcAfge8A\nZyZZrek3kE71emFjrAecTSdYF3Am8NEkr+vq8+55e8K7rEUnXAN8tKvvplV1c1V9GZgMbJlkY+Ch\nqvoW8G1g9KLurctE4Iiu8Uf14VpJkiRpsfRmz/hQ4Izm8YBzgLvo7M9+HPhn4JYkM4BZdPaBP9hc\nt3qSacDg5roLgK8CVNVDST4AnNo8aWUucDXwiwXmPgG4JMljwK+BTZr2TyfZrbnuVuDnwAeAY5I8\nA8wE+lIZPxL4RpKb6LwnVwOH9OF6SZIkqc/SKVRLy6ZkeHV2KEmSpLb4Ac6+S9JTVTsuql+v9oxL\nkiRJ6n+GcUmSJKklvdkzLrVmzJjhTJnin8YkSdKKycq4JEmS1BLDuCRJktQSw7gkSZLUEsO4JEmS\n1BLDuCRJktQSw7gkSZLUEsO4JEmS1BLDuCRJktQSw7gkSZLUEsO4JEmS1BLDuCRJktQSw7gkSZLU\nEsO4JEmS1BLDuCRJktQSw7gkSZLUEsO4JEmS1BLDuCRJktQSw7gkSZLUEsO4JEmS1JJBbS9AejE9\nM2aQSZPaXoakltT48W0vQZKWKCvjkiRJUksM45IkSVJLDOOSJElSSwzjkiRJUksM45IkSVJLDOOS\nJElSSwzjkiRJUkt8zriWaWOGDWOKzxmWJEkrqF5VxpN8LsmtSW5KMi3J65IMSnJSkjubtmlJPtd1\nzbNN261Jfp/kqCQDus6PS3J1kj8muTHJt5MMSXJAkjP76waTXJ5k7eb1kUluS3Jhkv2SHNdf80iS\nJEl9tcjKeJKdgH2B0VX1dJJ1gVWALwKvAEZW1ewkw4Cjui6dVVWjmjHWBy4C1gQmJNkAuAT4QFVd\n1/TZHxjWf7fWUVX7dB0eBuxZVfc3x5f1dpwkg6pqTr8uTpIkSSu13lTGNwQeqaqnAarqEWA6cBBw\nRFXNbtpnVNUJCxugqh4GPgF8MkmAw4Hz5gXxps8Pq+qh7uuSvD3J75rK+ZVNiCfJm7qq8TcmGZZk\nw6bSPi3JLUl2afrem2TdJGcDrwF+nuQz3RX4JOsluTTJ5OZn56b9hCQXJLkWuKCX76kkSZLUK73Z\nMz4R+HySO4ArgYuBx4D7qmpGbyeqqv9OMhBYH9gWOK8Xl10DvL6qKsmBwD/Qqb4fDRxeVdcmGQrM\nphP2f1lVX2rmGbLA/Ick2RvYraoeSXJA1+nTgK9V1TVJXg38EtiqObc18MaqmtXbe1X/6el5kOTE\ntpchSdJKoWpC20tY6SwyjFfVzCRjgF2A3eiE8ZO6+yT5GPApYB3gDVX1535a30bAxUk2pLM15p6m\n/Vrgq0kuBH5UVfcnmQyck2Qw8OOqmtaHefYEtu4U7QFYswn5AJcZxCVJkrQk9OoDnFX1bFVNqs6v\nS58E3g68utknTlV9t9kf/jgwcGFjJHkN8CzwMHArMKYXU58BnFlVI4GDgdWa+U4GDgRWB65NsmVV\nXQ3sCjwAnJvkI725t8YAOhX4Uc3PK6tqZnPuyT6MI0mSJPXaIsN4ki2SbNbVNAr4I/Ad4MwkqzX9\nBtKpXi9sjPWAs+kE6wLOBD6a5HVdfd49b094l7XohGuAj3b13bSqbq6qLwOTgS2TbAw8VFXfAr4N\njF7UvXWZCBzRNf6oPlwrSZIkLZbe7BkfCpzRPB5wDnAXnf3ZjwP/DNySZAYwi84+8Aeb61ZPMg0Y\n3Fx3AfBVgKp6KMkHgFObJ63MBa4GfrHA3CcAlyR5DPg1sEnT/ukkuzXX3Qr8HPgAcEySZ4CZQF8q\n40cC30hyE5335GrgkD5cL0mSJPVZOoVqadmUDK/ODiVJkrSk+QHO/pOkp6p2XFS/Xu0ZlyRJktT/\nDOOSJElSS3qzZ1xqzZgxw5kyxT+ZSZKkFZOVcUmSJKklhnFJkiSpJYZxSZIkqSWGcUmSJKklhnFJ\nkiSpJYZxSZIkqSWGcUmSJKklhnFJkiSpJYZxSZIkqSWGcUmSJKklhnFJkiSpJYZxSZIkqSWGcUmS\nJKklhnFJkiSpJYZxSZIkqSWGcUmSJKklhnFJkiSpJYZxSZIkqSWGcUmSJKklg9pegPRiembMIJMm\ntb0MaYmp8ePbXoIkqUVWxiVJkqSWGMYlSZKklhjGJUmSpJYYxiVJkqSWGMYlSZKklhjGJUmSpJYY\nxiVJkqSWLPI540lmVtXQBdoOAZ6qqvOX2Mo683wc+AxQdH5x+BywNrB3VX2wq9+6wG3ARsBc4J+B\n9wAzgKeBL1TVz5fkWrVkjBk2jCk+h1mSJK2gFutLf6rq7P5eSLckAV5FJ3yPrqrHkwwF1gMeBb6S\nZEhVPdVcsj/wk6p6OsnJwIbAts3xBsCbluR6JUmSpMWxWNtUkpyQ5Ojm9aQkX05yQ5I7kuzStA9M\nckqSyUluSnJw0z40ya+STE1yc5J3NO0jkvwxyfnALcAmdCrbMwGqamZV3VNVTwD/Bby9a0kfAL6f\nZAhwEHBEVT3dXPdQVf1gce5TkiRJWpL6a8/4oKoaB3wamNC0/R3weFWNBcYCByXZBJgNvKuqRgO7\n0alyp7lmM+CsqtoGuAZ4CLgnyXeTdIfv79MJ4CQZDmwO/Bp4LXBfE9glSZKkZdpibVNZiB81//YA\nI5rXewHLs4XeAAAgAElEQVTbJdm/OV6LTti+Hzgpya509ne/Etig6fOnqroeoKqeTbI3nSC/B/C1\nJGOq6gTgZ8BZSdYE3gdc2vTvp9vRsqKn50GSE9tehiRJK6WqCYvupJekv8L4082/z3aNGTrbRX7Z\n3THJAXT2fo+pqmeS3Aus1px+srtvVRVwA3BDkiuA7wInVNWsJL8A3kWnQv73zSV3Aa9OsqbVcUmS\nJC3rluSjDX8JHJpkMECSzZOsQadC/nATxHcDNl7YxUmGJxnd1TQK+FPX8ffphPANgOsAmg90fgc4\nLckqzTjrJXlv/96aJEmS9NL1pjI+JMn9Xcdf7eXY36azZWVqsyf8L8A7gQuBnyS5GZgC3P4C1w8G\nTm32hM9urj+k6/wVwPnAd5oK+jzHA18E/pBkNp1q++d7uWZJkiRpqclzc6y0bEmGFxzc9jIkSVop\nuWd88SXpqaodF9XPb+CUJEmSWmIYlyRJklpiGJckSZJa0l+PNpSWiDFjhjNlivvVJEnSisnKuCRJ\nktQSw7gkSZLUEsO4JEmS1BLDuCRJktQSw7gkSZLUEsO4JEmS1BLDuCRJktQSw7gkSZLUEsO4JEmS\n1BLDuCRJktQSw7gkSZLUEsO4JEmS1BLDuCRJktQSw7gkSZLUEsO4JEmS1BLDuCRJktQSw7gkSZLU\nEsO4JEmS1BLDuCRJktSSQW0vQHoxPTNmkEmT2l6G+qjGj297CZIkLResjEuSJEktMYxLkiRJLTGM\nS5IkSS0xjEuSJEktMYxLkiRJLTGMS5IkSS0xjEuSJEkt6dVzxpN8Dvgb4FlgLnAw0AN8AXgv8GTT\n9ZKq+lJzzbPAzcBgYA5wPvC1qprbnB8HnApsADzVjHck8D5gx6r6ZD/cH0kuB/6mqqYnORI4FJgK\nXAxsXVUn98c8WjLGDBvGFJ9ZLUmSVlCLDONJdgL2BUZX1dNJ1gVWAb4IvAIYWVWzkwwDjuq6dFZV\njWrGWB+4CFgTmJBkA+AS4ANVdV3TZ39gWP/dWkdV7dN1eBiwZ1Xd3xxf1ttxkgyqqjn9ujhJkiSt\n1HqzTWVD4JGqehqgqh4BpgMHAUdU1eymfUZVnbCwAarqYeATwCeTBDgcOG9eEG/6/LCqHuq+Lsnb\nk/wuyY1JrmxCPEnelGRa83NjkmFJNkxyddN2S5Jdmr73Jlk3ydnAa4CfJ/lMkgOSnNn0WS/JpUkm\nNz87N+0nJLkgybXABb18TyVJkqRe6U0Ynwi8KskdSc5K8ibgtcB9VTWjtxNV1X8DA4H1gW3pbEtZ\nlGuA11fVDsC/A//QtB8NHN5U3ncBZtHZRvPLpm17YNoC8x8CPAjsVlVfW2Ce0+hsoRkLvAf4dte5\nrelU0z/Y23uVJEmSemOR21SqamaSMXRC72509lqf1N0nyceATwHrAG+oqj/30/o2Ai5OsiGdrTH3\nNO3XAl9NciHwo6q6P8lk4Jwkg4EfV9W0hQ+5UHsCW3eK9gCsmWRo8/qyqpr1ku9Ei6Wn50GSE9te\nhiRJK6WqCW0vYYXXq6epVNWzVTWpOv9FPgm8HXh1s0+cqvpuU5F+nE71+3mSvIbOB0AfBm4FxvRi\n6jOAM6tqJJ0Pja7WzHcycCCwOnBtki2r6mpgV+AB4NwkH+nNvTUG0KnAj2p+XllVM5tzT77YhZIk\nSdLiWmQYT7JFks26mkYBfwS+A5yZZLWm30A61euFjbEecDadYF3AmcBHk7yuq8+75+0J77IWnXAN\n8NGuvptW1c1V9WVgMrBlko2Bh6rqW3S2mYxe1L11mQgc0TX+qD5cK0mSJC2W3jzacChwRpK16Tyi\n8C46H8Z8HPhn4JYkM+js2z6Pzr5sgNWTTOOvjza8APgqQFU9lOQDwKnNk1bmAlcDv1hg7hOAS5I8\nBvwa2KRp/3SS3ZrrbgV+DnwAOCbJM8BMoC+V8SOBbyS5ic57cjVwSB+ulyRJkvosnUK1tGxKhldn\nh5IkSVra3DO++JL0VNWOi+rnN3BKkiRJLTGMS5IkSS0xjEuSJEkt6c0HOKXWjBkznClT3K8mSZJW\nTFbGJUmSpJYYxiVJkqSWGMYlSZKklhjGJUmSpJYYxiVJkqSWGMYlSZKklhjGJUmSpJYYxiVJkqSW\nGMYlSZKklhjGJUmSpJYYxiVJkqSWGMYlSZKklhjGJUmSpJYYxiVJkqSWGMYlSZKklhjGJUmSpJYY\nxiVJkqSWGMYlSZKklhjGJUmSpJYMansB0ovpmTGDTJrU9jK0nKvx49tegiRJC2VlXJIkSWqJYVyS\nJElqiWFckiRJaolhXJIkSWqJYVySJElqiWFckiRJaolhXJIkSWrJIp8znmRmVQ1doO0Q4KmqOn+J\nrawzz8eBzwBF5xeHzwFrA3tX1Qe7+q0L3AZsBMwF/hl4DzADeBr4QlX9fEmuVUvGmGHDmOIzoiVJ\n0gpqsb70p6rO7u+FdEsS4FV0wvfoqno8yVBgPeBR4CtJhlTVU80l+wM/qaqnk5wMbAhs2xxvALxp\nSa5XkiRJWhyLtU0lyQlJjm5eT0ry5SQ3JLkjyS5N+8AkpySZnOSmJAc37UOT/CrJ1CQ3J3lH0z4i\nyR+TnA/cAmxCp7I9E6CqZlbVPVX1BPBfwNu7lvQB4PtJhgAHAUdU1dPNdQ9V1Q8W5z4lSZKkJam/\n9owPqqpxwKeBCU3b3wGPV9VYYCxwUJJNgNnAu6pqNLAbnSp3mms2A86qqm2Aa4CHgHuSfDdJd/j+\nPp0ATpLhwObAr4HXAvc1gV2SJElapi3WNpWF+FHzbw8wonm9F7Bdkv2b47XohO37gZOS7Epnf/cr\ngQ2aPn+qqusBqurZJHvTCfJ7AF9LMqaqTgB+BpyVZE3gfcClTf9+uh0tK3p6HiQ5se1lSJK00qqa\nsOhOWmz9Fcafbv59tmvM0Nku8svujkkOoLP3e0xVPZPkXmC15vST3X2rqoAbgBuSXAF8FzihqmYl\n+QXwLjoV8r9vLrkLeHWSNa2OS5IkaVm3JB9t+Evg0CSDAZJsnmQNOhXyh5sgvhuw8cIuTjI8yeiu\nplHAn7qOv08nhG8AXAfQfKDzO8BpSVZpxlkvyXv799YkSZKkl643lfEhSe7vOv5qL8f+Np0tK1Ob\nPeF/Ad4JXAj8JMnNwBTg9he4fjBwarMnfHZz/SFd568Azge+01TQ5zke+CLwhySz6VTbP9/LNUuS\nJElLTZ6bY6VlSzK84OC2lyFJ0krLPeOLJ0lPVe24qH5+A6ckSZLUEsO4JEmS1BLDuCRJktSS/nq0\nobREjBkznClT3KsmSZJWTFbGJUmSpJYYxiVJkqSWGMYlSZKklhjGJUmSpJYYxiVJkqSWGMYlSZKk\nlhjGJUmSpJb4nHEt2x7qga/kr8dHVXtrkSRJ6mdWxiVJkqSWGMYlSZKklhjGJUmSpJYYxiVJkqSW\nGMYlSZKklhjGJUmSpJYYxiVJkqSW+JxxLds2GANHTWl7FZIkSUuElXFJkiSpJYZxSZIkqSWGcUmS\nJKkl7hnXMq1nxgwyaVLby5AkSSuIGj++7SU8h5VxSZIkqSWGcUmSJKklhnFJkiSpJYZxSZIkqSWG\ncUmSJKklhnFJkiSpJYZxSZIkqSWLfM54kmeBm5u+9wB/W1XTX+rESUYAP62qbfthrHOBNwGPN03n\nVNXpL3XcF5hrPPB/VfXbrraPAP8AFDAHuLCqTm3W9dOq+mE/zDscOL2q9m+Ovw9sA3wXeBlwdVVd\n+VLnWdaMGTaMKcvY80AlSZL6S2++9GdWVY0CSHIecDjwpSW6qsVzzOKE3iQDq+rZPlwyHpgJ/La5\n/q3Ap4G9qurBJKsCH+nrOhalqh4E5gXxVwBjq+q1izNWkkFVNac/1ydJkqS+6+s2leuAVwIkGZrk\nV0mmJrk5yTua9hFJbkvyrSS3JpmYZPXm3Jgkv0/yezqhnqZ9tSTfbca5McluTfsBSX6c5Iok9yb5\nZJK/b/pcn+TlL7bYJB9sxrwlyZe72mcm+Uqzjp2adf1Xkp4kv0yyYdPvyCR/SHJTkn9vqvmHAJ9J\nMi3JLsBngaObsExVPV1V31rIWj6fZHKzln9LkoXN0bS9qRl/WnOvw5r39ZZmuInAK+etIcm5SeYF\n9Re6l0lJvp5kCvCp3v8nlyRJ0pLSm8o40KkgA3sA32maZgPvqqonkqwLXJ/ksubcZsAHq+qgJD8A\n3gN8j86Wik9W1dVJTuka/nCgqmpkki2BiUk2b85tC+wArAbcBRxbVTsk+RqdCvTXm36nJDm+ef23\nwKPAl4ExwGPNmO+sqh8DawC/q6qjkgwG/gt4R1X9Jcn76VT+Pw4cB2xSVU8nWbuqpic5G5hZVac2\n78u2QE8v3sIzq+oLzTUXAPsCP1lwjqbv0cDhVXVtkqHNe91tPzrbX+b9xeLvmn8HA2e8wL0ArFJV\nO/ZircuMnp4HSU5sexmSJC1xVRPaXoJa0JvK+OpJpgH/H7ABcEXTHuCkJDcBV9KpmG/QnLunqqY1\nr3uAEU3QXLuqrm7aL+ia4410wjpVdTvwJ2BeGL+qqmZU1V/o7An/SdN+MzCia4xjqmpU83MzMBaY\nVFV/abZkXAjs2vR9Fri0eb0FncB/RXOfxwMbNeduAi5M8mE6e8Ffit2S/C7JzcDudPZ7v9Ac1wJf\nTXIknfest3O/2L0AXPwS70GSJEn9qDdhfN6e8Y3pBPB520s+BKwHjGnOP0Sneg3wdNf1z9KHCvxC\ndI81t+t47ksYd3bXPvEAt3YF+ZFVtVdz7m3AN4DRwOQkC5vvVjrV9xeUZDXgLGD/qhoJfIu/vlfP\nm6OqTgYOBFYHrm3+WtAbL3YvAE/2chxJkiQtBb3eM15VTwFHAkc1oXQt4OGqeqbZ473xIq6fDkxP\n8sam6UNdp38z77jZnvJq4I+9vouFuwF4U5J1my02H6SzHWVBfwTWS7JTM//gJNskGQC8qqquAo6l\nc79DgRnAsK7r/4XOFplXNNevkuTABeaYF7wfabadzNvfvdA5kmxaVTdX1ZeByUBvw/hC76WX10qS\nJGkp61NluapubLalfJDOto+fNNsupgC392KIjwHnJCk6H0Kc5yzgm81Yc4ADmj3UfVnegmv9nyTH\nAVfRqRj/rKr+cyH9/q/58OPpSdai8558HbgD+F7TFjqPFZye5CfAD9P5wOoRVXV5kg2AK5sPZRZw\nzgJzTE/yLeAWOtt9JjenBr7AHP/c/IIzl07l/efAhr245xe6l1t7/85JkiRpaUlVtb0G6QUlwwsO\nbnsZkiQtcX6Ac8WSpKc3D87wGzglSZKklhjGJUmSpJa8lKecSEvcmDHDmTLFP9tJkqQVk5VxSZIk\nqSWGcUmSJKklhnFJkiSpJYZxSZIkqSWGcUmSJKklhnFJkiSpJYZxSZIkqSU+Z1zLtod64CtpexWS\nJGlFcVS1vYLnsDIuSZIktcQwLkmSJLXEMC5JkiS1xDAuSZIktcQwLkmSJLXEMC5JkiS1xDAuSZIk\ntcTnjGvZtsEYOGpK26uQJElaIqyMS5IkSS0xjEuSJEktMYxLkiRJLXHPuJZpPTNmkEmTetW3xo9f\nomuRJEnqb1bGJUmSpJYYxiVJkqSWGMYlSZKklhjGJUmSpJYYxiVJkqSWGMYlSZKklhjGJUmSpJb4\nnHEt08YMG8YUnx8uSZJWUIusjCeZ2fV6nyR3JNk4yQlJnkqy/sL6vsh4lydZexF9JiXZcSHtByQ5\nc1FzLI4kRye5Pcm0JJOTfOTF1rKYc+yY5PTm9apJrmzme3+SbyfZuj/mkSRJ0vKh15XxJHsApwNv\nqao/JQF4BDgKOLa341TVPn1dZH9IZ8GpqrkLOXcI8GZgXFU9kWRN4F39vYaqmgJMaQ53aNpGNccX\n92WsJAOr6tl+XJ4kSZKWsl7tGU+yK/AtYN+qurvr1DnA+5O8fCHXfDjJDU3l91+TDGza702ybvP6\nn5L8Mck1Sb6f5OiuId7bXH9Hkl262l/VVKvvTDKha76/T3JL8/Pppm1EM/75wC3Ntec2fW5O8pnm\n8n8EDq2qJwCq6omqOm8h9/TNJFOS3JrkxK72k5P8IclNSU5t2t7bzPP7JFc3beOT/LT5a8L3gLHN\n+7NpdwU+yV5JrksyNcklSYZ2vXdfTjIVeO8i/8NJkiRpmdabyviqwI+B8VV1+wLnZtIJ5J8CuoPx\nVsD7gZ2r6pkkZwEfAs7v6jMWeA+wPTAYmAr0dK+tqsYl2acZe8+mfRywLfAUMDnJz4ACPga8Dgjw\nuyT/BTwGbAZ8tKquTzIGeGVVbdusYe2mCj6sqv67F+/F56rqf5tfLH6VZDvgATpV9C2rqrq24Hye\nzl8RHlhwW05VPZzkQODoqtq3Wcu892Vd4Hhgz6p6MsmxwN8DX2guf7SqRvdirSuEnp4H6fq9R5Ik\ndamasOhOWqb1pjL+DPBb4O9e4PzpwEeTDOtq2wMYQycsT2uOX7PAdTsD/1lVs6tqBvCTBc7/qPm3\nBxjR1X5FVT1aVbOaPm9sfv6jqp6sqplN+7xq+p+q6vrm9X8Dr0lyRpK9gScWce8Lel9Tlb4R2AbY\nGngcmA18J8m76fySAHAtcG6Sg4CBfZjj9c241zbv3UeBjbvO92k7iyRJkpZdvQnjc4H3AeOS/OOC\nJ6tqOnARcHhXc4DzqmpU87NFVZ3Qx7U93fz7LM+t4NeCS1jEOE92rfUxOpX4ScAhwLebrSkzkyz4\ny8JzJNkE+P/bu/coP6v63uPvDwnKJRGqqIsAEkUQkNsh4AWtxEutqMW2goCcQ622kEqh9ehptYeK\nHrVH5WArIioioi0KchWrclEJQTCQRJIQbuoBUdFlwQty8wDxe/549pSf40zml5DMMwnv11qz8pv9\nXPb3+e01WZ/Zv/088zbgpVW1B/BlYJOqephutv5c4NXAxa2veXQz3NsBS5I8aYI6/7Mrul84Rt67\nXatq8Beh+8Y7UJIkSeuXodaMV9X9wKuAw5OMNUP+IeAoHgnNXwcOGnnSSpInJtl+1DFXAX+UZJO2\nJvrVQ9b8B+18mwJ/3M5zJfDHSTZLsjndspErRx/YloBsVFXn0QXlkeUe/xv4aFuyQpIZI09TGfAE\nuiB8d5KnAgeM7AtsUVVfAd5CF/ZJskNVXVNV7wTupAvlw1gIvCDJM9t5Nk+y05DHSpIkaT0y9NNU\n2lrpVwALktw5attdSS6gC6NU1Y1JjgMuTbIR3VKXo4HbB45ZlOQiYDnwU+B6uiUfE7kWOA/YFvi3\n9oQSkpzRtkE3431dktmjjt0G+HSrCeAd7d+PATPoltU81Oo9cdQ1LktyHXAz8EO6XwIAZgJfTLIJ\n3az2f2/tJyTZsbV9HVgG7D/RxVXVnUneAHw+yeNb83HAdyY6VpIkSeuXVE20ymMddp7MqKp7k2wG\nLACOrKpv91aQppxkVnUfukiSpNG8gXPqSrKkqib8WzV9/wXOU9P9oZtN6NaYG8QlSZL0mNFrGK+q\n1/fZvyRJktSnvmfGpVWaM2cWixf7EZwkSdowDfU0FUmSJElrn2FckiRJ6olhXJIkSeqJYVySJEnq\niWFckiRJ6olhXJIkSeqJYVySJEnqiWFckiRJ6olhXJIkSeqJYVySJEnqiWFckiRJ6olhXJIkSeqJ\nYVySJEnqiWFckiRJ6olhXJIkSeqJYVySJEnqiWFckiRJ6olhXJIkSeqJYVySJEnqyfS+C5BWZck9\n95D58/suQ+pdzZ3bdwmSpHXAmXFJkiSpJ4ZxSZIkqSeGcUmSJKknhnFJkiSpJ4ZxSZIkqSeGcUmS\nJKknhnFJkiSpJz5nXFPanJkzWezzlSVJ0gZqwpnxJCuTLE2yIsk5STZbGx0nOTDJ2x/lOZYmOWtt\n1LM2JZmV5NxHcfxzkixIckuS65KclmSzJG9IcvJarPMrSbZsr49NclOSM9fG2EiSJGliw8yMP1BV\newEkOROYB3zo0XZcVRcBF63p8Ul2AaYBv59k86q679HW1M47rapWPppzVNWPgYPWsP+nAucAh1bV\nt1rbQcDMR1PTWKrqlQPfvhl4WVX9qH0/9NgkmV5VD6/V4iRJkh4DVnfN+JXAMwGSXJhkSZIbkhzZ\n2qYlOaPNol+f5C2t/dgkNyZZPjKTPTLLm2SLJLcn2ai1b57kh0k2TrJDkotbP1cm2XmglsOAfwUu\nBV4z0phk39bP0iQnJFnR2jdL8oVWxwVJrkmyT9t2b5ITkywDnp9kTpIrWr+XJNl6Fdexf+traZvF\nnplk9kC/C5M8e6C++Un2add5epJr23Ej13A08JmRIA5QVedW1U8HByLJH7VruC7J11qIH6+erdtM\n+8gnHL/f9v1+kq2SfBx4BvDVJG8ZnIFP8uQk5yVZ1L5e0NrfleRfk1zVxkGSJEmraeg140mmAwcA\nF7emN1bVz5NsCixKch4wG9imqnZrx2zZ9n078PSq+n8DbQBU1d1JlgL7A5cDrwYuqaqHkpwKzKuq\n7yZ5LnAK8JJ26CHAHwA7A8cAn2vtnwb+sqq+leT9A129GfhFVe2aZDdg6cC2zYFrquqtSTYGrgBe\nU1V3JjkEeB/wxnGu423A0VV1VZIZwK9HvXVnA68Djm+hfuuqWpzkn4BvVNUb27muTfI1YDfgM+MO\nxCO+CTyvqirJXwB/B7x1nHqObO/p+5JMA35rqVFVzUvyCuDFVXVXkjcMbP4w8M9V9c0kTwMuAXZp\n23YFXlhVDwxR7xpZsuTHJO9eV6eXJEmrUHV83yVs8IYJ45u2sAzdzPin2utjk/xJe70dsCNwC/CM\nJB8Bvkw3aw2wHDgzyYXAhWP0cTZduL4cOBQ4pQXJ/YBzkozs93iANqN9V1X9IMkdwOlJngj8Bpg5\nMKv8ObpwD/BCumBJVa1Isnyg/5XAee31s+gC8WWt32nAT1ZxHVcBH0q3hOf8qvrRQL0AX2jvw/F0\noXxkLfnLgQOTvK19vwnwtDHem/FsC5zdAv7jgNtWUc+i9h5tDFxYVUvHPuWYXgbsOnBNT2hjA3DR\nugzikiRJG7phlqk8UFV7ta9jqurBJHPpQtrzq2pP4Dpgk6r6BbAnMJ9ubflp7RyvAj4K7E03iz76\nl4CLgFe0QD0H+Ear7ZcDfe9VVSMzsocBOyf5PvB/gScAr12D6x/x64F14gFuGOhz96p6+XjXUVXv\nB/4C2BS4atRSGqrqDuBnSfag+4Xj7IF+XjvQz9Oq6ibghvYeTOQjwMlVtTtwFF2YZ6x6qmoB8CLg\nDuCMJEesxnuzEd0M/Eid21TVvW3bWlmnL0mS9Fi1ps8Z34Juycf9LXw+DyDJVsBGVXUecBywd7q1\n4NtV1eXA37djZwyerIW7RXQz1/9eVSur6lfAbUkObudOkj3b+V4H7F5Vs6tqNt2a8cOq6pfAPW1J\nC3Sz7COuaseRZFdg93Gu7RbgyUme3/bdOMmzx7uOJDtU1fVV9YF2DTuPcc6z6ZaRbFFVIzPylwDH\npE05J/kvrf1k4M8GroEkfzqyJnzAFnThGuDPBvb9nXqSbA/8tKo+SfcL0t7jXPtYLqVbBjRy/r1W\n41hJkiStwpo+Z/xiYF6Sm+jC68LWvg3w6RZcAd5Bt8zj35JsQTcbfFJV/XLUUg7oAus5wNyBtsOB\njyU5DtgYOAvYErijPbFkxAK6pRRbA28CPpnkN3Rrv+9u+5wCfCbJjcDNdDPQdzNKm/k/CDip1Twd\n+BfgO+Ncx3uSvJhuicwNwFeBrUed9ly6XzTeM9D2nnbe5e39ug14dVX9NMmhwP9J8pR23gU8slZ/\nxLvolvD8gu6ThKe39r8do55Dgf+R5CHgXmB1ZsaPBT7alvVMb7XMW43jJUmSNI5UVd81rFVJZows\no0j3rOytq+pv2o2LG1fVr5PsAHwNeFZVPdhnvVq1ZFZ1q3AkSdJk8wbONZdkSVXtM9F+G+Jf4HxV\nknfQXdvtwBta+2bA5e0mxgBvNohLkiSpTxtcGK+qs3nkJsnB9nuACX87kSRJkibLBhfGtWGZM2cW\nixf7EZkkSdowrenTVCRJkiQ9SoZxSZIkqSeGcUmSJKknhnFJkiSpJ4ZxSZIkqSeGcUmSJKknhnFJ\nkiSpJ4ZxSZIkqSeGcUmSJKknhnFJkiSpJ4ZxSZIkqSeGcUmSJKknhnFJkiSpJ4ZxSZIkqSeGcUmS\nJKknhnFJkiSpJ4ZxSZIkqSeGcUmSJKknhnFJkiSpJ9P7LkBalSX33EPmz++7DA2p5s7tuwRJktYr\nzoxLkiRJPTGMS5IkST0xjEuSJEk9MYxLkiRJPTGMS5IkST0xjEuSJEk9MYxLkiRJPfE545rS5syc\nyWKfXS1JkjZQE86MJ1mZZGmSFUnOSbLZZBQ2Rh3/0Ee/kiRJ0royzDKVB6pqr6raDXgQmDfsyZNM\nW+PKfteYYTwdl9tIkiRpvbO6IfZK4JkASf5rkmvbrPknRoJ3knuTnJhkGfD8JPsmuTrJsrb/zCTT\nkpyQZFGS5UmOasfOTbIgyZeT3JLk40k2SvJ+YNPW15lJZrftnwVWANslOSzJ9W0G/wMjBbd63tf6\nX5jkqWvjjZMkSZIerVTVqndI7q2qGUmmA+cBFwPzgQ8Cf1pVDyU5BVhYVZ9NUsAhVfWFJI8Dbm7f\nL0ryBOB+4I3AU6rqvUkeD1wFHAxs386/K3B7e/2Jqjp3pI5W02zgVmC/qlqYZBawEJgD/AK4FDip\nqi5s9RxYVV9K8kHgV1X13rXy7mmdS2YVHNV3GZIkbVCqju+7hA1ekiVVtc9E+w0zM75pkqXAYuAH\nwKeAl9IF30Vt20uBZ7T9V9KFdoBnAT+pqkUAVfWrqnoYeDlwRDv2GuBJwI7tmGur6taqWgl8Hnjh\nOHXdXlUL2+t9gflVdWc7/5nAi9q2B4F/b6+XALOHuGZJkiRpnRvmaSoPVNVegw1JAnymqt4xxv6/\nbkF6VQIcU1WXjDrvXGD0VP14U/f3TdDHiIfqken/lfgEGUmSJE0Ra3rj49eBg5I8BSDJE5NsP8Z+\nt8o6DhsAAAnuSURBVABbJ9m37TezLXe5BPirJBu39p2SbN6OeU6Sp7ebMg8BvtnaHxrZfwzXAvsn\n2aqtXT8MuGINr02SJEmaFGsUxqvqRuA44NIky4HLgK3H2O9BukD9kXZD52XAJsBpwI3At5OsAD7B\nIzPWi4CTgZuA24ALWvupwPIkZ47Rz0+AtwOXA8uAJVX1xTW5NkmSJGmyTHgD52Rqy1TeVlWv7rsW\nTQ3ewClJ0trnDZzr3tq8gVOSJEnSOjClbmasqvl0j02UJEmSNnhTKoxLo82ZM4vFi/0oTZIkbZhc\npiJJkiT1xDAuSZIk9cQwLkmSJPXEMC5JkiT1xDAuSZIk9cQwLkmSJPXEMC5JkiT1xDAuSZIk9cQw\nLkmSJPXEMC5JkiT1xDAuSZIk9cQwLkmSJPXEMC5JkiT1xDAuSZIk9cQwLkmSJPXEMC5JkiT1xDAu\nSZIk9cQwLkmSJPXEMC5JkiT1ZHrfBUirsuSee8j8+UPtW3PnrtNaJEmS1jZnxiVJkqSeGMYlSZKk\nnhjGJUmSpJ4YxiVJkqSeGMYlSZKknhjGJUmSpJ4YxiVJkqSe+JxxTWlzZs5ksc8PlyRJG6gJZ8aT\nrEyyNMmKJF9KsmVrn5Xk3HGOmZ9knzUtKskBSRYnuTHJdUlObO3vSvK2NT3vGP1cPfD6hCQ3tH/n\nJTlibfUjSZIkjWWYmfEHqmovgCSfAY4G3ldVPwYOWtsFJdkNOBl4VVXdnGQacOTa7gegqvYb+PZI\n4IlVtXJ1z5NkelU9vPYqkyRJ0mPB6q4Z/xawDUCS2UlWtNebJjkryU1JLgA2HTkgyZuSfCfJtUk+\nmeTk1v7kJOclWdS+XtAO+Tu6sH8zQFWtrKqPjS4kyV+245a182zW2g9us/jLkixobc9u/S9NsjzJ\njq393vbvRcAMYEmSQwZn4JPskOTiJEuSXJlk59Z+RpKPJ7kG+OBqvo+SJEnS8GvG2wz1S4FPjbH5\nr4D7q2qXJHsA327HzAL+EdgbuAf4BrCsHfNh4J+r6ptJngZcAuwC7AacOERJ51fVJ1s/7wXeBHwE\neCfwh1V1x8iSGmAe8OGqOjPJ44BpgyeqqgOT3DvwCcC7BjafCsyrqu8meS5wCvCStm1bYL81mU3X\ncJYs+THJu/suQ5Kkx6Sq4/suYYM3TBjfNMlSuhnxm4DLxtjnRcBJAFW1PMny1v4c4Iqq+jlAknOA\nndq2lwG7Jhk5xxOSzFiN2ndrIXxLulntS1r7VcAZSb4AnN/avgX8zyTb0oX47w7TQatnP+CcgTof\nP7DLOQZxSZIkralhlqmMrBnfHgjdmvG11ffzqmqv9rVNVd0L3ADMGeL4M4C/rqrdgXcDmwBU1Tzg\nOGA7umUnT6qqzwEHAg8AX0nykrFPOWaNvxyoca+q2mVg+31DnkeSJEn6HUOvGa+q+4FjgbcmGT2j\nvgB4PfznDZh7tPZFwP5Jfq8d89qBYy4Fjhn5Jsle7eUJwD8k2am1b5Rk3hglzQR+kmRj4PCB8+xQ\nVddU1TuBO4HtkjwDuLWqTgK+OFDfRNf8K+C2JAe3cyfJnsMcK0mSJE1ktW7grKrrgOXAYaM2fQyY\nkeQm4H8BS9r+dwD/BFxLt3zk+8Dd7ZhjgX3aDZU30q3rpqqWA38LfL6dbwXwjDHK+Ufgmnbemwfa\nT0hyfbu59Gq6NeqvA1a05Ta7AZ9djcs+HHhTkmV0s/avWY1jJUmSpHGlqtZtB8mMqrq3zYxfAJxe\nVRes0061wUhmFRzVdxmSJD0meQPnmkuypKom/Ls7q/towzXxrjYjvQK4DbhwEvqUJEmSpryhH224\npqpqrf3FTEmSJGlDss7DuPRozJkzi8WL/YhMkiRtmCZjmYokSZKkMRjGJUmSpJ4YxiVJkqSeGMYl\nSZKknhjGJUmSpJ4YxiVJkqSeGMYlSZKknhjGJUmSpJ4YxiVJkqSeGMYlSZKknhjGJUmSpJ4YxiVJ\nkqSeGMYlSZKknhjGJUmSpJ4YxiVJkqSeGMYlSZKknhjGJUmSpJ4YxiVJkqSeGMYlSZKknhjGJUmS\npJ4YxiVJkqSeGMYlSZKknhjGJUmSpJ6kqvquQRpXknuAW/quQ0PZCrir7yI0FMdq/eFYrT8cq/XH\nZI3V9lX15Il2mj4JhUiPxi1VtU/fRWhiSRY7VusHx2r94VitPxyr9cdUGyuXqUiSJEk9MYxLkiRJ\nPTGMa6o7te8CNDTHav3hWK0/HKv1h2O1/phSY+UNnJIkSVJPnBmXJEmSemIYlyRJknpiGFfvkrwi\nyS1Jvpfk7WNsT5KT2vblSfbuo04NNVaHtzG6PsnVSfbso05NPFYD++2b5OEkB01mfXrEMGOVZG6S\npUluSHLFZNeozhD/B26R5EtJlrWx+vM+6hQkOT3JfyRZMc72KZMtDOPqVZJpwEeBA4BdgcOS7Dpq\ntwOAHdvXkcDHJrVIAUOP1W3A/lW1O/AepthNMo8VQ47VyH4fAC6d3Ao1YpixSrIlcApwYFU9Gzh4\n0gvVsD9XRwM3VtWewFzgxCSPm9RCNeIM4BWr2D5lsoVhXH17DvC9qrq1qh4EzgJeM2qf1wCfrc5C\nYMskW092oZp4rKrq6qr6Rft2IbDtJNeozjA/VwDHAOcB/zGZxem3DDNWrwfOr6ofAFSV49WPYcaq\ngJlJAswAfg48PLllCqCqFtC9/+OZMtnCMK6+bQP8cOD7H7W21d1H697qjsObgK+u04o0ngnHKsk2\nwJ/gJ019G+bnaifg95LMT7IkyRGTVp0GDTNWJwO7AD8Grgf+pqp+MznlaTVNmWwxvY9OJW3YkryY\nLoy/sO9aNK5/Af6+qn7TTeJpCpsOzAFeCmwKfCvJwqr6Tr9laQx/CCwFXgLsAFyW5Mqq+lW/ZWkq\nM4yrb3cA2w18v21rW919tO4NNQ5J9gBOAw6oqp9NUm36bcOM1T7AWS2IbwW8MsnDVXXh5JSoZpix\n+hHws6q6D7gvyQJgT8AwPrmGGas/B95f3R9x+V6S24CdgWsnp0SthimTLVymor4tAnZM8vR2k8uh\nwEWj9rkIOKLd+fw84O6q+slkF6qJxyrJ04Dzgf/mrF2vJhyrqnp6Vc2uqtnAucCbDeK9GOb/wC8C\nL0wyPclmwHOBmya5Tg03Vj+g+wSDJE8FngXcOqlValhTJls4M65eVdXDSf4auASYBpxeVTckmde2\nfxz4CvBK4HvA/XQzD5pkQ47VO4EnAae0GdeHq2qfvmp+rBpyrDQFDDNWVXVTkouB5cBvgNOqaszH\ntWndGfLn6j3AGUmuB0K3FOyu3op+DEvyebon2myV5EfA8cDGMPWyRbpPUiRJkiRNNpepSJIkST0x\njEuSJEk9MYxLkiRJPTGMS5IkST0xjEuSJEk9MYxLkiRJPTGMS5IkST35//dsG2TFAaEtAAAAAElF\nTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1096a668>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def benchmark(clf):\n",
    "    print('_' * 80)\n",
    "    print(\"Training: \")\n",
    "    print(clf)\n",
    "    t0 = time()\n",
    "    clf.fit(X_train, y_train)\n",
    "    #clf.fit(x_train, y_train)\n",
    "    train_time = time() - t0\n",
    "    print(\"train time: %0.3fs\" % train_time)\n",
    "\n",
    "    t0 = time()\n",
    "    pred = clf.predict(X_test)\n",
    "    #pred = clf.predict(x_test)\n",
    "    test_time = time() - t0\n",
    "    print(\"test time:  %0.3fs\" % test_time)\n",
    "\n",
    "    score = metrics.accuracy_score(y_test, pred)\n",
    "    print(\"accuracy:   %0.3f\" % score)\n",
    "\n",
    "    if hasattr(clf, 'coef_'):\n",
    "        print(\"dimensionality: %d\" % clf.coef_.shape[1])\n",
    "        print(\"density: %f\" % density(clf.coef_))\n",
    "\n",
    "        if True and feature_names is not None:\n",
    "        #if True and names is not None:\n",
    "            print(\"top 10 keywords per class:\")\n",
    "            for i, label in enumerate(target_names):\n",
    "            #for i, label in enumerate(labels):\n",
    "                top10 = np.argsort(clf.coef_[i])[-10:]\n",
    "                print(trim(\"%s: %s\" % (label, \" \".join(feature_names[top10]))))\n",
    "                #print(trim(\"%s: %s\" % (label, \" \".join(names[top10]))))\n",
    "        print()\n",
    "\n",
    "    if True:\n",
    "        print(\"classification report:\")\n",
    "        print(metrics.classification_report(y_test, pred,\n",
    "                                            target_names=target_names))\n",
    "\n",
    "    if True:\n",
    "        print(\"confusion matrix:\")\n",
    "        print(metrics.confusion_matrix(y_test, pred))\n",
    "\n",
    "    print()\n",
    "    clf_descr = str(clf).split('(')[0]\n",
    "    return clf_descr, score, train_time, test_time\n",
    "\n",
    "\n",
    "results = []\n",
    "for clf, name in (\n",
    "        (RidgeClassifier(tol=1e-2, solver=\"lsqr\"), \"Ridge Classifier\"),\n",
    "        (Perceptron(n_iter=50), \"Perceptron\"),\n",
    "        (PassiveAggressiveClassifier(n_iter=50), \"Passive-Aggressive\"),\n",
    "        (KNeighborsClassifier(n_neighbors=10), \"kNN\"),\n",
    "        (RandomForestClassifier(n_estimators=100), \"Random forest\")):\n",
    "    print('=' * 80)\n",
    "    print(name)\n",
    "    results.append(benchmark(clf))\n",
    "\n",
    "for penalty in [\"l2\", \"l1\"]:\n",
    "    print('=' * 80)\n",
    "    print(\"%s penalty\" % penalty.upper())\n",
    "    # Train Liblinear model\n",
    "    results.append(benchmark(LinearSVC(loss='l2', penalty=penalty,\n",
    "                                            dual=False, tol=1e-3)))\n",
    "\n",
    "    # Train SGD model\n",
    "    results.append(benchmark(SGDClassifier(alpha=.0001, n_iter=50,\n",
    "                                           penalty=penalty)))\n",
    "\n",
    "# Train SGD with Elastic Net penalty\n",
    "print('=' * 80)\n",
    "print(\"Elastic-Net penalty\")\n",
    "#results.append(benchmark(SGDClassifier(alpha=.0001, n_iter=50,\n",
    "#                                       penalty=\"elasticnet\")))\n",
    "\n",
    "# 'alpha': 0.000868511373751352, 'l1_ratio': 0.0035564803062231283\n",
    "results.append(benchmark(SGDClassifier(alpha=0.000868511373751352, n_iter=50,\n",
    "                                       l1_ratio=0.0035564803062231283, penalty=\"elasticnet\")))\n",
    "\n",
    "# Train NearestCentroid without threshold\n",
    "print('=' * 80)\n",
    "print(\"NearestCentroid (aka Rocchio classifier)\")\n",
    "results.append(benchmark(NearestCentroid()))\n",
    "\n",
    "# Train sparse Naive Bayes classifiers\n",
    "print('=' * 80)\n",
    "print(\"Naive Bayes\")\n",
    "#results.append(benchmark(MultinomialNB(alpha=.01)))\n",
    "#results.append(benchmark(BernoulliNB(alpha=.01)))\n",
    "\n",
    "print('=' * 80)\n",
    "print(\"LinearSVC with L1-based feature selection\")\n",
    "# The smaller C, the stronger the regularization.\n",
    "# The more regularization, the more sparsity.\n",
    "results.append(benchmark(Pipeline([\n",
    "  ('feature_selection', LinearSVC(penalty=\"l1\", dual=False, tol=1e-3)),\n",
    "  ('classification', LinearSVC())\n",
    "])))\n",
    "\n",
    "# make some plots\n",
    "\n",
    "indices = np.arange(len(results))\n",
    "\n",
    "results = [[x[i] for x in results] for i in range(4)]\n",
    "\n",
    "clf_names, score, training_time, test_time = results\n",
    "training_time = np.array(training_time) / np.max(training_time)\n",
    "test_time = np.array(test_time) / np.max(test_time)\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.title(\"Score\")\n",
    "plt.barh(indices, score, .2, label=\"score\", color='navy')\n",
    "plt.barh(indices + .3, training_time, .2, label=\"training time\",\n",
    "         color='c')\n",
    "plt.barh(indices + .6, test_time, .2, label=\"test time\", color='darkorange')\n",
    "plt.yticks(())\n",
    "plt.legend(loc='best')\n",
    "plt.subplots_adjust(left=.25)\n",
    "plt.subplots_adjust(top=.95)\n",
    "plt.subplots_adjust(bottom=.05)\n",
    "\n",
    "for i, c in zip(indices, clf_names):\n",
    "    plt.text(-.3, i, c)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "      Fatos       0.73      0.68      0.70        47\n",
      "     Normas       0.70      0.72      0.71        43\n",
      " Argumentos       0.43      0.52      0.47        44\n",
      "    Pedidos       0.55      0.71      0.62        34\n",
      "Irrelevante       0.76      0.60      0.67        85\n",
      "\n",
      "avg / total       0.66      0.64      0.64       253\n",
      "\n",
      "Fatos: n ru reclamante anexo qualquer 00 data imvel conforme requerente\n",
      "Normas: ser qualquer atos ato processual processo iii lei ii art\n",
      "Argumentos: protesto ru r razo requerente requerida imvel assim autor ser\n",
      "Pedidos: advocatcios custas bem 20 honorrios juros processuais pagamento co...\n",
      "Irrelevante: tutela direito contrato moral mais posse exposto dano ao pedido\n"
     ]
    }
   ],
   "source": [
    "raw_data = pd.read_csv('C:\\Users\\pedro.castanha\\Downloads\\ML_Gabinete_Digital.csv', error_bad_lines=False, sep='\\t', encoding='utf_8')\n",
    "words = pd.read_table('C:\\Users\\pedro.castanha\\Downloads\\stoplists\\stopwords_pt_br.txt', encoding='mbcs')\n",
    "\n",
    "stopwords = words.values.T.tolist()[0]\n",
    "\n",
    "x_vectorized = TfidfVectorizer(sublinear_tf=True, max_df=0.5, stop_words=stopwords)\n",
    "x_vectorized.fit(raw_data.Text)\n",
    "x_train = x_vectorized.transform(raw_data.Text)\n",
    "y_train = raw_data.Class\n",
    "\n",
    "names = np.asarray(x_vectorized.get_feature_names())\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_train, y_train, test_size=0.4, random_state=42)\n",
    "\n",
    "clf = MultinomialNB(alpha=.01)\n",
    "clf.fit(x_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(x_test)\n",
    "\n",
    "print(metrics.classification_report(y_test, y_pred, target_names=labels))\n",
    "\n",
    "for i, label in enumerate(labels):\n",
    "    top10 = np.argsort(clf.coef_[i])[-10:]\n",
    "    print(trim(\"%s: %s\" % (label, \" \".join(names[top10]))))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
