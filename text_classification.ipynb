{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import logging\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from optparse import OptionParser\n",
    "import sys\n",
    "from time import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neighbors import NearestCentroid\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.utils.extmath import density\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "# Display progress logs on stdout\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s %(levelname)s %(message)s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define default labels\n",
    "labels = ['Fatos', 'Normas', 'Argumentos', 'Pedidos', 'Irrelevante']\n",
    "\n",
    "# Define stopwords list\n",
    "stopwords = []\n",
    "\n",
    "raw_data = pd.read_csv('C:\\Users\\pedro.castanha\\Downloads\\ML_Gabinete_Digital.csv', error_bad_lines=False, sep='\\t', encoding='utf_8')\n",
    "words = pd.read_table('C:\\Users\\pedro.castanha\\Downloads\\stoplists\\stopwords_pt_br.txt', encoding='mbcs')\n",
    "\n",
    "stopwords = words.values.T.tolist()[0]\n",
    "\n",
    "x_vectorized = TfidfVectorizer(sublinear_tf=True, max_df=0.5, stop_words=stopwords)\n",
    "x_vectorized.fit(raw_data.Text)\n",
    "x_train = x_vectorized.transform(raw_data.Text)\n",
    "y_train = raw_data.Class\n",
    "\n",
    "names = np.asarray(x_vectorized.get_feature_names())\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_train, y_train, test_size=0.4, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load some categories from the training set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 20 newsgroups dataset for categories:\n",
      "['alt.atheism', 'talk.religion.misc', 'comp.graphics', 'sci.space']\n",
      "data loaded\n",
      "2034 documents - 3.980MB (training set)\n",
      "1353 documents - 2.867MB (test set)\n",
      "4 categories\n",
      "\n",
      "Extracting features from the training data using a sparse vectorizer\n",
      "done in 0.687000s at 5.793MB/s\n",
      "n_samples: 2034, n_features: 33809\n",
      "\n",
      "Extracting features from the test data using the same vectorizer\n",
      "done in 0.422000s at 6.795MB/s\n",
      "n_samples: 1353, n_features: 33809\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#if opts.all_categories:\n",
    "#    categories = None\n",
    "\n",
    "categories = [\n",
    "        'alt.atheism',\n",
    "        'talk.religion.misc',\n",
    "        'comp.graphics',\n",
    "        'sci.space',\n",
    "]\n",
    "\n",
    "#if opts.filtered:\n",
    "#    remove = ('headers', 'footers', 'quotes')\n",
    "#else:\n",
    "remove = ()\n",
    "\n",
    "print(\"Loading 20 newsgroups dataset for categories:\")\n",
    "print(categories if categories else \"all\")\n",
    "\n",
    "data_train = fetch_20newsgroups(subset='train', categories=categories,\n",
    "                                shuffle=True, random_state=42,\n",
    "                                remove=remove)\n",
    "\n",
    "data_test = fetch_20newsgroups(subset='test', categories=categories,\n",
    "                               shuffle=True, random_state=42,\n",
    "                               remove=remove)\n",
    "print('data loaded')\n",
    "\n",
    "# order of labels in `target_names` can be different from `categories`\n",
    "target_names = data_train.target_names\n",
    "\n",
    "\n",
    "def size_mb(docs):\n",
    "    return sum(len(s.encode('utf-8')) for s in docs) / 1e6\n",
    "\n",
    "data_train_size_mb = size_mb(data_train.data)\n",
    "data_test_size_mb = size_mb(data_test.data)\n",
    "\n",
    "print(\"%d documents - %0.3fMB (training set)\" % (\n",
    "    len(data_train.data), data_train_size_mb))\n",
    "print(\"%d documents - %0.3fMB (test set)\" % (\n",
    "    len(data_test.data), data_test_size_mb))\n",
    "print(\"%d categories\" % len(categories))\n",
    "print()\n",
    "\n",
    "# split a training set and a test set\n",
    "y_train, y_test = data_train.target, data_test.target\n",
    "\n",
    "print(\"Extracting features from the training data using a sparse vectorizer\")\n",
    "t0 = time()\n",
    "#if opts.use_hashing:\n",
    "#    vectorizer = HashingVectorizer(stop_words='english', non_negative=True,\n",
    "#                                   n_features=opts.n_features)\n",
    "#    X_train = vectorizer.transform(data_train.data)\n",
    "#else:\n",
    "vectorizer = TfidfVectorizer(sublinear_tf=True, max_df=0.5,\n",
    "                                 stop_words='english')\n",
    "X_train = vectorizer.fit_transform(data_train.data)\n",
    "duration = time() - t0\n",
    "print(\"done in %fs at %0.3fMB/s\" % (duration, data_train_size_mb / duration))\n",
    "print(\"n_samples: %d, n_features: %d\" % X_train.shape)\n",
    "print()\n",
    "\n",
    "print(\"Extracting features from the test data using the same vectorizer\")\n",
    "t0 = time()\n",
    "X_test = vectorizer.transform(data_test.data)\n",
    "duration = time() - t0\n",
    "print(\"done in %fs at %0.3fMB/s\" % (duration, data_test_size_mb / duration))\n",
    "print(\"n_samples: %d, n_features: %d\" % X_test.shape)\n",
    "print()\n",
    "\n",
    "# mapping from integer feature name to original token string\n",
    "#if opts.use_hashing:\n",
    "#    feature_names = None\n",
    "#else:\n",
    "feature_names = vectorizer.get_feature_names()\n",
    "\n",
    "#if opts.select_chi2:\n",
    "#    print(\"Extracting %d best features by a chi-squared test\" %\n",
    "#          opts.select_chi2)\n",
    "#    t0 = time()\n",
    "#    ch2 = SelectKBest(chi2, k=opts.select_chi2)\n",
    "#    X_train = ch2.fit_transform(X_train, y_train)\n",
    "#    X_test = ch2.transform(X_test)\n",
    "#    if feature_names:\n",
    "        # keep selected feature names\n",
    "#        feature_names = [feature_names[i] for i\n",
    "#                         in ch2.get_support(indices=True)]\n",
    "#    print(\"done in %fs\" % (time() - t0))\n",
    "#    print()\n",
    "\n",
    "if feature_names:\n",
    "    feature_names = np.asarray(feature_names)\n",
    "\n",
    "\n",
    "def trim(s):\n",
    "    \"\"\"Trim string to fit on terminal (assuming 80-column display)\"\"\"\n",
    "    return s if len(s) <= 80 else s[:77] + \"...\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Ridge Classifier\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,\n",
      "        max_iter=None, normalize=False, random_state=None, solver='lsqr',\n",
      "        tol=0.01)\n",
      "train time: 0.000s\n",
      "test time:  0.000s\n",
      "accuracy:   0.660\n",
      "dimensionality: 4259\n",
      "density: 0.725053\n",
      "top 10 keywords per class:\n",
      "Fatos: com requerentes 01 nº data anexo reclamante requerente conforme foi\n",
      "Normas: cpc apresentação lei cpp será processual iii ii ou art\n",
      "Argumentos: qual ser era assim pela lhe autor as protesto que\n",
      "Pedidos: querendo pena citação sejam depoimento da ao valor condenação seja\n",
      "Irrelevante: prática tem neste fazer exposto mais face pode ação pedido\n",
      "\n",
      "classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      Fatos       0.79      0.47      0.59        47\n",
      "     Normas       0.91      0.67      0.77        43\n",
      " Argumentos       0.71      0.27      0.39        44\n",
      "    Pedidos       0.88      0.65      0.75        34\n",
      "Irrelevante       0.54      0.96      0.69        85\n",
      "\n",
      "avg / total       0.72      0.66      0.64       253\n",
      "\n",
      "confusion matrix:\n",
      "[[22  0  1  0 24]\n",
      " [ 0 29  0  0 14]\n",
      " [ 5  1 12  3 23]\n",
      " [ 0  1  3 22  8]\n",
      " [ 1  1  1  0 82]]\n",
      "\n",
      "================================================================================\n",
      "Perceptron\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "Perceptron(alpha=0.0001, class_weight=None, eta0=1.0, fit_intercept=True,\n",
      "      n_iter=50, n_jobs=1, penalty=None, random_state=0, shuffle=True,\n",
      "      verbose=0, warm_start=False)\n",
      "train time: 0.016s\n",
      "test time:  0.000s\n",
      "accuracy:   0.640\n",
      "dimensionality: 4259\n",
      "density: 0.293966\n",
      "top 10 keywords per class:\n",
      "Fatos: registros 01 imóvel entretanto requerentes anexo requerente conforme r...\n",
      "Normas: colocou responsáveis cdc ii diploma ou cpc apresentação cpp art\n",
      "Argumentos: comarca um quais superior 30 todos observa as crédito protesto\n",
      "Pedidos: pago seja determinação empresa citação valor da procedente condenaçã...\n",
      "Irrelevante: inversão contrato ante judiciário impõe fudamentação pedido ante...\n",
      "\n",
      "classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      Fatos       0.69      0.66      0.67        47\n",
      "     Normas       0.76      0.79      0.77        43\n",
      " Argumentos       0.45      0.34      0.39        44\n",
      "    Pedidos       0.53      0.71      0.61        34\n",
      "Irrelevante       0.68      0.68      0.68        85\n",
      "\n",
      "avg / total       0.64      0.64      0.64       253\n",
      "\n",
      "confusion matrix:\n",
      "[[31  4  4  2  6]\n",
      " [ 2 34  1  2  4]\n",
      " [ 5  2 15  8 14]\n",
      " [ 3  1  3 24  3]\n",
      " [ 4  4 10  9 58]]\n",
      "\n",
      "================================================================================\n",
      "Passive-Aggressive\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "PassiveAggressiveClassifier(C=1.0, class_weight=None, fit_intercept=True,\n",
      "              loss='hinge', n_iter=50, n_jobs=1, random_state=None,\n",
      "              shuffle=True, verbose=0, warm_start=False)\n",
      "train time: 0.015s\n",
      "test time:  0.000s\n",
      "accuracy:   0.715\n",
      "dimensionality: 4259\n",
      "density: 0.666917\n",
      "top 10 keywords per class:\n",
      "Fatos: ano 000 requerentes 01 data anexo reclamante requerente conforme foi\n",
      "Normas: inexistência cdc cpc cpp processual será iii ii ou art\n",
      "Argumentos: superior notificação cabendo era observa fez lhe posto crédito pr...\n",
      "Pedidos: procedente querendo empresa pena sejam citação depoimento valor seja...\n",
      "Irrelevante: exatamente fazer tem neste pode mais prática face ação pedido\n",
      "\n",
      "classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      Fatos       0.82      0.68      0.74        47\n",
      "     Normas       0.89      0.74      0.81        43\n",
      " Argumentos       0.53      0.45      0.49        44\n",
      "    Pedidos       0.87      0.76      0.81        34\n",
      "Irrelevante       0.65      0.84      0.73        85\n",
      "\n",
      "avg / total       0.73      0.72      0.71       253\n",
      "\n",
      "confusion matrix:\n",
      "[[32  0  6  1  8]\n",
      " [ 2 32  0  0  9]\n",
      " [ 4  0 20  2 18]\n",
      " [ 0  1  3 26  4]\n",
      " [ 1  3  9  1 71]]\n",
      "\n",
      "================================================================================\n",
      "kNN\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=10, p=2,\n",
      "           weights='uniform')\n",
      "train time: 0.000s\n",
      "test time:  0.000s\n",
      "accuracy:   0.613\n",
      "classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      Fatos       0.68      0.55      0.61        47\n",
      "     Normas       0.74      0.72      0.73        43\n",
      " Argumentos       0.39      0.34      0.37        44\n",
      "    Pedidos       0.50      0.82      0.62        34\n",
      "Irrelevante       0.70      0.65      0.67        85\n",
      "\n",
      "avg / total       0.62      0.61      0.61       253\n",
      "\n",
      "confusion matrix:\n",
      "[[26  1  7  5  8]\n",
      " [ 3 31  3  3  3]\n",
      " [ 7  2 15 11  9]\n",
      " [ 1  1  0 28  4]\n",
      " [ 1  7 13  9 55]]\n",
      "\n",
      "================================================================================\n",
      "Random forest\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=100, n_jobs=1, oob_score=False, random_state=None,\n",
      "            verbose=0, warm_start=False)\n",
      "train time: 0.534s\n",
      "test time:  0.047s\n",
      "accuracy:   0.553\n",
      "classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      Fatos       0.54      0.30      0.38        47\n",
      "     Normas       0.89      0.58      0.70        43\n",
      " Argumentos       1.00      0.05      0.09        44\n",
      "    Pedidos       0.95      0.59      0.73        34\n",
      "Irrelevante       0.45      0.93      0.61        85\n",
      "\n",
      "avg / total       0.70      0.55      0.51       253\n",
      "\n",
      "confusion matrix:\n",
      "[[14  0  0  0 33]\n",
      " [ 0 25  0  0 18]\n",
      " [ 8  0  2  1 33]\n",
      " [ 1  0  0 20 13]\n",
      " [ 3  3  0  0 79]]\n",
      "\n",
      "================================================================================\n",
      "L2 penalty\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "LinearSVC(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='l2', max_iter=1000, multi_class='ovr',\n",
      "     penalty='l2', random_state=None, tol=0.001, verbose=0)\n",
      "train time: 0.000s\n",
      "test time:  0.000s\n",
      "accuracy:   0.692\n",
      "dimensionality: 4259\n",
      "density: 0.725053\n",
      "top 10 keywords per class:\n",
      "Fatos: nº ano 01 requerentes data anexo reclamante requerente conforme foi\n",
      "Normas: apresentação cdc cpc será cpp processual iii ii ou art\n",
      "Argumentos: crédito pela ser assim era autor lhe as protesto que\n",
      "Pedidos: querendo pena citação da sejam ao depoimento valor condenação seja\n",
      "Irrelevante: contrato neste fazer tem face prática mais pode ação pedido\n",
      "\n",
      "classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      Fatos       0.82      0.57      0.68        47\n",
      "     Normas       0.91      0.70      0.79        43\n",
      " Argumentos       0.71      0.34      0.46        44\n",
      "    Pedidos       0.85      0.68      0.75        34\n",
      "Irrelevante       0.58      0.94      0.71        85\n",
      "\n",
      "avg / total       0.74      0.69      0.68       253\n",
      "\n",
      "confusion matrix:\n",
      "[[27  1  1  0 18]\n",
      " [ 0 30  0  0 13]\n",
      " [ 5  0 15  3 21]\n",
      " [ 0  1  3 23  7]\n",
      " [ 1  1  2  1 80]]\n",
      "\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', n_iter=50, n_jobs=1,\n",
      "       penalty='l2', power_t=0.5, random_state=None, shuffle=True,\n",
      "       verbose=0, warm_start=False)\n",
      "train time: 0.016s\n",
      "test time:  0.000s\n",
      "accuracy:   0.708\n",
      "dimensionality: 4259\n",
      "density: 0.521813\n",
      "top 10 keywords per class:\n",
      "Fatos: ano qualquer data requerentes realização anexo reclamante requerente c...\n",
      "Normas: apresentação será cdc iii processual cpc cpp ou ii art\n",
      "Argumentos: crédito era assim lhe ser notificação autor as que protesto\n",
      "Pedidos: desde citação querendo valor sejam ao depoimento da condenação seja\n",
      "Irrelevante: pode exatamente exposto face impõe ação tem mais prática pedido\n",
      "\n",
      "classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      Fatos       0.82      0.60      0.69        47\n",
      "     Normas       0.87      0.79      0.83        43\n",
      " Argumentos       0.65      0.39      0.49        44\n",
      "    Pedidos       0.89      0.71      0.79        34\n",
      "Irrelevante       0.60      0.89      0.72        85\n",
      "\n",
      "avg / total       0.74      0.71      0.70       253\n",
      "\n",
      "confusion matrix:\n",
      "[[28  2  1  0 16]\n",
      " [ 0 34  0  0  9]\n",
      " [ 5  0 17  2 20]\n",
      " [ 0  1  3 24  6]\n",
      " [ 1  2  5  1 76]]\n",
      "\n",
      "================================================================================\n",
      "L1 penalty\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "LinearSVC(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='l2', max_iter=1000, multi_class='ovr',\n",
      "     penalty='l1', random_state=None, tol=0.001, verbose=0)\n",
      "train time: 0.015s\n",
      "test time:  0.000s\n",
      "accuracy:   0.581\n",
      "dimensionality: 4259\n",
      "density: 0.016201\n",
      "top 10 keywords per class:\n",
      "Fatos: anexo oitenta requerente foram entretanto requerentes conforme reclama...\n",
      "Normas: cpp 1o praticado processual incompetência será iii ou ii art\n",
      "Argumentos: era isto autores superior que posto lhe 30 crédito protesto\n",
      "Pedidos: ao todos querendo sejam citação pena valor depoimento seja condenação\n",
      "Irrelevante: ação judiciário contrato jurídico neste tem conduta mais pode face\n",
      "\n",
      "classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      Fatos       0.58      0.45      0.51        47\n",
      "     Normas       0.83      0.56      0.67        43\n",
      " Argumentos       0.47      0.18      0.26        44\n",
      "    Pedidos       0.78      0.62      0.69        34\n",
      "Irrelevante       0.51      0.86      0.64        85\n",
      "\n",
      "avg / total       0.61      0.58      0.56       253\n",
      "\n",
      "confusion matrix:\n",
      "[[21  0  3  1 22]\n",
      " [ 0 24  0  1 18]\n",
      " [11  0  8  1 24]\n",
      " [ 1  2  3 21  7]\n",
      " [ 3  3  3  3 73]]\n",
      "\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', n_iter=50, n_jobs=1,\n",
      "       penalty='l1', power_t=0.5, random_state=None, shuffle=True,\n",
      "       verbose=0, warm_start=False)\n",
      "train time: 0.032s\n",
      "test time:  0.000s\n",
      "accuracy:   0.652\n",
      "dimensionality: 4259\n",
      "density: 0.107913\n",
      "top 10 keywords per class:\n",
      "Fatos: data realização entretanto 000 cópia requerente reclamante conforme an...\n",
      "Normas: será apresentação responsáveis incompetência diploma iii ou cpp art ii\n",
      "Argumentos: este crédito superior que fez autor as lhe 30 protesto\n",
      "Pedidos: apreensão equivalente mandado citação depoimento valor sejam pena co...\n",
      "Irrelevante: tem administração justiça define fudamentação exatamente neste p...\n",
      "\n",
      "classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      Fatos       0.65      0.64      0.65        47\n",
      "     Normas       0.91      0.67      0.77        43\n",
      " Argumentos       0.39      0.27      0.32        44\n",
      "    Pedidos       0.77      0.68      0.72        34\n",
      "Irrelevante       0.62      0.84      0.71        85\n",
      "\n",
      "avg / total       0.65      0.65      0.64       253\n",
      "\n",
      "confusion matrix:\n",
      "[[30  0  6  2  9]\n",
      " [ 0 29  1  0 13]\n",
      " [10  1 12  4 17]\n",
      " [ 3  1  3 23  4]\n",
      " [ 3  1  9  1 71]]\n",
      "\n",
      "================================================================================\n",
      "Elastic-Net penalty\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', n_iter=50, n_jobs=1,\n",
      "       penalty='elasticnet', power_t=0.5, random_state=None, shuffle=True,\n",
      "       verbose=0, warm_start=False)\n",
      "train time: 0.031s\n",
      "test time:  0.000s\n",
      "accuracy:   0.708\n",
      "dimensionality: 4259\n",
      "density: 0.379714\n",
      "top 10 keywords per class:\n",
      "Fatos: realização cópia constituída requerentes anexo ano reclamante requeren...\n",
      "Normas: apresentação cpp será processual cdc cpc iii ii ou art\n",
      "Argumentos: era assim fez crédito notificação autor lhe as que protesto\n",
      "Pedidos: querendo requer pena citação sejam valor depoimento da condenação seja\n",
      "Irrelevante: exatamente conduta contrato impõe pedido mais tem pode jurídico ...\n",
      "\n",
      "classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      Fatos       0.78      0.60      0.67        47\n",
      "     Normas       0.87      0.79      0.83        43\n",
      " Argumentos       0.59      0.43      0.50        44\n",
      "    Pedidos       0.88      0.68      0.77        34\n",
      "Irrelevante       0.62      0.88      0.73        85\n",
      "\n",
      "avg / total       0.72      0.71      0.70       253\n",
      "\n",
      "confusion matrix:\n",
      "[[28  1  4  0 14]\n",
      " [ 0 34  0  0  9]\n",
      " [ 5  0 19  2 18]\n",
      " [ 2  2  3 23  4]\n",
      " [ 1  2  6  1 75]]\n",
      "\n",
      "================================================================================\n",
      "NearestCentroid (aka Rocchio classifier)\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "NearestCentroid(metric='euclidean', shrink_threshold=None)\n",
      "train time: 0.000s\n",
      "test time:  0.000s\n",
      "accuracy:   0.648\n",
      "classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      Fatos       0.73      0.47      0.57        47\n",
      "     Normas       0.94      0.67      0.78        43\n",
      " Argumentos       0.57      0.55      0.56        44\n",
      "    Pedidos       0.94      0.47      0.63        34\n",
      "Irrelevante       0.55      0.86      0.67        85\n",
      "\n",
      "avg / total       0.71      0.65      0.65       253\n",
      "\n",
      "confusion matrix:\n",
      "[[22  0  5  0 20]\n",
      " [ 0 29  0  1 13]\n",
      " [ 4  0 24  0 16]\n",
      " [ 3  1  3 16 11]\n",
      " [ 1  1 10  0 73]]\n",
      "\n",
      "================================================================================\n",
      "Naive Bayes\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "MultinomialNB(alpha=0.01, class_prior=None, fit_prior=True)\n",
      "train time: 0.000s\n",
      "test time:  0.000s\n",
      "accuracy:   0.656\n",
      "dimensionality: 4259\n",
      "density: 1.000000\n",
      "top 10 keywords per class:\n",
      "Fatos: não que para da conforme com do requerente foi em\n",
      "Normas: que em lei se não os no ii art ou\n",
      "Argumentos: sua ao as pela por não se da do que\n",
      "Pedidos: por em seja que pagamento condenação valor ao do da\n",
      "Irrelevante: ao pedido ação dos na se em que da do\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pedro.castanha\\AppData\\Local\\Continuum\\Anaconda2\\lib\\site-packages\\sklearn\\svm\\classes.py:199: DeprecationWarning: loss='l2' has been deprecated in favor of loss='squared_hinge' as of 0.16. Backward compatibility for the loss='l2' will be removed in 1.0\n",
      "  DeprecationWarning)\n",
      "C:\\Users\\pedro.castanha\\AppData\\Local\\Continuum\\Anaconda2\\lib\\site-packages\\sklearn\\svm\\classes.py:199: DeprecationWarning: loss='l2' has been deprecated in favor of loss='squared_hinge' as of 0.16. Backward compatibility for the loss='l2' will be removed in 1.0\n",
      "  DeprecationWarning)\n",
      "C:\\Users\\pedro.castanha\\AppData\\Local\\Continuum\\Anaconda2\\lib\\site-packages\\sklearn\\utils\\deprecation.py:70: DeprecationWarning: Function transform is deprecated; Support to use estimators as feature selectors will be removed in version 0.19. Use SelectFromModel instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "C:\\Users\\pedro.castanha\\AppData\\Local\\Continuum\\Anaconda2\\lib\\site-packages\\sklearn\\utils\\deprecation.py:70: DeprecationWarning: Function transform is deprecated; Support to use estimators as feature selectors will be removed in version 0.19. Use SelectFromModel instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      Fatos       0.74      0.74      0.74        47\n",
      "     Normas       0.77      0.77      0.77        43\n",
      " Argumentos       0.42      0.57      0.48        44\n",
      "    Pedidos       0.62      0.74      0.68        34\n",
      "Irrelevante       0.76      0.56      0.65        85\n",
      "\n",
      "avg / total       0.68      0.66      0.66       253\n",
      "\n",
      "confusion matrix:\n",
      "[[35  2  8  2  0]\n",
      " [ 2 33  2  1  5]\n",
      " [ 7  0 25  6  6]\n",
      " [ 1  1  3 25  4]\n",
      " [ 2  7 22  6 48]]\n",
      "\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "BernoulliNB(alpha=0.01, binarize=0.0, class_prior=None, fit_prior=True)\n",
      "train time: 0.002s\n",
      "test time:  0.001s\n",
      "accuracy:   0.684\n",
      "dimensionality: 4259\n",
      "density: 1.000000\n",
      "top 10 keywords per class:\n",
      "Fatos: no os para foi requerente com que do da em\n",
      "Normas: da se não no em os do que art ou\n",
      "Argumentos: na as não ao em por se da do que\n",
      "Pedidos: se no valor pagamento por ao em que do da\n",
      "Irrelevante: por não dos ao na se em que da do\n",
      "\n",
      "classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      Fatos       0.77      0.77      0.77        47\n",
      "     Normas       0.65      0.84      0.73        43\n",
      " Argumentos       0.52      0.64      0.57        44\n",
      "    Pedidos       0.72      0.68      0.70        34\n",
      "Irrelevante       0.77      0.59      0.67        85\n",
      "\n",
      "avg / total       0.70      0.68      0.68       253\n",
      "\n",
      "confusion matrix:\n",
      "[[36  2  7  1  1]\n",
      " [ 2 36  1  1  3]\n",
      " [ 6  0 28  3  7]\n",
      " [ 1  3  3 23  4]\n",
      " [ 2 14 15  4 50]]\n",
      "\n",
      "================================================================================\n",
      "LinearSVC with L1-based feature selection\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "Pipeline(steps=[('feature_selection', LinearSVC(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l1', random_state=None, tol=0.001,\n",
      "     verbose=0)), ('classification', LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
      "     verbose=0))])\n",
      "train time: 0.025s\n",
      "test time:  0.001s\n",
      "accuracy:   0.617\n",
      "classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      Fatos       0.68      0.49      0.57        47\n",
      "     Normas       0.86      0.56      0.68        43\n",
      " Argumentos       0.48      0.23      0.31        44\n",
      "    Pedidos       0.85      0.65      0.73        34\n",
      "Irrelevante       0.53      0.91      0.67        85\n",
      "\n",
      "avg / total       0.65      0.62      0.60       253\n",
      "\n",
      "confusion matrix:\n",
      "[[23  0  4  0 20]\n",
      " [ 0 24  1  0 18]\n",
      " [ 9  1 10  3 21]\n",
      " [ 1  0  3 22  8]\n",
      " [ 1  3  3  1 77]]\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAuMAAAI1CAYAAAB8GvSWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xbc572b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def benchmark(clf):\n",
    "    print('_' * 80)\n",
    "    print(\"Training: \")\n",
    "    print(clf)\n",
    "    t0 = time()\n",
    "    #clf.fit(X_train, y_train)\n",
    "    clf.fit(x_train, y_train)\n",
    "    train_time = time() - t0\n",
    "    print(\"train time: %0.3fs\" % train_time)\n",
    "\n",
    "    t0 = time()\n",
    "    #pred = clf.predict(X_test)\n",
    "    pred = clf.predict(x_test)\n",
    "    test_time = time() - t0\n",
    "    print(\"test time:  %0.3fs\" % test_time)\n",
    "\n",
    "    score = metrics.accuracy_score(y_test, pred)\n",
    "    print(\"accuracy:   %0.3f\" % score)\n",
    "\n",
    "    if hasattr(clf, 'coef_'):\n",
    "        print(\"dimensionality: %d\" % clf.coef_.shape[1])\n",
    "        print(\"density: %f\" % density(clf.coef_))\n",
    "\n",
    "        #if True and feature_names is not None:\n",
    "        if True and names is not None:\n",
    "            print(\"top 10 keywords per class:\")\n",
    "            #for i, label in enumerate(target_names):\n",
    "            for i, label in enumerate(labels):\n",
    "                top10 = np.argsort(clf.coef_[i])[-10:]\n",
    "                #print(trim(\"%s: %s\" % (label, \" \".join(feature_names[top10]))))\n",
    "                print(trim(\"%s: %s\" % (label, \" \".join(names[top10]))))\n",
    "        print()\n",
    "\n",
    "    if True:\n",
    "        print(\"classification report:\")\n",
    "        print(metrics.classification_report(y_test, pred,\n",
    "                                            target_names=target_names))\n",
    "\n",
    "    if True:\n",
    "        print(\"confusion matrix:\")\n",
    "        print(metrics.confusion_matrix(y_test, pred))\n",
    "\n",
    "    print()\n",
    "    clf_descr = str(clf).split('(')[0]\n",
    "    return clf_descr, score, train_time, test_time\n",
    "\n",
    "\n",
    "results = []\n",
    "for clf, name in (\n",
    "        (RidgeClassifier(tol=1e-2, solver=\"lsqr\"), \"Ridge Classifier\"),\n",
    "        (Perceptron(n_iter=50), \"Perceptron\"),\n",
    "        (PassiveAggressiveClassifier(n_iter=50), \"Passive-Aggressive\"),\n",
    "        (KNeighborsClassifier(n_neighbors=10), \"kNN\"),\n",
    "        (RandomForestClassifier(n_estimators=100), \"Random forest\")):\n",
    "    print('=' * 80)\n",
    "    print(name)\n",
    "    results.append(benchmark(clf))\n",
    "\n",
    "for penalty in [\"l2\", \"l1\"]:\n",
    "    print('=' * 80)\n",
    "    print(\"%s penalty\" % penalty.upper())\n",
    "    # Train Liblinear model\n",
    "    results.append(benchmark(LinearSVC(loss='l2', penalty=penalty,\n",
    "                                            dual=False, tol=1e-3)))\n",
    "\n",
    "    # Train SGD model\n",
    "    results.append(benchmark(SGDClassifier(alpha=.0001, n_iter=50,\n",
    "                                           penalty=penalty)))\n",
    "\n",
    "# Train SGD with Elastic Net penalty\n",
    "print('=' * 80)\n",
    "print(\"Elastic-Net penalty\")\n",
    "results.append(benchmark(SGDClassifier(alpha=.0001, n_iter=50,\n",
    "                                       penalty=\"elasticnet\")))\n",
    "\n",
    "# Train NearestCentroid without threshold\n",
    "print('=' * 80)\n",
    "print(\"NearestCentroid (aka Rocchio classifier)\")\n",
    "results.append(benchmark(NearestCentroid()))\n",
    "\n",
    "# Train sparse Naive Bayes classifiers\n",
    "print('=' * 80)\n",
    "print(\"Naive Bayes\")\n",
    "results.append(benchmark(MultinomialNB(alpha=.01)))\n",
    "results.append(benchmark(BernoulliNB(alpha=.01)))\n",
    "\n",
    "print('=' * 80)\n",
    "print(\"LinearSVC with L1-based feature selection\")\n",
    "# The smaller C, the stronger the regularization.\n",
    "# The more regularization, the more sparsity.\n",
    "results.append(benchmark(Pipeline([\n",
    "  ('feature_selection', LinearSVC(penalty=\"l1\", dual=False, tol=1e-3)),\n",
    "  ('classification', LinearSVC())\n",
    "])))\n",
    "\n",
    "# make some plots\n",
    "\n",
    "indices = np.arange(len(results))\n",
    "\n",
    "results = [[x[i] for x in results] for i in range(4)]\n",
    "\n",
    "clf_names, score, training_time, test_time = results\n",
    "training_time = np.array(training_time) / np.max(training_time)\n",
    "test_time = np.array(test_time) / np.max(test_time)\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.title(\"Score\")\n",
    "plt.barh(indices, score, .2, label=\"score\", color='navy')\n",
    "plt.barh(indices + .3, training_time, .2, label=\"training time\",\n",
    "         color='c')\n",
    "plt.barh(indices + .6, test_time, .2, label=\"test time\", color='darkorange')\n",
    "plt.yticks(())\n",
    "plt.legend(loc='best')\n",
    "plt.subplots_adjust(left=.25)\n",
    "plt.subplots_adjust(top=.95)\n",
    "plt.subplots_adjust(bottom=.05)\n",
    "\n",
    "for i, c in zip(indices, clf_names):\n",
    "    plt.text(-.3, i, c)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "      Fatos       0.73      0.68      0.70        47\n",
      "     Normas       0.70      0.72      0.71        43\n",
      " Argumentos       0.43      0.52      0.47        44\n",
      "    Pedidos       0.55      0.71      0.62        34\n",
      "Irrelevante       0.76      0.60      0.67        85\n",
      "\n",
      "avg / total       0.66      0.64      0.64       253\n",
      "\n",
      "Fatos: nº réu reclamante anexo qualquer 00 data imóvel conforme requerente\n",
      "Normas: ser qualquer atos ato processual processo iii lei ii art\n",
      "Argumentos: protesto réu ré razão requerente requerida imóvel assim autor ser\n",
      "Pedidos: advocatícios custas bem 20 honorários juros processuais pagamento co...\n",
      "Irrelevante: tutela direito contrato moral mais posse exposto dano ação pedido\n"
     ]
    }
   ],
   "source": [
    "raw_data = pd.read_csv('C:\\Users\\pedro.castanha\\Downloads\\ML_Gabinete_Digital.csv', error_bad_lines=False, sep='\\t', encoding='utf_8')\n",
    "words = pd.read_table('C:\\Users\\pedro.castanha\\Downloads\\stoplists\\stopwords_pt_br.txt', encoding='mbcs')\n",
    "\n",
    "stopwords = words.values.T.tolist()[0]\n",
    "\n",
    "x_vectorized = TfidfVectorizer(sublinear_tf=True, max_df=0.5, stop_words=stopwords)\n",
    "x_vectorized.fit(raw_data.Text)\n",
    "x_train = x_vectorized.transform(raw_data.Text)\n",
    "y_train = raw_data.Class\n",
    "\n",
    "names = np.asarray(x_vectorized.get_feature_names())\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_train, y_train, test_size=0.4, random_state=42)\n",
    "\n",
    "clf = MultinomialNB(alpha=.01)\n",
    "clf.fit(x_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(x_test)\n",
    "\n",
    "print(metrics.classification_report(y_test, y_pred, target_names=labels))\n",
    "\n",
    "for i, label in enumerate(labels):\n",
    "    top10 = np.argsort(clf.coef_[i])[-10:]\n",
    "    print(trim(\"%s: %s\" % (label, \" \".join(names[top10]))))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
